{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module import\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import torch\n",
    "import torchvision\n",
    "                \n",
    "sys.path.append('../cnn_preferred')\n",
    "from utils import normalise_img, clip_extreme_pixel,  get_cnn_features, img_deprocess, get_target_feature_shape\n",
    "from activation_maximization import generate_preferred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load network\n",
    "net = torchvision.models.vgg16(pretrained=True)\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image mean and std for pre/de-process image for input network\n",
    "img_mean=np.array([0.485, 0.456, 0.406],dtype=np.float),\n",
    "img_std = np.array([0.229,0.224,0.225])\n",
    "\n",
    "# if the model input is for 0-1 range, norm = 255, elif 0-255, norm = 1\n",
    "norm = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create save_dir\n",
    "save_dir = '../result'\n",
    "save_folder = 'jupyter_demo_torch_simpleCNN_conv'\n",
    "save_folder = save_folder + '_' + datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "save_path = os.path.join(save_dir,save_folder)\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial image for the optimization\n",
    "h, w = 224,224\n",
    "initial_input = np.random.randint(0, 256, (h,w,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layer = \"features[8]\"\n",
    "target_layer = \"features[10]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target layer setting\n",
    "target_layer_list = [target_layer]\n",
    "## obtain target feature shape\n",
    "# transform input shape for torch avairable shape\n",
    "initial_torch_input = torch.Tensor(initial_input.transpose(2,0, 1)[np.newaxis])\n",
    "# obtain target layer activation \n",
    "feat_shape = get_target_feature_shape(net, initial_torch_input, exec_str_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 56, 56)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options\n",
    "opts = {\n",
    "    'img_mean': img_mean, # img_mean to preprocessing input image (the default is [0.485, 0.456, 0.406]) \n",
    "    'img_std': img_std,   # img_std to preprocessing input image  (the default is [0.229,0.224,0.225]) \n",
    "    'norm': norm,         # if the model input is for 0-1 range, norm = 255, elif 0-255, norm = 1 (defalt is 255)\n",
    "    \n",
    "    'iter_n': 200, # the total number of iterations for gradient descend (defalt is 200)\n",
    "\n",
    "    'disp_every': 1, # display the information on the terminal for every n iterations (default is 1)\n",
    "\n",
    "    'save_intermediate': True, # save the intermediate or not (default is None)\n",
    "    'save_intermediate_every': 10, # save the intermediate for every n iterations (default is 10)\n",
    "    'save_intermediate_path': save_path, # the path to save the intermediate (default is None)\n",
    "\n",
    "    'lr_start': 1., # learning rate (default is 1.)\n",
    "    'lr_end': 1.,   # we can change learning rate linearly setteing these two parameters \n",
    "\n",
    "    'momentum_start': 0.001, # gradient with momentum (default is 0.001)\n",
    "    'momentum_end': 0.001,   # we can change momentum linearly setteing these two parameters too \n",
    "\n",
    "    'decay_start': 0.001, # pixel decay for each iteration (default is 0.001)\n",
    "    'decay_end': 0.001,   # we can also change pixel decay linealy  \n",
    "\n",
    "    'image_blur': True, # Use image smoothing or not (default is True)\n",
    "    'sigma_start': 2.5, # the size of the gaussian filter for image smoothing (default is 2.5)\n",
    "    'sigma_end': 0.5,   \n",
    "\n",
    "    'image_jitter': True, # use image jittering during optimization (default is True)\n",
    "    'jitter_size': 4,     # the size of jitter (default is 32)\n",
    "    \n",
    "    'use_p_norm_reg': False, # use p_norm regularization (default is False)\n",
    "    'p': 2,\n",
    "\n",
    "    'use_TV_norm_reg': False, # use total variance norm (default is False)\n",
    "    'TVbeta1': 1,             # the order of  spatial domain\n",
    "    'TVbeta2':1.2,            # the order temporal domain (for video input)\n",
    "\n",
    "    'clip_small_norm': True,   # clip or not the pixels with extreme high or low value (default True) \n",
    "    'clip_small_norm_every': 1,\n",
    "    'n_pct_start': 5,\n",
    "    'n_pct_end': 5,\n",
    "\n",
    "    'clip_small_contribution': True, # clip or not the poxels with smal contribution norm of RGB channels\n",
    "    'clip_small_contribution_every': 1,\n",
    "    'c_pct_start': 5,\n",
    "    'c_pct_end':5,\n",
    "    \n",
    "    'initial_input': initial_input, # the initial image for the optimization (setting to None will use random noise as initial image)\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set channel index and center postion (for setting feature mask)\n",
    "channel_list = [14,56]\n",
    "y_index = int(feat_shape[2]/2)\n",
    "x_index = int(feat_shape[3]/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "channel=14\n",
      "\n",
      "iter=1; mean(abs(feat))=5.89461;\n",
      "iter=2; mean(abs(feat))=1498.56;\n",
      "iter=3; mean(abs(feat))=2739.8;\n",
      "iter=4; mean(abs(feat))=5285.72;\n",
      "iter=5; mean(abs(feat))=2645.55;\n",
      "iter=6; mean(abs(feat))=2517.29;\n",
      "iter=7; mean(abs(feat))=2974.32;\n",
      "iter=8; mean(abs(feat))=3380.27;\n",
      "iter=9; mean(abs(feat))=379.454;\n",
      "iter=10; mean(abs(feat))=4587.21;\n",
      "iter=11; mean(abs(feat))=3953.31;\n",
      "iter=12; mean(abs(feat))=7453.28;\n",
      "iter=13; mean(abs(feat))=3751.87;\n",
      "iter=14; mean(abs(feat))=5618.27;\n",
      "iter=15; mean(abs(feat))=6989.64;\n",
      "iter=16; mean(abs(feat))=5098.97;\n",
      "iter=17; mean(abs(feat))=865.434;\n",
      "iter=18; mean(abs(feat))=6793.17;\n",
      "iter=19; mean(abs(feat))=3513.88;\n",
      "iter=20; mean(abs(feat))=2557.05;\n",
      "iter=21; mean(abs(feat))=2481.68;\n",
      "iter=22; mean(abs(feat))=3904.78;\n",
      "iter=23; mean(abs(feat))=6286.18;\n",
      "iter=24; mean(abs(feat))=3596.25;\n",
      "iter=25; mean(abs(feat))=4149.51;\n",
      "iter=26; mean(abs(feat))=4837.01;\n",
      "iter=27; mean(abs(feat))=7323.94;\n",
      "iter=28; mean(abs(feat))=3170.42;\n",
      "iter=29; mean(abs(feat))=5891.7;\n",
      "iter=30; mean(abs(feat))=6893.2;\n",
      "iter=31; mean(abs(feat))=2437.64;\n",
      "iter=32; mean(abs(feat))=3812.24;\n",
      "iter=33; mean(abs(feat))=7128.89;\n",
      "iter=34; mean(abs(feat))=8124.77;\n",
      "iter=35; mean(abs(feat))=5553.83;\n",
      "iter=36; mean(abs(feat))=6542.89;\n",
      "iter=37; mean(abs(feat))=6319.62;\n",
      "iter=38; mean(abs(feat))=7677.64;\n",
      "iter=39; mean(abs(feat))=5021.27;\n",
      "iter=40; mean(abs(feat))=4940.39;\n",
      "iter=41; mean(abs(feat))=4044.7;\n",
      "iter=42; mean(abs(feat))=2185.48;\n",
      "iter=43; mean(abs(feat))=4625.9;\n",
      "iter=44; mean(abs(feat))=3571.86;\n",
      "iter=45; mean(abs(feat))=3605.71;\n",
      "iter=46; mean(abs(feat))=6855.05;\n",
      "iter=47; mean(abs(feat))=4258.46;\n",
      "iter=48; mean(abs(feat))=5093.84;\n",
      "iter=49; mean(abs(feat))=5095.44;\n",
      "iter=50; mean(abs(feat))=4971.83;\n",
      "iter=51; mean(abs(feat))=7951.04;\n",
      "iter=52; mean(abs(feat))=8530.53;\n",
      "iter=53; mean(abs(feat))=7109;\n",
      "iter=54; mean(abs(feat))=5521.89;\n",
      "iter=55; mean(abs(feat))=5823.16;\n",
      "iter=56; mean(abs(feat))=4032;\n",
      "iter=57; mean(abs(feat))=4725.6;\n",
      "iter=58; mean(abs(feat))=5038.93;\n",
      "iter=59; mean(abs(feat))=7386.54;\n",
      "iter=60; mean(abs(feat))=8853.1;\n",
      "iter=61; mean(abs(feat))=5332.68;\n",
      "iter=62; mean(abs(feat))=7019.67;\n",
      "iter=63; mean(abs(feat))=9756.94;\n",
      "iter=64; mean(abs(feat))=11433;\n",
      "iter=65; mean(abs(feat))=13997.6;\n",
      "iter=66; mean(abs(feat))=11386.6;\n",
      "iter=67; mean(abs(feat))=8181.18;\n",
      "iter=68; mean(abs(feat))=11290.9;\n",
      "iter=69; mean(abs(feat))=13234.6;\n",
      "iter=70; mean(abs(feat))=15221.4;\n",
      "iter=71; mean(abs(feat))=7070.68;\n",
      "iter=72; mean(abs(feat))=6987;\n",
      "iter=73; mean(abs(feat))=12876.2;\n",
      "iter=74; mean(abs(feat))=13485.2;\n",
      "iter=75; mean(abs(feat))=5074.58;\n",
      "iter=76; mean(abs(feat))=7275.26;\n",
      "iter=77; mean(abs(feat))=6332.42;\n",
      "iter=78; mean(abs(feat))=5449.63;\n",
      "iter=79; mean(abs(feat))=8430.22;\n",
      "iter=80; mean(abs(feat))=10786.7;\n",
      "iter=81; mean(abs(feat))=13019.8;\n",
      "iter=82; mean(abs(feat))=9987.63;\n",
      "iter=83; mean(abs(feat))=15207.1;\n",
      "iter=84; mean(abs(feat))=17054.1;\n",
      "iter=85; mean(abs(feat))=12168.6;\n",
      "iter=86; mean(abs(feat))=14609.1;\n",
      "iter=87; mean(abs(feat))=12938.6;\n",
      "iter=88; mean(abs(feat))=10819.6;\n",
      "iter=89; mean(abs(feat))=11455;\n",
      "iter=90; mean(abs(feat))=9808.2;\n",
      "iter=91; mean(abs(feat))=7960;\n",
      "iter=92; mean(abs(feat))=6356.12;\n",
      "iter=93; mean(abs(feat))=8042.33;\n",
      "iter=94; mean(abs(feat))=1569.11;\n",
      "iter=95; mean(abs(feat))=7876.35;\n",
      "iter=96; mean(abs(feat))=10762.7;\n",
      "iter=97; mean(abs(feat))=9912.48;\n",
      "iter=98; mean(abs(feat))=7727.9;\n",
      "iter=99; mean(abs(feat))=2902.48;\n",
      "iter=100; mean(abs(feat))=9890.47;\n",
      "iter=101; mean(abs(feat))=10706.2;\n",
      "iter=102; mean(abs(feat))=7062.64;\n",
      "iter=103; mean(abs(feat))=4327.18;\n",
      "iter=104; mean(abs(feat))=2468.15;\n",
      "iter=105; mean(abs(feat))=13028;\n",
      "iter=106; mean(abs(feat))=6699.17;\n",
      "iter=107; mean(abs(feat))=15954;\n",
      "iter=108; mean(abs(feat))=16447.5;\n",
      "iter=109; mean(abs(feat))=10091.1;\n",
      "iter=110; mean(abs(feat))=15209.6;\n",
      "iter=111; mean(abs(feat))=10309;\n",
      "iter=112; mean(abs(feat))=7271.67;\n",
      "iter=113; mean(abs(feat))=9105.08;\n",
      "iter=114; mean(abs(feat))=5011.49;\n",
      "iter=115; mean(abs(feat))=13603.6;\n",
      "iter=116; mean(abs(feat))=5540.15;\n",
      "iter=117; mean(abs(feat))=12430.4;\n",
      "iter=118; mean(abs(feat))=11943.8;\n",
      "iter=119; mean(abs(feat))=12309.3;\n",
      "iter=120; mean(abs(feat))=7667.89;\n",
      "iter=121; mean(abs(feat))=13755.3;\n",
      "iter=122; mean(abs(feat))=9001.25;\n",
      "iter=123; mean(abs(feat))=5537.89;\n",
      "iter=124; mean(abs(feat))=9504.06;\n",
      "iter=125; mean(abs(feat))=19561.6;\n",
      "iter=126; mean(abs(feat))=13640;\n",
      "iter=127; mean(abs(feat))=19203.4;\n",
      "iter=128; mean(abs(feat))=16938.8;\n",
      "iter=129; mean(abs(feat))=16174.4;\n",
      "iter=130; mean(abs(feat))=11999;\n",
      "iter=131; mean(abs(feat))=18817.3;\n",
      "iter=132; mean(abs(feat))=14995;\n",
      "iter=133; mean(abs(feat))=6476.5;\n",
      "iter=134; mean(abs(feat))=14588.5;\n",
      "iter=135; mean(abs(feat))=9463.28;\n",
      "iter=136; mean(abs(feat))=20353.3;\n",
      "iter=137; mean(abs(feat))=21149.7;\n",
      "iter=138; mean(abs(feat))=11054.6;\n",
      "iter=139; mean(abs(feat))=10317.8;\n",
      "iter=140; mean(abs(feat))=11097.5;\n",
      "iter=141; mean(abs(feat))=21466.3;\n",
      "iter=142; mean(abs(feat))=14463.4;\n",
      "iter=143; mean(abs(feat))=29093.3;\n",
      "iter=144; mean(abs(feat))=22287.7;\n",
      "iter=145; mean(abs(feat))=11621.7;\n",
      "iter=146; mean(abs(feat))=29167.5;\n",
      "iter=147; mean(abs(feat))=11207.9;\n",
      "iter=148; mean(abs(feat))=8414.03;\n",
      "iter=149; mean(abs(feat))=11873.3;\n",
      "iter=150; mean(abs(feat))=14035.6;\n",
      "iter=151; mean(abs(feat))=21783.2;\n",
      "iter=152; mean(abs(feat))=13759.9;\n",
      "iter=153; mean(abs(feat))=22355;\n",
      "iter=154; mean(abs(feat))=29781.8;\n",
      "iter=155; mean(abs(feat))=11364.6;\n",
      "iter=156; mean(abs(feat))=14999.4;\n",
      "iter=157; mean(abs(feat))=14928.4;\n",
      "iter=158; mean(abs(feat))=10340.3;\n",
      "iter=159; mean(abs(feat))=22020.2;\n",
      "iter=160; mean(abs(feat))=30203.3;\n",
      "iter=161; mean(abs(feat))=40507.9;\n",
      "iter=162; mean(abs(feat))=13629.9;\n",
      "iter=163; mean(abs(feat))=34982;\n",
      "iter=164; mean(abs(feat))=26245.1;\n",
      "iter=165; mean(abs(feat))=23815.6;\n",
      "iter=166; mean(abs(feat))=32078.3;\n",
      "iter=167; mean(abs(feat))=37209.7;\n",
      "iter=168; mean(abs(feat))=52384.2;\n",
      "iter=169; mean(abs(feat))=57420.2;\n",
      "iter=170; mean(abs(feat))=45256.8;\n",
      "iter=171; mean(abs(feat))=30602.9;\n",
      "iter=172; mean(abs(feat))=16881.7;\n",
      "iter=173; mean(abs(feat))=30381;\n",
      "iter=174; mean(abs(feat))=3817.61;\n",
      "iter=175; mean(abs(feat))=39710.6;\n",
      "iter=176; mean(abs(feat))=41086.2;\n",
      "iter=177; mean(abs(feat))=44130.3;\n",
      "iter=178; mean(abs(feat))=18458.9;\n",
      "iter=179; mean(abs(feat))=19363;\n",
      "iter=180; mean(abs(feat))=12077.1;\n",
      "iter=181; mean(abs(feat))=21460.7;\n",
      "iter=182; mean(abs(feat))=38299.9;\n",
      "iter=183; mean(abs(feat))=25820;\n",
      "iter=184; mean(abs(feat))=43828.6;\n",
      "iter=185; mean(abs(feat))=33804.8;\n",
      "iter=186; mean(abs(feat))=58195.5;\n",
      "iter=187; mean(abs(feat))=40836;\n",
      "iter=188; mean(abs(feat))=2226.52;\n",
      "iter=189; mean(abs(feat))=52215.2;\n",
      "iter=190; mean(abs(feat))=43600.4;\n",
      "iter=191; mean(abs(feat))=19330.9;\n",
      "iter=192; mean(abs(feat))=54169.5;\n",
      "iter=193; mean(abs(feat))=11789.5;\n",
      "iter=194; mean(abs(feat))=19146.7;\n",
      "iter=195; mean(abs(feat))=23631;\n",
      "iter=196; mean(abs(feat))=36984;\n",
      "iter=197; mean(abs(feat))=64169.4;\n",
      "iter=198; mean(abs(feat))=73358.7;\n",
      "iter=199; mean(abs(feat))=43318.6;\n",
      "iter=200; mean(abs(feat))=79870.5;\n",
      "\n",
      "channel=56\n",
      "\n",
      "iter=1; mean(abs(feat))=7.63224;\n",
      "iter=2; mean(abs(feat))=189.417;\n",
      "iter=3; mean(abs(feat))=282.872;\n",
      "iter=4; mean(abs(feat))=710.395;\n",
      "iter=5; mean(abs(feat))=54.5231;\n",
      "iter=6; mean(abs(feat))=111.658;\n",
      "iter=7; mean(abs(feat))=120.443;\n",
      "iter=8; mean(abs(feat))=444.139;\n",
      "iter=9; mean(abs(feat))=279.781;\n",
      "iter=10; mean(abs(feat))=788.457;\n",
      "iter=11; mean(abs(feat))=1525.42;\n",
      "iter=12; mean(abs(feat))=796.004;\n",
      "iter=13; mean(abs(feat))=1202.57;\n",
      "iter=14; mean(abs(feat))=1514.92;\n",
      "iter=15; mean(abs(feat))=817.835;\n",
      "iter=16; mean(abs(feat))=1798.28;\n",
      "iter=17; mean(abs(feat))=2190.39;\n",
      "iter=18; mean(abs(feat))=337.66;\n",
      "iter=19; mean(abs(feat))=2126.82;\n",
      "iter=20; mean(abs(feat))=437.118;\n",
      "iter=21; mean(abs(feat))=821.223;\n",
      "iter=22; mean(abs(feat))=1318.86;\n",
      "iter=23; mean(abs(feat))=889.676;\n",
      "iter=24; mean(abs(feat))=689.013;\n",
      "iter=25; mean(abs(feat))=866.747;\n",
      "iter=26; mean(abs(feat))=934.698;\n",
      "iter=27; mean(abs(feat))=2334.62;\n",
      "iter=28; mean(abs(feat))=2116.11;\n",
      "iter=29; mean(abs(feat))=2539.98;\n",
      "iter=30; mean(abs(feat))=4116.4;\n",
      "iter=31; mean(abs(feat))=408.761;\n",
      "iter=32; mean(abs(feat))=2084.6;\n",
      "iter=33; mean(abs(feat))=2458.68;\n",
      "iter=34; mean(abs(feat))=262.96;\n",
      "iter=35; mean(abs(feat))=1187.44;\n",
      "iter=36; mean(abs(feat))=3111.63;\n",
      "iter=37; mean(abs(feat))=93.7989;\n",
      "iter=38; mean(abs(feat))=2683.73;\n",
      "iter=39; mean(abs(feat))=2435.19;\n",
      "iter=40; mean(abs(feat))=1703.95;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=41; mean(abs(feat))=775.452;\n",
      "iter=42; mean(abs(feat))=477.644;\n",
      "iter=43; mean(abs(feat))=283.371;\n",
      "iter=44; mean(abs(feat))=1162.19;\n",
      "iter=45; mean(abs(feat))=616.821;\n",
      "iter=46; mean(abs(feat))=2147.86;\n",
      "iter=47; mean(abs(feat))=4181.09;\n",
      "iter=48; mean(abs(feat))=3136.54;\n",
      "iter=49; mean(abs(feat))=1137.11;\n",
      "iter=50; mean(abs(feat))=1215.34;\n",
      "iter=51; mean(abs(feat))=2988.06;\n",
      "iter=52; mean(abs(feat))=4153.95;\n",
      "iter=53; mean(abs(feat))=4532.81;\n",
      "iter=54; mean(abs(feat))=4590.33;\n",
      "iter=55; mean(abs(feat))=2035.26;\n",
      "iter=56; mean(abs(feat))=1537.59;\n",
      "iter=57; mean(abs(feat))=81.499;\n",
      "iter=58; mean(abs(feat))=441.165;\n",
      "iter=59; mean(abs(feat))=723.348;\n",
      "iter=60; mean(abs(feat))=1920.54;\n",
      "iter=61; mean(abs(feat))=1121.41;\n",
      "iter=62; mean(abs(feat))=3966.17;\n",
      "iter=63; mean(abs(feat))=2594.01;\n",
      "iter=64; mean(abs(feat))=751.861;\n",
      "iter=65; mean(abs(feat))=241.192;\n",
      "iter=66; mean(abs(feat))=2083.33;\n",
      "iter=67; mean(abs(feat))=1768.77;\n",
      "iter=68; mean(abs(feat))=4140.32;\n",
      "iter=69; mean(abs(feat))=603.097;\n",
      "iter=70; mean(abs(feat))=3631.71;\n",
      "iter=71; mean(abs(feat))=6592.87;\n",
      "iter=72; mean(abs(feat))=6661.6;\n",
      "iter=73; mean(abs(feat))=4328.22;\n",
      "iter=74; mean(abs(feat))=2893.7;\n",
      "iter=75; mean(abs(feat))=3374.07;\n",
      "iter=76; mean(abs(feat))=5816.54;\n",
      "iter=77; mean(abs(feat))=1319.03;\n",
      "iter=78; mean(abs(feat))=576.859;\n",
      "iter=79; mean(abs(feat))=2659.67;\n",
      "iter=80; mean(abs(feat))=273.011;\n",
      "iter=81; mean(abs(feat))=1006.92;\n",
      "iter=82; mean(abs(feat))=2410.58;\n",
      "iter=83; mean(abs(feat))=5444.24;\n",
      "iter=84; mean(abs(feat))=5750.77;\n",
      "iter=85; mean(abs(feat))=5924.18;\n",
      "iter=86; mean(abs(feat))=841.152;\n",
      "iter=87; mean(abs(feat))=884.256;\n",
      "iter=88; mean(abs(feat))=2677.28;\n",
      "iter=89; mean(abs(feat))=5596.69;\n",
      "iter=90; mean(abs(feat))=6014.07;\n",
      "iter=91; mean(abs(feat))=2039.63;\n",
      "iter=92; mean(abs(feat))=4398.18;\n",
      "iter=93; mean(abs(feat))=3702.49;\n",
      "iter=94; mean(abs(feat))=7.48509;\n",
      "iter=95; mean(abs(feat))=2709.61;\n",
      "iter=96; mean(abs(feat))=233.961;\n",
      "iter=97; mean(abs(feat))=1063.65;\n",
      "iter=98; mean(abs(feat))=4149.77;\n",
      "iter=99; mean(abs(feat))=5234.72;\n",
      "iter=100; mean(abs(feat))=4477.01;\n",
      "iter=101; mean(abs(feat))=4363.3;\n",
      "iter=102; mean(abs(feat))=5350.44;\n",
      "iter=103; mean(abs(feat))=8476.3;\n",
      "iter=104; mean(abs(feat))=532.747;\n",
      "iter=105; mean(abs(feat))=2535.08;\n",
      "iter=106; mean(abs(feat))=5098.1;\n",
      "iter=107; mean(abs(feat))=2240.59;\n",
      "iter=108; mean(abs(feat))=6349.57;\n",
      "iter=109; mean(abs(feat))=7700.88;\n",
      "iter=110; mean(abs(feat))=2230.65;\n",
      "iter=111; mean(abs(feat))=3.29333;\n",
      "iter=112; mean(abs(feat))=4848.78;\n",
      "iter=113; mean(abs(feat))=5038.21;\n",
      "iter=114; mean(abs(feat))=4264;\n",
      "iter=115; mean(abs(feat))=4425.38;\n",
      "iter=116; mean(abs(feat))=9293.51;\n",
      "iter=117; mean(abs(feat))=547.118;\n",
      "iter=118; mean(abs(feat))=1565.89;\n",
      "iter=119; mean(abs(feat))=880.021;\n",
      "iter=120; mean(abs(feat))=6893.57;\n",
      "iter=121; mean(abs(feat))=12399.7;\n",
      "iter=122; mean(abs(feat))=12769.6;\n",
      "iter=123; mean(abs(feat))=6583.32;\n",
      "iter=124; mean(abs(feat))=5387.79;\n",
      "iter=125; mean(abs(feat))=6291.37;\n",
      "iter=126; mean(abs(feat))=3795.71;\n",
      "iter=127; mean(abs(feat))=8217.74;\n",
      "iter=128; mean(abs(feat))=12834.6;\n",
      "iter=129; mean(abs(feat))=14997;\n",
      "iter=130; mean(abs(feat))=3675.16;\n",
      "iter=131; mean(abs(feat))=12007.8;\n",
      "iter=132; mean(abs(feat))=16059.6;\n",
      "iter=133; mean(abs(feat))=1916;\n",
      "iter=134; mean(abs(feat))=6423.17;\n",
      "iter=135; mean(abs(feat))=13262.9;\n",
      "iter=136; mean(abs(feat))=371.671;\n",
      "iter=137; mean(abs(feat))=8652.97;\n",
      "iter=138; mean(abs(feat))=6255.46;\n",
      "iter=139; mean(abs(feat))=7674.45;\n",
      "iter=140; mean(abs(feat))=4836.04;\n",
      "iter=141; mean(abs(feat))=6584.43;\n",
      "iter=142; mean(abs(feat))=10136.2;\n",
      "iter=143; mean(abs(feat))=10309.8;\n",
      "iter=144; mean(abs(feat))=8236.66;\n",
      "iter=145; mean(abs(feat))=9950.23;\n",
      "iter=146; mean(abs(feat))=4813.25;\n",
      "iter=147; mean(abs(feat))=5855.2;\n",
      "iter=148; mean(abs(feat))=17329.2;\n",
      "iter=149; mean(abs(feat))=16729.1;\n",
      "iter=150; mean(abs(feat))=7888.56;\n",
      "iter=151; mean(abs(feat))=13515.8;\n",
      "iter=152; mean(abs(feat))=2843.91;\n",
      "iter=153; mean(abs(feat))=6395.02;\n",
      "iter=154; mean(abs(feat))=9213.04;\n",
      "iter=155; mean(abs(feat))=3383.7;\n",
      "iter=156; mean(abs(feat))=9654.61;\n",
      "iter=157; mean(abs(feat))=20411.5;\n",
      "iter=158; mean(abs(feat))=11433.3;\n",
      "iter=159; mean(abs(feat))=19443.7;\n",
      "iter=160; mean(abs(feat))=20328.4;\n",
      "iter=161; mean(abs(feat))=29297.7;\n",
      "iter=162; mean(abs(feat))=10142;\n",
      "iter=163; mean(abs(feat))=2558.41;\n",
      "iter=164; mean(abs(feat))=8573.71;\n",
      "iter=165; mean(abs(feat))=2868.84;\n",
      "iter=166; mean(abs(feat))=14128;\n",
      "iter=167; mean(abs(feat))=16619.5;\n",
      "iter=168; mean(abs(feat))=23149.4;\n",
      "iter=169; mean(abs(feat))=21056.8;\n",
      "iter=170; mean(abs(feat))=23228.9;\n",
      "iter=171; mean(abs(feat))=22673.9;\n",
      "iter=172; mean(abs(feat))=13477.9;\n",
      "iter=173; mean(abs(feat))=33435.5;\n",
      "iter=174; mean(abs(feat))=15930.6;\n",
      "iter=175; mean(abs(feat))=22546.2;\n",
      "iter=176; mean(abs(feat))=25934.5;\n",
      "iter=177; mean(abs(feat))=39108.1;\n",
      "iter=178; mean(abs(feat))=27460.2;\n",
      "iter=179; mean(abs(feat))=28735.9;\n",
      "iter=180; mean(abs(feat))=37187.9;\n",
      "iter=181; mean(abs(feat))=18088.1;\n",
      "iter=182; mean(abs(feat))=40834.1;\n",
      "iter=183; mean(abs(feat))=30687.4;\n",
      "iter=184; mean(abs(feat))=38427.1;\n",
      "iter=185; mean(abs(feat))=44677.8;\n",
      "iter=186; mean(abs(feat))=49890.9;\n",
      "iter=187; mean(abs(feat))=36935.3;\n",
      "iter=188; mean(abs(feat))=15343.7;\n",
      "iter=189; mean(abs(feat))=20117.2;\n",
      "iter=190; mean(abs(feat))=20894.2;\n",
      "iter=191; mean(abs(feat))=25645.2;\n",
      "iter=192; mean(abs(feat))=19360;\n",
      "iter=193; mean(abs(feat))=34966;\n",
      "iter=194; mean(abs(feat))=36389.9;\n",
      "iter=195; mean(abs(feat))=53007.4;\n",
      "iter=196; mean(abs(feat))=23483.8;\n",
      "iter=197; mean(abs(feat))=32474;\n",
      "iter=198; mean(abs(feat))=47448.3;\n",
      "iter=199; mean(abs(feat))=47618.7;\n",
      "iter=200; mean(abs(feat))=13666;\n"
     ]
    }
   ],
   "source": [
    "for channel in channel_list:\n",
    "    #\n",
    "    print('')\n",
    "    print('channel='+str(channel))\n",
    "    print('')\n",
    "    \n",
    "    # Instead to setting target channel, generate_preferred function also accepts feature mask, which\n",
    "    # The values of the mask array are binary, (1: target uint; 0: irrelevant unit) and whose shape is \n",
    "    # the same as that of target layer\n",
    "    \n",
    "    #create feature_mask\n",
    "    feature_mask = np.zeros(feat_shape)\n",
    "    # Only try to maximize the center of unit\n",
    "    feature_mask[0,channel, y_index, x_index] = 1.\n",
    "        \n",
    "    # activation maximization\n",
    "    preferred_stim = generate_preferred(net, target_layer_list, feature_mask=feature_mask, **opts)\n",
    "    # save the results\n",
    "    save_name = 'preferred_img' + '_layer_' + str(target_layer) + '_channel_' + str(channel) + '.npy'\n",
    "    np.save(os.path.join(save_path,save_name), preferred_stim)\n",
    "\n",
    "    save_name = 'preferred_img' + '_layer_' + str(target_layer) + '_channel_' + str(channel) + '.jpg'\n",
    "    # To better display the image, clip pixels with extreme values (0.02% of\n",
    "    # pixels with extreme low values and 0.02% of the pixels with extreme high\n",
    "    # values). And then normalise the image by mapping the pixel value to be\n",
    "    # within [0,255].\n",
    "    PIL.Image.fromarray(normalise_img(clip_extreme_pixel(preferred_stim, pct=0.04))).save(\n",
    "                    os.path.join(save_path, save_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
