{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module import\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import torch\n",
    "import torchvision\n",
    "                \n",
    "sys.path.append('../cnn_preferred')\n",
    "from utils import normalise_img, clip_extreme_pixel,  get_cnn_features, img_deprocess, get_target_feature_shape\n",
    "from activation_maximization import generate_preferred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load network\n",
    "net = torchvision.models.vgg19(pretrained=True)\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image mean and std for pre/de-process image for input network\n",
    "img_mean=np.array([0.485, 0.456, 0.406],dtype=np.float),\n",
    "img_std = np.array([0.229,0.224,0.225])\n",
    "\n",
    "# if the model input is for 0-1 range, norm = 255, elif 0-255, norm = 1\n",
    "norm = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create save_dir\n",
    "save_dir = '../result'\n",
    "save_folder = 'jupyter_demo_torch_simpleCNN_conv'\n",
    "save_folder = save_folder + '_' + datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "save_path = os.path.join(save_dir,save_folder)\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial image for the optimization\n",
    "h, w = 224,224\n",
    "initial_input = np.random.randint(0, 256, (h,w,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layer = \"features[2]\"\n",
    "target_layer = \"features[10]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target layer setting\n",
    "exec_str_list = [target_layer]\n",
    "## obtain target feature shape\n",
    "# transform input shape for torch avairable shape\n",
    "initial_torch_input = torch.Tensor(initial_input.transpose(2,0, 1)[np.newaxis])\n",
    "# obtain target layer activation \n",
    "feat_shape = get_target_feature_shape(net, initial_torch_input, exec_str_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 56, 56)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options\n",
    "opts = {\n",
    "    'img_mean': img_mean, # img_mean to preprocessing input image (the default is [0.485, 0.456, 0.406]) \n",
    "    'img_std': img_std,   # img_std to preprocessing input image  (the default is [0.229,0.224,0.225]) \n",
    "    'norm': norm,         # if the model input is for 0-1 range, norm = 255, elif 0-255, norm = 1 (defalt is 255)\n",
    "    \n",
    "    'iter_n': 200, # the total number of iterations for gradient descend (defalt is 200)\n",
    "\n",
    "    'disp_every': 1, # display the information on the terminal for every n iterations (default is 1)\n",
    "\n",
    "    'save_intermediate': True, # save the intermediate or not (default is None)\n",
    "    'save_intermediate_every': 10, # save the intermediate for every n iterations (default is 10)\n",
    "    'save_intermediate_path': save_path, # the path to save the intermediate (default is None)\n",
    "\n",
    "    'lr_start': 1., # learning rate (default is 1.)\n",
    "    'lr_end': 1.,   # we can change learning rate linearly setteing these two parameters \n",
    "\n",
    "    'momentum_start': 0.001, # gradient with momentum (default is 0.001)\n",
    "    'momentum_end': 0.001,   # we can change momentum linearly setteing these two parameters too \n",
    "\n",
    "    'decay_start': 0.001, # pixel decay for each iteration (default is 0.001)\n",
    "    'decay_end': 0.001,   # we can also change pixel decay linealy  \n",
    "\n",
    "    'image_blur': True, # Use image smoothing or not (default is True)\n",
    "    'sigma_start': 2.5, # the size of the gaussian filter for image smoothing (default is 2.5)\n",
    "    'sigma_end': 0.5,   \n",
    "\n",
    "    'image_jitter': True, # use image jittering during optimization (default is True)\n",
    "    'jitter_size': 4,     # the size of jitter (default is 32)\n",
    "    \n",
    "    'use_p_norm_reg': False, # use p_norm regularization (default is False)\n",
    "    'p': 2,\n",
    "\n",
    "    'use_TV_norm_reg': False, # use total variance norm (default is False)\n",
    "    'TVbeta1': 1,             # the order of  spatial domain\n",
    "    'TVbeta2':1.2,            # the order temporal domain (for video input)\n",
    "\n",
    "    'clip_small_norm': True,   # clip or not the pixels with extreme high or low value (default True) \n",
    "    'clip_small_norm_every': 1,\n",
    "    'n_pct_start': 5,\n",
    "    'n_pct_end': 5,\n",
    "\n",
    "    'clip_small_contribution': True, # clip or not the poxels with smal contribution norm of RGB channels\n",
    "    'clip_small_contribution_every': 1,\n",
    "    'c_pct_start': 5,\n",
    "    'c_pct_end':5,\n",
    "    \n",
    "    'initial_input': initial_input, # the initial image for the optimization (setting to None will use random noise as initial image)\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set channel index and center postion (for setting feature mask)\n",
    "channel_list = [14,56]\n",
    "y_index = int(feat_shape[2]/2)\n",
    "x_index = int(feat_shape[3]/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "channel=14\n",
      "\n",
      "iter=1; mean(abs(feat))=2.92657;\n",
      "iter=2; mean(abs(feat))=1098.65;\n",
      "iter=3; mean(abs(feat))=136.144;\n",
      "iter=4; mean(abs(feat))=863.489;\n",
      "iter=5; mean(abs(feat))=195.371;\n",
      "iter=6; mean(abs(feat))=910.724;\n",
      "iter=7; mean(abs(feat))=1620.39;\n",
      "iter=8; mean(abs(feat))=1059.04;\n",
      "iter=9; mean(abs(feat))=3080.9;\n",
      "iter=10; mean(abs(feat))=3885.07;\n",
      "iter=11; mean(abs(feat))=1914.79;\n",
      "iter=12; mean(abs(feat))=2960.41;\n",
      "iter=13; mean(abs(feat))=2530.98;\n",
      "iter=14; mean(abs(feat))=4043.27;\n",
      "iter=15; mean(abs(feat))=4022;\n",
      "iter=16; mean(abs(feat))=4747.41;\n",
      "iter=17; mean(abs(feat))=498.877;\n",
      "iter=18; mean(abs(feat))=1162.73;\n",
      "iter=19; mean(abs(feat))=3137.27;\n",
      "iter=20; mean(abs(feat))=2678.14;\n",
      "iter=21; mean(abs(feat))=355.895;\n",
      "iter=22; mean(abs(feat))=996.265;\n",
      "iter=23; mean(abs(feat))=1927.91;\n",
      "iter=24; mean(abs(feat))=142.08;\n",
      "iter=25; mean(abs(feat))=3189.11;\n",
      "iter=26; mean(abs(feat))=1857.26;\n",
      "iter=27; mean(abs(feat))=1308.52;\n",
      "iter=28; mean(abs(feat))=4303.65;\n",
      "iter=29; mean(abs(feat))=2952.85;\n",
      "iter=30; mean(abs(feat))=5394;\n",
      "iter=31; mean(abs(feat))=3224.26;\n",
      "iter=32; mean(abs(feat))=1912.18;\n",
      "iter=33; mean(abs(feat))=683.106;\n",
      "iter=34; mean(abs(feat))=2978.28;\n",
      "iter=35; mean(abs(feat))=510.705;\n",
      "iter=36; mean(abs(feat))=4253.71;\n",
      "iter=37; mean(abs(feat))=3427.64;\n",
      "iter=38; mean(abs(feat))=2292.64;\n",
      "iter=39; mean(abs(feat))=2493.3;\n",
      "iter=40; mean(abs(feat))=5477.25;\n",
      "iter=41; mean(abs(feat))=1117.21;\n",
      "iter=42; mean(abs(feat))=928.081;\n",
      "iter=43; mean(abs(feat))=154.871;\n",
      "iter=44; mean(abs(feat))=28.7841;\n",
      "iter=45; mean(abs(feat))=1366.68;\n",
      "iter=46; mean(abs(feat))=1186.09;\n",
      "iter=47; mean(abs(feat))=3520.29;\n",
      "iter=48; mean(abs(feat))=665.741;\n",
      "iter=49; mean(abs(feat))=4470.42;\n",
      "iter=50; mean(abs(feat))=3553.39;\n",
      "iter=51; mean(abs(feat))=2960.37;\n",
      "iter=52; mean(abs(feat))=2356.16;\n",
      "iter=53; mean(abs(feat))=1241.8;\n",
      "iter=54; mean(abs(feat))=5035.73;\n",
      "iter=55; mean(abs(feat))=1595.57;\n",
      "iter=56; mean(abs(feat))=2108.66;\n",
      "iter=57; mean(abs(feat))=2006.92;\n",
      "iter=58; mean(abs(feat))=3.05087;\n",
      "iter=59; mean(abs(feat))=1835.17;\n",
      "iter=60; mean(abs(feat))=4772.21;\n",
      "iter=61; mean(abs(feat))=3752.44;\n",
      "iter=62; mean(abs(feat))=343.535;\n",
      "iter=63; mean(abs(feat))=5682.75;\n",
      "iter=64; mean(abs(feat))=5575.32;\n",
      "iter=65; mean(abs(feat))=1207.24;\n",
      "iter=66; mean(abs(feat))=2831.49;\n",
      "iter=67; mean(abs(feat))=4328.86;\n",
      "iter=68; mean(abs(feat))=5179.76;\n",
      "iter=69; mean(abs(feat))=8711.47;\n",
      "iter=70; mean(abs(feat))=10192.3;\n",
      "iter=71; mean(abs(feat))=2714.94;\n",
      "iter=72; mean(abs(feat))=1519.74;\n",
      "iter=73; mean(abs(feat))=1209.17;\n",
      "iter=74; mean(abs(feat))=1340.26;\n",
      "iter=75; mean(abs(feat))=235.016;\n",
      "iter=76; mean(abs(feat))=1378.66;\n",
      "iter=77; mean(abs(feat))=960.549;\n",
      "iter=78; mean(abs(feat))=4894.46;\n",
      "iter=79; mean(abs(feat))=7776.55;\n",
      "iter=80; mean(abs(feat))=1587.16;\n",
      "iter=81; mean(abs(feat))=2490.67;\n",
      "iter=82; mean(abs(feat))=2651.76;\n",
      "iter=83; mean(abs(feat))=3161.29;\n",
      "iter=84; mean(abs(feat))=6178.05;\n",
      "iter=85; mean(abs(feat))=952.016;\n",
      "iter=86; mean(abs(feat))=5701.31;\n",
      "iter=87; mean(abs(feat))=3411.88;\n",
      "iter=88; mean(abs(feat))=1167.5;\n",
      "iter=89; mean(abs(feat))=7658.34;\n",
      "iter=90; mean(abs(feat))=10289.5;\n",
      "iter=91; mean(abs(feat))=10985.2;\n",
      "iter=92; mean(abs(feat))=6924.98;\n",
      "iter=93; mean(abs(feat))=1653.04;\n",
      "iter=94; mean(abs(feat))=9431.83;\n",
      "iter=95; mean(abs(feat))=9351.86;\n",
      "iter=96; mean(abs(feat))=2494.38;\n",
      "iter=97; mean(abs(feat))=3215.77;\n",
      "iter=98; mean(abs(feat))=5316.65;\n",
      "iter=99; mean(abs(feat))=8322.91;\n",
      "iter=100; mean(abs(feat))=4464.24;\n",
      "iter=101; mean(abs(feat))=5413.87;\n",
      "iter=102; mean(abs(feat))=8325.23;\n",
      "iter=103; mean(abs(feat))=11599.1;\n",
      "iter=104; mean(abs(feat))=8977.4;\n",
      "iter=105; mean(abs(feat))=2701.4;\n",
      "iter=106; mean(abs(feat))=2171.17;\n",
      "iter=107; mean(abs(feat))=6838.14;\n",
      "iter=108; mean(abs(feat))=1467.98;\n",
      "iter=109; mean(abs(feat))=3352.42;\n",
      "iter=110; mean(abs(feat))=5658.91;\n",
      "iter=111; mean(abs(feat))=107.508;\n",
      "iter=112; mean(abs(feat))=2494.48;\n",
      "iter=113; mean(abs(feat))=8354.54;\n",
      "iter=114; mean(abs(feat))=9048.11;\n",
      "iter=115; mean(abs(feat))=2634.73;\n",
      "iter=116; mean(abs(feat))=7794.93;\n",
      "iter=117; mean(abs(feat))=12298.7;\n",
      "iter=118; mean(abs(feat))=14585.6;\n",
      "iter=119; mean(abs(feat))=3052.58;\n",
      "iter=120; mean(abs(feat))=6353.21;\n",
      "iter=121; mean(abs(feat))=15164.4;\n",
      "iter=122; mean(abs(feat))=13048.8;\n",
      "iter=123; mean(abs(feat))=16019.9;\n",
      "iter=124; mean(abs(feat))=14242;\n",
      "iter=125; mean(abs(feat))=2524.22;\n",
      "iter=126; mean(abs(feat))=1070.34;\n",
      "iter=127; mean(abs(feat))=3237.62;\n",
      "iter=128; mean(abs(feat))=5350.92;\n",
      "iter=129; mean(abs(feat))=18213.3;\n",
      "iter=130; mean(abs(feat))=738.862;\n",
      "iter=131; mean(abs(feat))=7893.37;\n",
      "iter=132; mean(abs(feat))=2593.42;\n",
      "iter=133; mean(abs(feat))=12975.3;\n",
      "iter=134; mean(abs(feat))=6741;\n",
      "iter=135; mean(abs(feat))=7975.67;\n",
      "iter=136; mean(abs(feat))=7574.57;\n",
      "iter=137; mean(abs(feat))=16320.2;\n",
      "iter=138; mean(abs(feat))=14392;\n",
      "iter=139; mean(abs(feat))=20606.6;\n",
      "iter=140; mean(abs(feat))=13208.2;\n",
      "iter=141; mean(abs(feat))=23651.8;\n",
      "iter=142; mean(abs(feat))=32124.5;\n",
      "iter=143; mean(abs(feat))=22850.4;\n",
      "iter=144; mean(abs(feat))=877.014;\n",
      "iter=145; mean(abs(feat))=16095.4;\n",
      "iter=146; mean(abs(feat))=18949.1;\n",
      "iter=147; mean(abs(feat))=22024.4;\n",
      "iter=148; mean(abs(feat))=18797.7;\n",
      "iter=149; mean(abs(feat))=11216.4;\n",
      "iter=150; mean(abs(feat))=6595.91;\n",
      "iter=151; mean(abs(feat))=4523.75;\n",
      "iter=152; mean(abs(feat))=4794.78;\n",
      "iter=153; mean(abs(feat))=17824.8;\n",
      "iter=154; mean(abs(feat))=10118.5;\n",
      "iter=155; mean(abs(feat))=8325.71;\n",
      "iter=156; mean(abs(feat))=332.335;\n",
      "iter=157; mean(abs(feat))=6210.7;\n",
      "iter=158; mean(abs(feat))=15737;\n",
      "iter=159; mean(abs(feat))=16812.8;\n",
      "iter=160; mean(abs(feat))=17407.2;\n",
      "iter=161; mean(abs(feat))=27122.6;\n",
      "iter=162; mean(abs(feat))=31338.1;\n",
      "iter=163; mean(abs(feat))=3848.41;\n",
      "iter=164; mean(abs(feat))=13434.9;\n",
      "iter=165; mean(abs(feat))=14950.7;\n",
      "iter=166; mean(abs(feat))=9996.77;\n",
      "iter=167; mean(abs(feat))=7912.15;\n",
      "iter=168; mean(abs(feat))=12659.9;\n",
      "iter=169; mean(abs(feat))=21591;\n",
      "iter=170; mean(abs(feat))=20247.3;\n",
      "iter=171; mean(abs(feat))=1989.09;\n",
      "iter=172; mean(abs(feat))=6963.44;\n",
      "iter=173; mean(abs(feat))=198.268;\n",
      "iter=174; mean(abs(feat))=12940;\n",
      "iter=175; mean(abs(feat))=8358.94;\n",
      "iter=176; mean(abs(feat))=11147.7;\n",
      "iter=177; mean(abs(feat))=14415.6;\n",
      "iter=178; mean(abs(feat))=16103.2;\n",
      "iter=179; mean(abs(feat))=25670.8;\n",
      "iter=180; mean(abs(feat))=41344.7;\n",
      "iter=181; mean(abs(feat))=25057.8;\n",
      "iter=182; mean(abs(feat))=5008.92;\n",
      "iter=183; mean(abs(feat))=139.928;\n",
      "iter=184; mean(abs(feat))=29378.3;\n",
      "iter=185; mean(abs(feat))=32782.3;\n",
      "iter=186; mean(abs(feat))=48250.8;\n",
      "iter=187; mean(abs(feat))=4606.65;\n",
      "iter=188; mean(abs(feat))=24738.9;\n",
      "iter=189; mean(abs(feat))=6742.67;\n",
      "iter=190; mean(abs(feat))=8075.38;\n",
      "iter=191; mean(abs(feat))=34929.1;\n",
      "iter=192; mean(abs(feat))=24404;\n",
      "iter=193; mean(abs(feat))=37240.3;\n",
      "iter=194; mean(abs(feat))=39013.2;\n",
      "iter=195; mean(abs(feat))=50040.3;\n",
      "iter=196; mean(abs(feat))=8465.54;\n",
      "iter=197; mean(abs(feat))=17134.1;\n",
      "iter=198; mean(abs(feat))=31539.2;\n",
      "iter=199; mean(abs(feat))=53994.3;\n",
      "iter=200; mean(abs(feat))=40428.8;\n",
      "\n",
      "channel=56\n",
      "\n",
      "iter=1; mean(abs(feat))=5.42997;\n",
      "iter=2; mean(abs(feat))=801.828;\n",
      "iter=3; mean(abs(feat))=2355.77;\n",
      "iter=4; mean(abs(feat))=208.312;\n",
      "iter=5; mean(abs(feat))=1079.39;\n",
      "iter=6; mean(abs(feat))=1825.02;\n",
      "iter=7; mean(abs(feat))=391.725;\n",
      "iter=8; mean(abs(feat))=3676.23;\n",
      "iter=9; mean(abs(feat))=640.113;\n",
      "iter=10; mean(abs(feat))=1849.02;\n",
      "iter=11; mean(abs(feat))=1349.39;\n",
      "iter=12; mean(abs(feat))=1251.16;\n",
      "iter=13; mean(abs(feat))=1542.84;\n",
      "iter=14; mean(abs(feat))=1496.97;\n",
      "iter=15; mean(abs(feat))=1724.13;\n",
      "iter=16; mean(abs(feat))=261.095;\n",
      "iter=17; mean(abs(feat))=1064.12;\n",
      "iter=18; mean(abs(feat))=2343.66;\n",
      "iter=19; mean(abs(feat))=2626.51;\n",
      "iter=20; mean(abs(feat))=334.479;\n",
      "iter=21; mean(abs(feat))=2182.09;\n",
      "iter=22; mean(abs(feat))=997.796;\n",
      "iter=23; mean(abs(feat))=976.187;\n",
      "iter=24; mean(abs(feat))=1693.1;\n",
      "iter=25; mean(abs(feat))=1297.05;\n",
      "iter=26; mean(abs(feat))=3823.99;\n",
      "iter=27; mean(abs(feat))=842.412;\n",
      "iter=28; mean(abs(feat))=218.403;\n",
      "iter=29; mean(abs(feat))=341.878;\n",
      "iter=30; mean(abs(feat))=84.79;\n",
      "iter=31; mean(abs(feat))=202.647;\n",
      "iter=32; mean(abs(feat))=34.1657;\n",
      "iter=33; mean(abs(feat))=1312.83;\n",
      "iter=34; mean(abs(feat))=3803.21;\n",
      "iter=35; mean(abs(feat))=365.752;\n",
      "iter=36; mean(abs(feat))=54.0395;\n",
      "iter=37; mean(abs(feat))=1413.74;\n",
      "iter=38; mean(abs(feat))=4423.99;\n",
      "iter=39; mean(abs(feat))=5052.91;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=40; mean(abs(feat))=4207.56;\n",
      "iter=41; mean(abs(feat))=37.8559;\n",
      "iter=42; mean(abs(feat))=3717.15;\n",
      "iter=43; mean(abs(feat))=3411.84;\n",
      "iter=44; mean(abs(feat))=4056.09;\n",
      "iter=45; mean(abs(feat))=4709.8;\n",
      "iter=46; mean(abs(feat))=2849.47;\n",
      "iter=47; mean(abs(feat))=755.085;\n",
      "iter=48; mean(abs(feat))=2342.39;\n",
      "iter=49; mean(abs(feat))=3013.83;\n",
      "iter=50; mean(abs(feat))=5127.58;\n",
      "iter=51; mean(abs(feat))=3379.27;\n",
      "iter=52; mean(abs(feat))=982.992;\n",
      "iter=53; mean(abs(feat))=598.288;\n",
      "iter=54; mean(abs(feat))=1997.14;\n",
      "iter=55; mean(abs(feat))=1255.25;\n",
      "iter=56; mean(abs(feat))=2657.99;\n",
      "iter=57; mean(abs(feat))=1083.29;\n",
      "iter=58; mean(abs(feat))=2317.17;\n",
      "iter=59; mean(abs(feat))=1047.89;\n",
      "iter=60; mean(abs(feat))=3101.8;\n",
      "iter=61; mean(abs(feat))=2907.18;\n",
      "iter=62; mean(abs(feat))=6405.22;\n",
      "iter=63; mean(abs(feat))=3908.75;\n",
      "iter=64; mean(abs(feat))=1517.66;\n",
      "iter=65; mean(abs(feat))=3878.66;\n",
      "iter=66; mean(abs(feat))=4657.07;\n",
      "iter=67; mean(abs(feat))=1604.66;\n",
      "iter=68; mean(abs(feat))=3359.98;\n",
      "iter=69; mean(abs(feat))=59.066;\n",
      "iter=70; mean(abs(feat))=6053.54;\n",
      "iter=71; mean(abs(feat))=2341.58;\n",
      "iter=72; mean(abs(feat))=3091.3;\n",
      "iter=73; mean(abs(feat))=4798.44;\n",
      "iter=74; mean(abs(feat))=9470.4;\n",
      "iter=75; mean(abs(feat))=3692.41;\n",
      "iter=76; mean(abs(feat))=7286.45;\n",
      "iter=77; mean(abs(feat))=5504.87;\n",
      "iter=78; mean(abs(feat))=588.297;\n",
      "iter=79; mean(abs(feat))=4223.9;\n",
      "iter=80; mean(abs(feat))=4149.75;\n",
      "iter=81; mean(abs(feat))=10101.8;\n",
      "iter=82; mean(abs(feat))=2161.29;\n",
      "iter=83; mean(abs(feat))=7372.72;\n",
      "iter=84; mean(abs(feat))=357.869;\n",
      "iter=85; mean(abs(feat))=6400.63;\n",
      "iter=86; mean(abs(feat))=3573.94;\n",
      "iter=87; mean(abs(feat))=4154.69;\n",
      "iter=88; mean(abs(feat))=6691.66;\n",
      "iter=89; mean(abs(feat))=670.04;\n",
      "iter=90; mean(abs(feat))=1037.45;\n",
      "iter=91; mean(abs(feat))=3863.07;\n",
      "iter=92; mean(abs(feat))=1608;\n",
      "iter=93; mean(abs(feat))=1630.67;\n",
      "iter=94; mean(abs(feat))=1798.45;\n",
      "iter=95; mean(abs(feat))=3148.43;\n",
      "iter=96; mean(abs(feat))=4967.91;\n",
      "iter=97; mean(abs(feat))=2040.73;\n",
      "iter=98; mean(abs(feat))=5593.58;\n",
      "iter=99; mean(abs(feat))=998.489;\n",
      "iter=100; mean(abs(feat))=4586.03;\n",
      "iter=101; mean(abs(feat))=5095;\n",
      "iter=102; mean(abs(feat))=4727.6;\n",
      "iter=103; mean(abs(feat))=7309.49;\n",
      "iter=104; mean(abs(feat))=5191.12;\n",
      "iter=105; mean(abs(feat))=3287.02;\n",
      "iter=106; mean(abs(feat))=431.398;\n",
      "iter=107; mean(abs(feat))=5566.5;\n",
      "iter=108; mean(abs(feat))=2027.46;\n",
      "iter=109; mean(abs(feat))=8172.23;\n",
      "iter=110; mean(abs(feat))=3723.27;\n",
      "iter=111; mean(abs(feat))=11470;\n",
      "iter=112; mean(abs(feat))=12354.3;\n",
      "iter=113; mean(abs(feat))=8533.17;\n",
      "iter=114; mean(abs(feat))=3211.5;\n",
      "iter=115; mean(abs(feat))=8184.34;\n",
      "iter=116; mean(abs(feat))=4924.16;\n",
      "iter=117; mean(abs(feat))=7001.72;\n",
      "iter=118; mean(abs(feat))=8294.61;\n",
      "iter=119; mean(abs(feat))=2929.43;\n",
      "iter=120; mean(abs(feat))=5942.15;\n",
      "iter=121; mean(abs(feat))=8391.84;\n",
      "iter=122; mean(abs(feat))=9262.35;\n",
      "iter=123; mean(abs(feat))=5547.31;\n",
      "iter=124; mean(abs(feat))=8250.92;\n",
      "iter=125; mean(abs(feat))=563.599;\n",
      "iter=126; mean(abs(feat))=524.742;\n",
      "iter=127; mean(abs(feat))=5228.35;\n",
      "iter=128; mean(abs(feat))=7893.47;\n",
      "iter=129; mean(abs(feat))=15165.5;\n",
      "iter=130; mean(abs(feat))=21444.6;\n",
      "iter=131; mean(abs(feat))=7195.74;\n",
      "iter=132; mean(abs(feat))=16588.8;\n",
      "iter=133; mean(abs(feat))=12677.9;\n",
      "iter=134; mean(abs(feat))=5580.45;\n",
      "iter=135; mean(abs(feat))=10260.4;\n",
      "iter=136; mean(abs(feat))=12626.3;\n",
      "iter=137; mean(abs(feat))=8747.65;\n",
      "iter=138; mean(abs(feat))=13144.5;\n",
      "iter=139; mean(abs(feat))=12382.5;\n",
      "iter=140; mean(abs(feat))=11393.4;\n",
      "iter=141; mean(abs(feat))=16648;\n",
      "iter=142; mean(abs(feat))=5454.95;\n",
      "iter=143; mean(abs(feat))=6430.66;\n",
      "iter=144; mean(abs(feat))=17032.2;\n",
      "iter=145; mean(abs(feat))=10819.1;\n",
      "iter=146; mean(abs(feat))=20985.1;\n",
      "iter=147; mean(abs(feat))=29816.5;\n",
      "iter=148; mean(abs(feat))=14148.8;\n",
      "iter=149; mean(abs(feat))=7623.78;\n",
      "iter=150; mean(abs(feat))=1951.64;\n",
      "iter=151; mean(abs(feat))=17504.5;\n",
      "iter=152; mean(abs(feat))=11536.1;\n",
      "iter=153; mean(abs(feat))=26663.8;\n",
      "iter=154; mean(abs(feat))=9356.09;\n",
      "iter=155; mean(abs(feat))=20054.7;\n",
      "iter=156; mean(abs(feat))=10259.2;\n",
      "iter=157; mean(abs(feat))=4964.79;\n",
      "iter=158; mean(abs(feat))=9361.5;\n",
      "iter=159; mean(abs(feat))=14928.5;\n",
      "iter=160; mean(abs(feat))=1866.1;\n",
      "iter=161; mean(abs(feat))=12920.2;\n",
      "iter=162; mean(abs(feat))=7509;\n",
      "iter=163; mean(abs(feat))=19115.1;\n",
      "iter=164; mean(abs(feat))=578.671;\n",
      "iter=165; mean(abs(feat))=12302.9;\n",
      "iter=166; mean(abs(feat))=12576.8;\n",
      "iter=167; mean(abs(feat))=9167.66;\n",
      "iter=168; mean(abs(feat))=9858.97;\n",
      "iter=169; mean(abs(feat))=17555.9;\n",
      "iter=170; mean(abs(feat))=24069.2;\n",
      "iter=171; mean(abs(feat))=36402.6;\n",
      "iter=172; mean(abs(feat))=28522.7;\n",
      "iter=173; mean(abs(feat))=26319.1;\n",
      "iter=174; mean(abs(feat))=28930.3;\n",
      "iter=175; mean(abs(feat))=33185.3;\n",
      "iter=176; mean(abs(feat))=24620.5;\n",
      "iter=177; mean(abs(feat))=23345.9;\n",
      "iter=178; mean(abs(feat))=23848.1;\n",
      "iter=179; mean(abs(feat))=23752;\n",
      "iter=180; mean(abs(feat))=42999;\n",
      "iter=181; mean(abs(feat))=28623.7;\n",
      "iter=182; mean(abs(feat))=22104.4;\n",
      "iter=183; mean(abs(feat))=8693.93;\n",
      "iter=184; mean(abs(feat))=34885.8;\n",
      "iter=185; mean(abs(feat))=18574.2;\n",
      "iter=186; mean(abs(feat))=36971.7;\n",
      "iter=187; mean(abs(feat))=34841.6;\n",
      "iter=188; mean(abs(feat))=19862.3;\n",
      "iter=189; mean(abs(feat))=28643;\n",
      "iter=190; mean(abs(feat))=22530.7;\n",
      "iter=191; mean(abs(feat))=25524.2;\n",
      "iter=192; mean(abs(feat))=26103.1;\n",
      "iter=193; mean(abs(feat))=22737.7;\n",
      "iter=194; mean(abs(feat))=57406.2;\n",
      "iter=195; mean(abs(feat))=20357.6;\n",
      "iter=196; mean(abs(feat))=42965.2;\n",
      "iter=197; mean(abs(feat))=62813.3;\n",
      "iter=198; mean(abs(feat))=76599.3;\n",
      "iter=199; mean(abs(feat))=15385.7;\n",
      "iter=200; mean(abs(feat))=35005.7;\n"
     ]
    }
   ],
   "source": [
    "for channel in channel_list:\n",
    "    #\n",
    "    print('')\n",
    "    print('channel='+str(channel))\n",
    "    print('')\n",
    "    \n",
    "    # Instead to setting target channel, generate_preferred function also accepts feature mask, which\n",
    "    # The values of the mask array are binary, (1: target uint; 0: irrelevant unit) and whose shape is \n",
    "    # the same as that of target layer\n",
    "    \n",
    "    #create feature_mask\n",
    "    feature_mask = np.zeros(feat_shape)\n",
    "    # Only try to maximize the center of unit\n",
    "    feature_mask[0,channel, y_index, x_index] = 1.\n",
    "        \n",
    "    # activation maximization\n",
    "    preferred_stim = generate_preferred(net, exec_str_list, feature_mask=feature_mask, **opts)\n",
    "    # save the results\n",
    "    save_name = 'preferred_img' + '_layer_' + str(target_layer) + '_channel_' + str(channel) + '.npy'\n",
    "    np.save(os.path.join(save_path,save_name), preferred_stim)\n",
    "\n",
    "    save_name = 'preferred_img' + '_layer_' + str(target_layer) + '_channel_' + str(channel) + '.jpg'\n",
    "    # To better display the image, clip pixels with extreme values (0.02% of\n",
    "    # pixels with extreme low values and 0.02% of the pixels with extreme high\n",
    "    # values). And then normalise the image by mapping the pixel value to be\n",
    "    # within [0,255].\n",
    "    PIL.Image.fromarray(normalise_img(clip_extreme_pixel(preferred_stim, pct=0.04))).save(\n",
    "                    os.path.join(save_path, save_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
