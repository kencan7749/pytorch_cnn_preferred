{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# module import\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import torch\n",
    "import torchvision\n",
    "                \n",
    "sys.path.append('../cnn_preferred')\n",
    "from utils import normalise_img, clip_extreme_pixel, save_video, normalise_vid, get_cnn_features, img_deprocess, get_target_feature_shape\n",
    "from activation_maximization import generate_preferred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network load\n",
    "net = torchvision.models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image mean and std for pre/de-process image for input network\n",
    "img_mean=np.array([0.485, 0.456, 0.406],dtype=np.float),\n",
    "img_std = np.array([0.229,0.224,0.225])\n",
    "\n",
    "# if the model input is for 0-1 range, norm = 255, elif 0-255, norm = 1\n",
    "norm = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_dir\n",
    "save_dir = '../result'\n",
    "save_folder = 'jupyter_demo_torch_simpleCNN_conv'\n",
    "save_folder = save_folder + '_' + datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "save_path = os.path.join(save_dir,save_folder)\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial image for the optimization\n",
    "h, w = 224,224\n",
    "initial_input = np.random.randint(0, 256, (h,w,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layer = \"features[8]\"\n",
    "target_layer = \"features[10]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target layer setting\n",
    "exec_str_list = [target_layer]\n",
    "## obtain target feature shape\n",
    "# transform input shape for torch avairable shape\n",
    "initial_torch_input = torch.Tensor(initial_input.transpose(2,0, 1)[np.newaxis])\n",
    "# obtain target layer activation \n",
    "feat_shape = get_target_feature_shape(net, initial_torch_input, exec_str_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options\n",
    "opts = {\n",
    "    'img_mean': img_mean, # img_mean to preprocessing input image (the default is [0.485, 0.456, 0.406]) \n",
    "    'img_std': img_std,   # img_std to preprocessing input image  (the default is [0.229,0.224,0.225]) \n",
    "    'norm': norm,         # if the model input is for 0-1 range, norm = 255, elif 0-255, norm = 1 (defalt is 255)\n",
    "    \n",
    "    'iter_n': 200, # the total number of iterations for gradient descend (defalt is 200)\n",
    "\n",
    "    'disp_every': 1, # display the information on the terminal for every n iterations (default is 1)\n",
    "\n",
    "    'save_intermediate': True, # save the intermediate or not (default is None)\n",
    "    'save_intermediate_every': 10, # save the intermediate for every n iterations (default is 10)\n",
    "    'save_intermediate_path': save_path, # the path to save the intermediate (default is None)\n",
    "\n",
    "    'lr_start': 1., # learning rate (default is 1.)\n",
    "    'lr_end': 1.,   # we can change learning rate linearly setteing these two parameters \n",
    "\n",
    "    'momentum_start': 0.001, # gradient with momentum (default is 0.001)\n",
    "    'momentum_end': 0.001,   # we can change momentum linearly setteing these two parameters too \n",
    "\n",
    "    'decay_start': 0.001, # pixel decay for each iteration (default is 0.001)\n",
    "    'decay_end': 0.001,   # we can also change pixel decay linealy  \n",
    "\n",
    "    'image_blur': True, # Use image smoothing or not (default is True)\n",
    "    'sigma_start': 2.5, # the size of the gaussian filter for image smoothing (default is 2.5)\n",
    "    'sigma_end': 0.5,   \n",
    "\n",
    "    'image_jitter': True, # use image jittering during optimization (default is True)\n",
    "    'jitter_size': 4,     # the size of jitter (default is 32)\n",
    "    \n",
    "    'use_p_norm_reg': False, # use p_norm regularization (default is False)\n",
    "    'p': 2,\n",
    "\n",
    "    'use_TV_norm_reg': False, # use total variance norm (default is False)\n",
    "    'TVbeta1': 1,             # the order of  spatial domain\n",
    "    'TVbeta2':1.2,            # the order temporal domain (for video input)\n",
    "\n",
    "    'clip_small_norm': True,   # clip or not the pixels with extreme high or low value (default True) \n",
    "    'clip_small_norm_every': 1,\n",
    "    'n_pct_start': 5,\n",
    "    'n_pct_end': 5,\n",
    "\n",
    "    'clip_small_contribution': True, # clip or not the poxels with smal contribution norm of RGB channels\n",
    "    'clip_small_contribution_every': 1,\n",
    "    'c_pct_start': 5,\n",
    "    'c_pct_end':5,\n",
    "    \n",
    "    'input_size': (224,224,3),\n",
    "    'initial_input': initial_input, # the initial image for the optimization (setting to None will use random noise as initial image)\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_list = [14,56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "channel=14\n",
      "\n",
      "iter=1; mean(abs(feat))=4.70402;\n",
      "iter=2; mean(abs(feat))=16.5821;\n",
      "iter=3; mean(abs(feat))=18.0405;\n",
      "iter=4; mean(abs(feat))=14.6219;\n",
      "iter=5; mean(abs(feat))=1.6333;\n",
      "iter=6; mean(abs(feat))=29.4826;\n",
      "iter=7; mean(abs(feat))=56.1883;\n",
      "iter=8; mean(abs(feat))=8.13925;\n",
      "iter=9; mean(abs(feat))=25.4075;\n",
      "iter=10; mean(abs(feat))=23.2243;\n",
      "iter=11; mean(abs(feat))=18.4643;\n",
      "iter=12; mean(abs(feat))=47.6797;\n",
      "iter=13; mean(abs(feat))=52.1476;\n",
      "iter=14; mean(abs(feat))=81.0078;\n",
      "iter=15; mean(abs(feat))=87.2539;\n",
      "iter=16; mean(abs(feat))=66.9968;\n",
      "iter=17; mean(abs(feat))=130.678;\n",
      "iter=18; mean(abs(feat))=60.7477;\n",
      "iter=19; mean(abs(feat))=100.525;\n",
      "iter=20; mean(abs(feat))=141.018;\n",
      "iter=21; mean(abs(feat))=101.869;\n",
      "iter=22; mean(abs(feat))=108.077;\n",
      "iter=23; mean(abs(feat))=144.94;\n",
      "iter=24; mean(abs(feat))=89.3926;\n",
      "iter=25; mean(abs(feat))=175.798;\n",
      "iter=26; mean(abs(feat))=174.166;\n",
      "iter=27; mean(abs(feat))=180.347;\n",
      "iter=28; mean(abs(feat))=170.286;\n",
      "iter=29; mean(abs(feat))=187.793;\n",
      "iter=30; mean(abs(feat))=223.669;\n",
      "iter=31; mean(abs(feat))=249.913;\n",
      "iter=32; mean(abs(feat))=233.739;\n",
      "iter=33; mean(abs(feat))=175.376;\n",
      "iter=34; mean(abs(feat))=200.66;\n",
      "iter=35; mean(abs(feat))=168.421;\n",
      "iter=36; mean(abs(feat))=213.412;\n",
      "iter=37; mean(abs(feat))=217.597;\n",
      "iter=38; mean(abs(feat))=194.414;\n",
      "iter=39; mean(abs(feat))=245.625;\n",
      "iter=40; mean(abs(feat))=254.887;\n",
      "iter=41; mean(abs(feat))=258.83;\n",
      "iter=42; mean(abs(feat))=262.863;\n",
      "iter=43; mean(abs(feat))=291.508;\n",
      "iter=44; mean(abs(feat))=278.065;\n",
      "iter=45; mean(abs(feat))=242.361;\n",
      "iter=46; mean(abs(feat))=287.397;\n",
      "iter=47; mean(abs(feat))=292.964;\n",
      "iter=48; mean(abs(feat))=297.359;\n",
      "iter=49; mean(abs(feat))=303.344;\n",
      "iter=50; mean(abs(feat))=254.385;\n",
      "iter=51; mean(abs(feat))=377.846;\n",
      "iter=52; mean(abs(feat))=353.743;\n",
      "iter=53; mean(abs(feat))=349.07;\n",
      "iter=54; mean(abs(feat))=315.964;\n",
      "iter=55; mean(abs(feat))=389.843;\n",
      "iter=56; mean(abs(feat))=371.063;\n",
      "iter=57; mean(abs(feat))=459.583;\n",
      "iter=58; mean(abs(feat))=368.991;\n",
      "iter=59; mean(abs(feat))=415.036;\n",
      "iter=60; mean(abs(feat))=339.965;\n",
      "iter=61; mean(abs(feat))=388.653;\n",
      "iter=62; mean(abs(feat))=377.226;\n",
      "iter=63; mean(abs(feat))=363.718;\n",
      "iter=64; mean(abs(feat))=430.003;\n",
      "iter=65; mean(abs(feat))=499.215;\n",
      "iter=66; mean(abs(feat))=445.674;\n",
      "iter=67; mean(abs(feat))=540.433;\n",
      "iter=68; mean(abs(feat))=447.72;\n",
      "iter=69; mean(abs(feat))=496.81;\n",
      "iter=70; mean(abs(feat))=476.25;\n",
      "iter=71; mean(abs(feat))=578.049;\n",
      "iter=72; mean(abs(feat))=470.315;\n",
      "iter=73; mean(abs(feat))=447.915;\n",
      "iter=74; mean(abs(feat))=498.643;\n",
      "iter=75; mean(abs(feat))=546.599;\n",
      "iter=76; mean(abs(feat))=541.79;\n",
      "iter=77; mean(abs(feat))=541.544;\n",
      "iter=78; mean(abs(feat))=523.357;\n",
      "iter=79; mean(abs(feat))=458.341;\n",
      "iter=80; mean(abs(feat))=529.541;\n",
      "iter=81; mean(abs(feat))=673.728;\n",
      "iter=82; mean(abs(feat))=649.617;\n",
      "iter=83; mean(abs(feat))=520.686;\n",
      "iter=84; mean(abs(feat))=579.244;\n",
      "iter=85; mean(abs(feat))=518.252;\n",
      "iter=86; mean(abs(feat))=561.745;\n",
      "iter=87; mean(abs(feat))=583.234;\n",
      "iter=88; mean(abs(feat))=607.944;\n",
      "iter=89; mean(abs(feat))=661.516;\n",
      "iter=90; mean(abs(feat))=721.467;\n",
      "iter=91; mean(abs(feat))=620.831;\n",
      "iter=92; mean(abs(feat))=606.355;\n",
      "iter=93; mean(abs(feat))=609.525;\n",
      "iter=94; mean(abs(feat))=668.185;\n",
      "iter=95; mean(abs(feat))=678.586;\n",
      "iter=96; mean(abs(feat))=652.647;\n",
      "iter=97; mean(abs(feat))=703.502;\n",
      "iter=98; mean(abs(feat))=582.043;\n",
      "iter=99; mean(abs(feat))=764.123;\n",
      "iter=100; mean(abs(feat))=791.303;\n",
      "iter=101; mean(abs(feat))=817.189;\n",
      "iter=102; mean(abs(feat))=732.724;\n",
      "iter=103; mean(abs(feat))=773.178;\n",
      "iter=104; mean(abs(feat))=824.774;\n",
      "iter=105; mean(abs(feat))=995.79;\n",
      "iter=106; mean(abs(feat))=870.362;\n",
      "iter=107; mean(abs(feat))=865.553;\n",
      "iter=108; mean(abs(feat))=805.53;\n",
      "iter=109; mean(abs(feat))=966.023;\n",
      "iter=110; mean(abs(feat))=918.4;\n",
      "iter=111; mean(abs(feat))=982.964;\n",
      "iter=112; mean(abs(feat))=1001.37;\n",
      "iter=113; mean(abs(feat))=933.589;\n",
      "iter=114; mean(abs(feat))=1096.57;\n",
      "iter=115; mean(abs(feat))=1101.71;\n",
      "iter=116; mean(abs(feat))=1031.81;\n",
      "iter=117; mean(abs(feat))=1187.36;\n",
      "iter=118; mean(abs(feat))=992.511;\n",
      "iter=119; mean(abs(feat))=1047.8;\n",
      "iter=120; mean(abs(feat))=1167.24;\n",
      "iter=121; mean(abs(feat))=1183.47;\n",
      "iter=122; mean(abs(feat))=1109.46;\n",
      "iter=123; mean(abs(feat))=891.345;\n",
      "iter=124; mean(abs(feat))=1143.51;\n",
      "iter=125; mean(abs(feat))=1290.16;\n",
      "iter=126; mean(abs(feat))=1099.59;\n",
      "iter=127; mean(abs(feat))=1216.11;\n",
      "iter=128; mean(abs(feat))=1248.52;\n",
      "iter=129; mean(abs(feat))=1339.18;\n",
      "iter=130; mean(abs(feat))=1157.28;\n",
      "iter=131; mean(abs(feat))=1395.36;\n",
      "iter=132; mean(abs(feat))=1338.69;\n",
      "iter=133; mean(abs(feat))=1396.08;\n",
      "iter=134; mean(abs(feat))=1661.94;\n",
      "iter=135; mean(abs(feat))=1647.63;\n",
      "iter=136; mean(abs(feat))=1499.32;\n",
      "iter=137; mean(abs(feat))=1435.81;\n",
      "iter=138; mean(abs(feat))=1411.89;\n",
      "iter=139; mean(abs(feat))=1583.68;\n",
      "iter=140; mean(abs(feat))=1564.92;\n",
      "iter=141; mean(abs(feat))=1709.24;\n",
      "iter=142; mean(abs(feat))=1748.01;\n",
      "iter=143; mean(abs(feat))=1828.2;\n",
      "iter=144; mean(abs(feat))=1849.12;\n",
      "iter=145; mean(abs(feat))=1797.24;\n",
      "iter=146; mean(abs(feat))=1968.02;\n",
      "iter=147; mean(abs(feat))=1842.37;\n",
      "iter=148; mean(abs(feat))=1804.55;\n",
      "iter=149; mean(abs(feat))=2130.51;\n",
      "iter=150; mean(abs(feat))=2003.3;\n",
      "iter=151; mean(abs(feat))=1937.54;\n",
      "iter=152; mean(abs(feat))=1790;\n",
      "iter=153; mean(abs(feat))=2149.82;\n",
      "iter=154; mean(abs(feat))=2252.1;\n",
      "iter=155; mean(abs(feat))=2244.95;\n",
      "iter=156; mean(abs(feat))=2333.58;\n",
      "iter=157; mean(abs(feat))=2210;\n",
      "iter=158; mean(abs(feat))=2209.05;\n",
      "iter=159; mean(abs(feat))=2656.89;\n",
      "iter=160; mean(abs(feat))=2738.78;\n",
      "iter=161; mean(abs(feat))=3188.97;\n",
      "iter=162; mean(abs(feat))=2238.6;\n",
      "iter=163; mean(abs(feat))=2596.35;\n",
      "iter=164; mean(abs(feat))=2937.91;\n",
      "iter=165; mean(abs(feat))=2592.71;\n",
      "iter=166; mean(abs(feat))=2582.39;\n",
      "iter=167; mean(abs(feat))=3057.5;\n",
      "iter=168; mean(abs(feat))=2793.33;\n",
      "iter=169; mean(abs(feat))=3029.95;\n",
      "iter=170; mean(abs(feat))=3601.98;\n",
      "iter=171; mean(abs(feat))=3322.87;\n",
      "iter=172; mean(abs(feat))=3119.12;\n",
      "iter=173; mean(abs(feat))=3316.91;\n",
      "iter=174; mean(abs(feat))=3646.32;\n",
      "iter=175; mean(abs(feat))=3229.82;\n",
      "iter=176; mean(abs(feat))=3375.27;\n",
      "iter=177; mean(abs(feat))=3810.34;\n",
      "iter=178; mean(abs(feat))=3968.63;\n",
      "iter=179; mean(abs(feat))=3315.87;\n",
      "iter=180; mean(abs(feat))=3982.32;\n",
      "iter=181; mean(abs(feat))=4023.62;\n",
      "iter=182; mean(abs(feat))=3658.83;\n",
      "iter=183; mean(abs(feat))=3806.18;\n",
      "iter=184; mean(abs(feat))=3761;\n",
      "iter=185; mean(abs(feat))=4786.21;\n",
      "iter=186; mean(abs(feat))=4160.29;\n",
      "iter=187; mean(abs(feat))=4674.36;\n",
      "iter=188; mean(abs(feat))=5373.6;\n",
      "iter=189; mean(abs(feat))=4614.36;\n",
      "iter=190; mean(abs(feat))=4821.74;\n",
      "iter=191; mean(abs(feat))=4712.97;\n",
      "iter=192; mean(abs(feat))=5514.59;\n",
      "iter=193; mean(abs(feat))=5787.36;\n",
      "iter=194; mean(abs(feat))=5375.03;\n",
      "iter=195; mean(abs(feat))=5413.7;\n",
      "iter=196; mean(abs(feat))=5504.01;\n",
      "iter=197; mean(abs(feat))=5890.36;\n",
      "iter=198; mean(abs(feat))=5928.57;\n",
      "iter=199; mean(abs(feat))=6522.63;\n",
      "iter=200; mean(abs(feat))=7046.67;\n",
      "\n",
      "channel=56\n",
      "\n",
      "iter=1; mean(abs(feat))=4.9644;\n",
      "iter=2; mean(abs(feat))=57.4169;\n",
      "iter=3; mean(abs(feat))=29.5103;\n",
      "iter=4; mean(abs(feat))=20.7825;\n",
      "iter=5; mean(abs(feat))=8.35452;\n",
      "iter=6; mean(abs(feat))=6.56389;\n",
      "iter=7; mean(abs(feat))=13.3525;\n",
      "iter=8; mean(abs(feat))=9.0107;\n",
      "iter=9; mean(abs(feat))=7.89955;\n",
      "iter=10; mean(abs(feat))=18.9898;\n",
      "iter=11; mean(abs(feat))=11.0651;\n",
      "iter=12; mean(abs(feat))=0.311007;\n",
      "iter=13; mean(abs(feat))=20.007;\n",
      "iter=14; mean(abs(feat))=26.9183;\n",
      "iter=15; mean(abs(feat))=5.17097;\n",
      "iter=16; mean(abs(feat))=54.961;\n",
      "iter=17; mean(abs(feat))=39.8038;\n",
      "iter=18; mean(abs(feat))=56.175;\n",
      "iter=19; mean(abs(feat))=43.2427;\n",
      "iter=20; mean(abs(feat))=63.7704;\n",
      "iter=21; mean(abs(feat))=45.7633;\n",
      "iter=22; mean(abs(feat))=56.139;\n",
      "iter=23; mean(abs(feat))=62.4311;\n",
      "iter=24; mean(abs(feat))=45.458;\n",
      "iter=25; mean(abs(feat))=45.6165;\n",
      "iter=26; mean(abs(feat))=63.6309;\n",
      "iter=27; mean(abs(feat))=51.4345;\n",
      "iter=28; mean(abs(feat))=112.791;\n",
      "iter=29; mean(abs(feat))=146.985;\n",
      "iter=30; mean(abs(feat))=144.041;\n",
      "iter=31; mean(abs(feat))=127.011;\n",
      "iter=32; mean(abs(feat))=121.438;\n",
      "iter=33; mean(abs(feat))=127.4;\n",
      "iter=34; mean(abs(feat))=111.037;\n",
      "iter=35; mean(abs(feat))=114.725;\n",
      "iter=36; mean(abs(feat))=110.177;\n",
      "iter=37; mean(abs(feat))=118.257;\n",
      "iter=38; mean(abs(feat))=95.5476;\n",
      "iter=39; mean(abs(feat))=141.505;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=40; mean(abs(feat))=143.824;\n",
      "iter=41; mean(abs(feat))=145.082;\n",
      "iter=42; mean(abs(feat))=169.278;\n",
      "iter=43; mean(abs(feat))=148.422;\n",
      "iter=44; mean(abs(feat))=134.879;\n",
      "iter=45; mean(abs(feat))=167.532;\n",
      "iter=46; mean(abs(feat))=170.534;\n",
      "iter=47; mean(abs(feat))=171.83;\n",
      "iter=48; mean(abs(feat))=202.019;\n",
      "iter=49; mean(abs(feat))=199.236;\n",
      "iter=50; mean(abs(feat))=234.775;\n",
      "iter=51; mean(abs(feat))=197.186;\n",
      "iter=52; mean(abs(feat))=204.855;\n",
      "iter=53; mean(abs(feat))=219.935;\n",
      "iter=54; mean(abs(feat))=236.22;\n",
      "iter=55; mean(abs(feat))=304.613;\n",
      "iter=56; mean(abs(feat))=249.135;\n",
      "iter=57; mean(abs(feat))=240.361;\n",
      "iter=58; mean(abs(feat))=250.466;\n",
      "iter=59; mean(abs(feat))=316.2;\n",
      "iter=60; mean(abs(feat))=336.536;\n",
      "iter=61; mean(abs(feat))=331.273;\n",
      "iter=62; mean(abs(feat))=348.515;\n",
      "iter=63; mean(abs(feat))=276.856;\n",
      "iter=64; mean(abs(feat))=313.127;\n",
      "iter=65; mean(abs(feat))=343.839;\n",
      "iter=66; mean(abs(feat))=389.519;\n",
      "iter=67; mean(abs(feat))=308.752;\n",
      "iter=68; mean(abs(feat))=412.901;\n",
      "iter=69; mean(abs(feat))=468.935;\n",
      "iter=70; mean(abs(feat))=382.591;\n",
      "iter=71; mean(abs(feat))=391.958;\n",
      "iter=72; mean(abs(feat))=327.096;\n",
      "iter=73; mean(abs(feat))=504.777;\n",
      "iter=74; mean(abs(feat))=430.139;\n",
      "iter=75; mean(abs(feat))=530.878;\n",
      "iter=76; mean(abs(feat))=557.33;\n",
      "iter=77; mean(abs(feat))=502.699;\n",
      "iter=78; mean(abs(feat))=576.528;\n",
      "iter=79; mean(abs(feat))=607.544;\n",
      "iter=80; mean(abs(feat))=514.274;\n",
      "iter=81; mean(abs(feat))=573.635;\n",
      "iter=82; mean(abs(feat))=556.464;\n",
      "iter=83; mean(abs(feat))=604.729;\n",
      "iter=84; mean(abs(feat))=606.525;\n",
      "iter=85; mean(abs(feat))=612.507;\n",
      "iter=86; mean(abs(feat))=646.676;\n",
      "iter=87; mean(abs(feat))=619.461;\n",
      "iter=88; mean(abs(feat))=664.508;\n",
      "iter=89; mean(abs(feat))=791.645;\n",
      "iter=90; mean(abs(feat))=512.98;\n",
      "iter=91; mean(abs(feat))=660.767;\n",
      "iter=92; mean(abs(feat))=720.452;\n",
      "iter=93; mean(abs(feat))=739.688;\n",
      "iter=94; mean(abs(feat))=679.789;\n",
      "iter=95; mean(abs(feat))=798.59;\n",
      "iter=96; mean(abs(feat))=794.116;\n",
      "iter=97; mean(abs(feat))=852.348;\n",
      "iter=98; mean(abs(feat))=781.384;\n",
      "iter=99; mean(abs(feat))=895.378;\n",
      "iter=100; mean(abs(feat))=705.374;\n",
      "iter=101; mean(abs(feat))=869.047;\n",
      "iter=102; mean(abs(feat))=683.603;\n",
      "iter=103; mean(abs(feat))=804.343;\n",
      "iter=104; mean(abs(feat))=686.601;\n",
      "iter=105; mean(abs(feat))=821.469;\n",
      "iter=106; mean(abs(feat))=800.053;\n",
      "iter=107; mean(abs(feat))=913.652;\n",
      "iter=108; mean(abs(feat))=970.84;\n",
      "iter=109; mean(abs(feat))=952.008;\n",
      "iter=110; mean(abs(feat))=888.888;\n",
      "iter=111; mean(abs(feat))=800.237;\n",
      "iter=112; mean(abs(feat))=926.371;\n",
      "iter=113; mean(abs(feat))=954.373;\n",
      "iter=114; mean(abs(feat))=1044.7;\n",
      "iter=115; mean(abs(feat))=1031.59;\n",
      "iter=116; mean(abs(feat))=1072.4;\n",
      "iter=117; mean(abs(feat))=1044.45;\n",
      "iter=118; mean(abs(feat))=1223.79;\n",
      "iter=119; mean(abs(feat))=946.907;\n",
      "iter=120; mean(abs(feat))=1096.51;\n",
      "iter=121; mean(abs(feat))=1117.07;\n",
      "iter=122; mean(abs(feat))=1114.56;\n",
      "iter=123; mean(abs(feat))=1142.65;\n",
      "iter=124; mean(abs(feat))=1187.57;\n",
      "iter=125; mean(abs(feat))=1050.09;\n",
      "iter=126; mean(abs(feat))=1102.53;\n",
      "iter=127; mean(abs(feat))=1304.79;\n",
      "iter=128; mean(abs(feat))=1387.95;\n",
      "iter=129; mean(abs(feat))=1230.33;\n",
      "iter=130; mean(abs(feat))=1333.96;\n",
      "iter=131; mean(abs(feat))=1274.44;\n",
      "iter=132; mean(abs(feat))=1294.16;\n",
      "iter=133; mean(abs(feat))=1319.28;\n",
      "iter=134; mean(abs(feat))=1307.57;\n",
      "iter=135; mean(abs(feat))=1282.28;\n",
      "iter=136; mean(abs(feat))=1444.97;\n",
      "iter=137; mean(abs(feat))=1464.39;\n",
      "iter=138; mean(abs(feat))=1445.76;\n",
      "iter=139; mean(abs(feat))=1379.91;\n",
      "iter=140; mean(abs(feat))=1687.69;\n",
      "iter=141; mean(abs(feat))=1526.02;\n",
      "iter=142; mean(abs(feat))=1484.41;\n",
      "iter=143; mean(abs(feat))=1439.8;\n",
      "iter=144; mean(abs(feat))=1532.41;\n",
      "iter=145; mean(abs(feat))=1648.99;\n",
      "iter=146; mean(abs(feat))=1773.51;\n",
      "iter=147; mean(abs(feat))=1677.09;\n",
      "iter=148; mean(abs(feat))=1565.74;\n",
      "iter=149; mean(abs(feat))=1810.96;\n",
      "iter=150; mean(abs(feat))=1875.38;\n",
      "iter=151; mean(abs(feat))=1896.73;\n",
      "iter=152; mean(abs(feat))=1927.95;\n",
      "iter=153; mean(abs(feat))=1977.83;\n",
      "iter=154; mean(abs(feat))=1995.19;\n",
      "iter=155; mean(abs(feat))=2136.92;\n",
      "iter=156; mean(abs(feat))=2168.5;\n",
      "iter=157; mean(abs(feat))=2283.43;\n",
      "iter=158; mean(abs(feat))=2338.43;\n",
      "iter=159; mean(abs(feat))=1881.34;\n",
      "iter=160; mean(abs(feat))=2134.48;\n",
      "iter=161; mean(abs(feat))=2466.02;\n",
      "iter=162; mean(abs(feat))=2554.11;\n",
      "iter=163; mean(abs(feat))=1998.68;\n",
      "iter=164; mean(abs(feat))=2102.72;\n",
      "iter=165; mean(abs(feat))=2314.35;\n",
      "iter=166; mean(abs(feat))=2653.4;\n",
      "iter=167; mean(abs(feat))=2627.94;\n",
      "iter=168; mean(abs(feat))=2538.73;\n",
      "iter=169; mean(abs(feat))=2536.87;\n",
      "iter=170; mean(abs(feat))=2612.22;\n",
      "iter=171; mean(abs(feat))=2937.66;\n",
      "iter=172; mean(abs(feat))=2846.13;\n",
      "iter=173; mean(abs(feat))=3009.36;\n",
      "iter=174; mean(abs(feat))=2926.07;\n",
      "iter=175; mean(abs(feat))=2829.67;\n",
      "iter=176; mean(abs(feat))=3380.75;\n",
      "iter=177; mean(abs(feat))=3066.44;\n",
      "iter=178; mean(abs(feat))=3323.64;\n",
      "iter=179; mean(abs(feat))=3325.98;\n",
      "iter=180; mean(abs(feat))=3043.39;\n",
      "iter=181; mean(abs(feat))=3334.51;\n",
      "iter=182; mean(abs(feat))=3648.45;\n",
      "iter=183; mean(abs(feat))=3415.21;\n",
      "iter=184; mean(abs(feat))=3644.44;\n",
      "iter=185; mean(abs(feat))=3982;\n",
      "iter=186; mean(abs(feat))=3767.98;\n",
      "iter=187; mean(abs(feat))=3467.47;\n",
      "iter=188; mean(abs(feat))=3699;\n",
      "iter=189; mean(abs(feat))=4164.41;\n",
      "iter=190; mean(abs(feat))=4353.85;\n",
      "iter=191; mean(abs(feat))=4587.39;\n",
      "iter=192; mean(abs(feat))=5076.06;\n",
      "iter=193; mean(abs(feat))=4628.07;\n",
      "iter=194; mean(abs(feat))=4261.14;\n",
      "iter=195; mean(abs(feat))=4428.26;\n",
      "iter=196; mean(abs(feat))=4737.39;\n",
      "iter=197; mean(abs(feat))=4929.16;\n",
      "iter=198; mean(abs(feat))=5294.15;\n",
      "iter=199; mean(abs(feat))=5831.11;\n",
      "iter=200; mean(abs(feat))=5535.48;\n"
     ]
    }
   ],
   "source": [
    "for channel in channel_list:\n",
    "    #\n",
    "    print('')\n",
    "    print('channel='+str(channel))\n",
    "    print('')\n",
    "\n",
    "    # target units\n",
    "    feat_size = feat_shape\n",
    "    y_index = int(feat_size[2]/2) # the unit in the center of feature map\n",
    "    x_index = int(feat_size[3]/2) # the unit in the center of feature map\n",
    "    feature_mask = np.zeros(feat_size)\n",
    "    feature_mask[0,channel,y_index,x_index] = 1\n",
    "    \n",
    "    \n",
    "    # activation maximization\n",
    "    preferred_stim = generate_preferred(net, exec_str_list, feature_mask=feature_mask, **opts)\n",
    "    # save the results\n",
    "    save_name = 'preferred_img' + '_layer_' + str(target_layer) + '_channel_' + str(channel) + '.npy'\n",
    "    np.save(os.path.join(save_path,save_name), preferred_stim)\n",
    "\n",
    "    save_name = 'preferred_img' + '_layer_' + str(target_layer) + '_channel_' + str(channel) + '.jpg'\n",
    "    # To better display the image, clip pixels with extreme values (0.02% of\n",
    "    # pixels with extreme low values and 0.02% of the pixels with extreme high\n",
    "    # values). And then normalise the image by mapping the pixel value to be\n",
    "    # within [0,255].\n",
    "    PIL.Image.fromarray(normalise_img(clip_extreme_pixel(preferred_stim, pct=0.04))).save(\n",
    "                    os.path.join(save_path, save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [channel, y_index, x_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[56, 6, 6]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_mask[0, target[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
