{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module import\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import torch\n",
    "import torchvision\n",
    "                \n",
    "sys.path.append('../cnn_preferred')\n",
    "from utils import normalise_img, clip_extreme_pixel, save_video, normalise_vid, get_cnn_features, img_deprocess, get_target_feature_shape\n",
    "from activation_maximization import generate_preferred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = torchvision.models.resnet50(pretrained=True)\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moment in time\n",
    "weight_file = '../model/resnet50/moments_RGB_resnet50_imagenetpretrained.pth.tar'\n",
    "net = torchvision.models.__dict__['resnet50'](num_classes=339)\n",
    "checkpoint = torch.load(weight_file, map_location=lambda storage,\n",
    "                                    loc: storage)\n",
    "state_dict = {str.replace(k, 'module.', ''): v for k, v in checkpoint['state_dict'].items()}\n",
    "net.load_state_dict(state_dict)\n",
    "net.eval()\n",
    "\n",
    "# image mean and std for pre/de-process image for input network\n",
    "img_mean=np.array([0.485, 0.456, 0.406],dtype=np.float),\n",
    "img_std = np.array([0.229,0.224,0.225])\n",
    "\n",
    "\n",
    "# if the model input is for 0-1 range, norm = 255, elif 0-255, norm = 1\n",
    "norm = 255\n",
    "bgr = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place 365\n",
    "weight_file = '../model/resnet50/resnet50_places365.pth.tar'\n",
    "net = torchvision.models.__dict__['resnet50'](num_classes=365)\n",
    "checkpoint = torch.load(weight_file, map_location=lambda storage,\n",
    "                                    loc: storage)\n",
    "state_dict = {str.replace(k, 'module.', ''): v for k, v in checkpoint['state_dict'].items()}\n",
    "net.load_state_dict(state_dict)\n",
    "net.eval()\n",
    "\n",
    "# image mean and std for pre/de-process image for input network\n",
    "img_mean=np.array([0.485, 0.456, 0.406],dtype=np.float),\n",
    "img_std = np.array([0.229,0.224,0.225])\n",
    "\n",
    "# if the model input is for 0-1 range, norm = 255, elif 0-255, norm = 1\n",
    "norm = 255\n",
    "bgr = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGGface2\n",
    "weight_file = '../model/resnet50/resnet50_ft_weight.pkl'\n",
    "with open(weight_file, 'rb') as f:\n",
    "    weights = pickle.load(f, encoding='latin1')\n",
    "net = torchvision.models.__dict__['resnet50'](num_classes=8631)\n",
    "own_state = net.state_dict()\n",
    "for name, param in weights.items():\n",
    "    if name in own_state:\n",
    "        try:\n",
    "            own_state[name].copy_(torch.from_numpy(param))\n",
    "        except Exception:\n",
    "            raise RuntimeError('While copying the parameter named {}, whose dimensions in the model are {} and whose '\\\n",
    "                               'dimensions in the checkpoint are {}.'.format(name, own_state[name].size(), param.size()))\n",
    "    else:\n",
    "        raise KeyError('unexpected key \"{}\" in state_dict'.format(name))\n",
    "\n",
    "net.eval()\n",
    "img_mean = np.array([93.5940,104.7624, 129.1863])\n",
    "#img_mean =np.array([0,0,0])\n",
    "img_std = np.array([1,1,1])\n",
    "norm = 1\n",
    "bgr = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_dir\n",
    "save_dir = '../result'\n",
    "save_folder = 'jupyter_demo_torch_complexCNN_conv'\n",
    "save_folder = save_folder + '_' + datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "save_path = os.path.join(save_dir,save_folder)\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial image for the optimization\n",
    "h, w = 299,299\n",
    "h,w = 224, 224\n",
    "initial_input = np.random.randint(0, 256, (h,w,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=2048, out_features=8631, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layer = \"net.classifier[6]\"\n",
    "target_layer = \"net.features.denseblock1.denselayer2.conv1\"\n",
    "#target_layer = \"net.features.conv0\"\n",
    "#target_layer = \"net.Conv2d_2a_3x3.conv\"\n",
    "target_layer = \"fc\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target layer setting\n",
    "exec_str_list = [target_layer]\n",
    "## obtain target feature shape\n",
    "# transform input shape for torch avairable shape\n",
    "initial_torch_input = torch.Tensor(initial_input.transpose(2,0, 1)[np.newaxis])\n",
    "# obtain target layer activation \n",
    "feat_shape = get_target_feature_shape(net, initial_torch_input, exec_str_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 8631)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options\n",
    "opts = {\n",
    "    'img_mean': img_mean, #img_mean to preprocessing input image\n",
    "    'img_std': img_std,   #img_std to preprocessing input image\n",
    "    'norm': norm,         #if the model input is for 0-1 range, norm = 255, elif 0-255, norm = 1\n",
    "    \n",
    "    'bgr': bgr,\n",
    "    \n",
    "    'iter_n': 200, # the total number of iterations for gradient descend\n",
    "\n",
    "    'disp_every': 1, # display the information on the terminal for every n iterations\n",
    "\n",
    "    'save_intermediate': True, # save the intermediate or not\n",
    "    'save_intermediate_every': 10, # save the intermediate for every n iterations\n",
    "    'save_intermediate_path': save_path, # the path to save the intermediate\n",
    "\n",
    "    'lr_start':1 , # learning rate\n",
    "    'lr_end': 1 ,   # we can change learning rate linearly setteing these two parameters\n",
    "\n",
    "    'momentum_start': 0.001, # gradient with momentum\n",
    "    'momentum_end': 0.001,   # we can change momentum linearly setteing these two parameters too\n",
    "\n",
    "    'decay_start': 0.001, # pixel decay for each iteration\n",
    "    'decay_end': 0.001,   # we can also change pixel decay linealy \n",
    "\n",
    "    'image_blur': True, # Use image smoothing or not\n",
    "    'sigma_start': 2.5, # the size of the gaussian filter for image smoothing\n",
    "    'sigma_end': 0.5,\n",
    "\n",
    "    'image_jitter': True, # use image jittering during optimization\n",
    "    'jitter_size': 32,\n",
    "    \n",
    "    'use_p_norm_reg': False, # use p_norm regularization\n",
    "    'p': 2,\n",
    "\n",
    "    'use_TV_norm_reg': False,\n",
    "    'TVbeta1': 1, \n",
    "    'TVbeta2':1.2,\n",
    "\n",
    "    'clip_small_norm': True,\n",
    "    'clip_small_norm_every': 1,\n",
    "    'n_pct_start': 5,\n",
    "    'n_pct_end': 5,\n",
    "\n",
    "    'clip_small_contribution': True,\n",
    "    'clip_small_contribution_every': 1,\n",
    "    'c_pct_start': 5,\n",
    "    'c_pct_end':5,\n",
    "    \n",
    "    'input_size': (224,224,3),\n",
    "    'initial_input': initial_input, # the initial image for the optimization (setting to None will use random noise as initial image)\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_list = [14,56, 123, 124, 215]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "channel=14\n",
      "\n",
      "iter=1; mean(abs(feat))=0.156639;\n",
      "iter=2; mean(abs(feat))=0.251772;\n",
      "iter=3; mean(abs(feat))=0.326699;\n",
      "iter=4; mean(abs(feat))=0.0430921;\n",
      "iter=5; mean(abs(feat))=0.252212;\n",
      "iter=6; mean(abs(feat))=0.496906;\n",
      "iter=7; mean(abs(feat))=1.60038;\n",
      "iter=8; mean(abs(feat))=1.13056;\n",
      "iter=9; mean(abs(feat))=1.19612;\n",
      "iter=10; mean(abs(feat))=1.50221;\n",
      "iter=11; mean(abs(feat))=1.43046;\n",
      "iter=12; mean(abs(feat))=2.97326;\n",
      "iter=13; mean(abs(feat))=2.92705;\n",
      "iter=14; mean(abs(feat))=2.60462;\n",
      "iter=15; mean(abs(feat))=3.58362;\n",
      "iter=16; mean(abs(feat))=3.93617;\n",
      "iter=17; mean(abs(feat))=1.20593;\n",
      "iter=18; mean(abs(feat))=4.19179;\n",
      "iter=19; mean(abs(feat))=5.02211;\n",
      "iter=20; mean(abs(feat))=5.53015;\n",
      "iter=21; mean(abs(feat))=4.43932;\n",
      "iter=22; mean(abs(feat))=1.48825;\n",
      "iter=23; mean(abs(feat))=4.85929;\n",
      "iter=24; mean(abs(feat))=4.96003;\n",
      "iter=25; mean(abs(feat))=2.32361;\n",
      "iter=26; mean(abs(feat))=5.70269;\n",
      "iter=27; mean(abs(feat))=4.5478;\n",
      "iter=28; mean(abs(feat))=6.56864;\n",
      "iter=29; mean(abs(feat))=8.09113;\n",
      "iter=30; mean(abs(feat))=7.16935;\n",
      "iter=31; mean(abs(feat))=7.36126;\n",
      "iter=32; mean(abs(feat))=4.65776;\n",
      "iter=33; mean(abs(feat))=9.19676;\n",
      "iter=34; mean(abs(feat))=4.01406;\n",
      "iter=35; mean(abs(feat))=5.06086;\n",
      "iter=36; mean(abs(feat))=7.57708;\n",
      "iter=37; mean(abs(feat))=6.90908;\n",
      "iter=38; mean(abs(feat))=8.9814;\n",
      "iter=39; mean(abs(feat))=3.22994;\n",
      "iter=40; mean(abs(feat))=8.68248;\n",
      "iter=41; mean(abs(feat))=10.9225;\n",
      "iter=42; mean(abs(feat))=11.7831;\n",
      "iter=43; mean(abs(feat))=9.39194;\n",
      "iter=44; mean(abs(feat))=10.328;\n",
      "iter=45; mean(abs(feat))=10.8244;\n",
      "iter=46; mean(abs(feat))=9.7111;\n",
      "iter=47; mean(abs(feat))=13.0843;\n",
      "iter=48; mean(abs(feat))=12.4446;\n",
      "iter=49; mean(abs(feat))=6.63211;\n",
      "iter=50; mean(abs(feat))=9.38083;\n",
      "iter=51; mean(abs(feat))=11.4496;\n",
      "iter=52; mean(abs(feat))=9.4621;\n",
      "iter=53; mean(abs(feat))=10.6204;\n",
      "iter=54; mean(abs(feat))=13.2772;\n",
      "iter=55; mean(abs(feat))=13.2692;\n",
      "iter=56; mean(abs(feat))=7.2653;\n",
      "iter=57; mean(abs(feat))=8.61285;\n",
      "iter=58; mean(abs(feat))=13.3311;\n",
      "iter=59; mean(abs(feat))=13.6489;\n",
      "iter=60; mean(abs(feat))=12.2526;\n",
      "iter=61; mean(abs(feat))=16.0814;\n",
      "iter=62; mean(abs(feat))=10.3193;\n",
      "iter=63; mean(abs(feat))=11.3492;\n",
      "iter=64; mean(abs(feat))=13.5261;\n",
      "iter=65; mean(abs(feat))=9.02451;\n",
      "iter=66; mean(abs(feat))=13.7013;\n",
      "iter=67; mean(abs(feat))=16.3643;\n",
      "iter=68; mean(abs(feat))=13.4639;\n",
      "iter=69; mean(abs(feat))=11.5709;\n",
      "iter=70; mean(abs(feat))=12.056;\n",
      "iter=71; mean(abs(feat))=14.0981;\n",
      "iter=72; mean(abs(feat))=11.026;\n",
      "iter=73; mean(abs(feat))=16.3291;\n",
      "iter=74; mean(abs(feat))=14.4805;\n",
      "iter=75; mean(abs(feat))=13.3848;\n",
      "iter=76; mean(abs(feat))=14.5297;\n",
      "iter=77; mean(abs(feat))=16.9634;\n",
      "iter=78; mean(abs(feat))=10.6483;\n",
      "iter=79; mean(abs(feat))=12.1604;\n",
      "iter=80; mean(abs(feat))=13.8741;\n",
      "iter=81; mean(abs(feat))=15.1394;\n",
      "iter=82; mean(abs(feat))=15.2063;\n",
      "iter=83; mean(abs(feat))=14.1186;\n",
      "iter=84; mean(abs(feat))=14.7973;\n",
      "iter=85; mean(abs(feat))=19.2747;\n",
      "iter=86; mean(abs(feat))=13.2389;\n",
      "iter=87; mean(abs(feat))=14.2773;\n",
      "iter=88; mean(abs(feat))=17.063;\n",
      "iter=89; mean(abs(feat))=18.2627;\n",
      "iter=90; mean(abs(feat))=11.4522;\n",
      "iter=91; mean(abs(feat))=15.4189;\n",
      "iter=92; mean(abs(feat))=15.4052;\n",
      "iter=93; mean(abs(feat))=15.2354;\n",
      "iter=94; mean(abs(feat))=14.1816;\n",
      "iter=95; mean(abs(feat))=12.2406;\n",
      "iter=96; mean(abs(feat))=18.4748;\n",
      "iter=97; mean(abs(feat))=17.0343;\n",
      "iter=98; mean(abs(feat))=19.126;\n",
      "iter=99; mean(abs(feat))=10.4831;\n",
      "iter=100; mean(abs(feat))=15.5722;\n",
      "iter=101; mean(abs(feat))=19.5595;\n",
      "iter=102; mean(abs(feat))=16.2038;\n",
      "iter=103; mean(abs(feat))=8.17965;\n",
      "iter=104; mean(abs(feat))=13.1132;\n",
      "iter=105; mean(abs(feat))=18.2616;\n",
      "iter=106; mean(abs(feat))=19.1483;\n",
      "iter=107; mean(abs(feat))=20.5151;\n",
      "iter=108; mean(abs(feat))=17.5924;\n",
      "iter=109; mean(abs(feat))=13.8201;\n",
      "iter=110; mean(abs(feat))=17.102;\n",
      "iter=111; mean(abs(feat))=19.1604;\n",
      "iter=112; mean(abs(feat))=10.8274;\n",
      "iter=113; mean(abs(feat))=17.7443;\n",
      "iter=114; mean(abs(feat))=9.86967;\n",
      "iter=115; mean(abs(feat))=16.9672;\n",
      "iter=116; mean(abs(feat))=19.6553;\n",
      "iter=117; mean(abs(feat))=13.0271;\n",
      "iter=118; mean(abs(feat))=19.7336;\n",
      "iter=119; mean(abs(feat))=14.2143;\n",
      "iter=120; mean(abs(feat))=19.4568;\n",
      "iter=121; mean(abs(feat))=23.0661;\n",
      "iter=122; mean(abs(feat))=23.8925;\n",
      "iter=123; mean(abs(feat))=20.1762;\n",
      "iter=124; mean(abs(feat))=20.1125;\n",
      "iter=125; mean(abs(feat))=24.3051;\n",
      "iter=126; mean(abs(feat))=21.3966;\n",
      "iter=127; mean(abs(feat))=16.7321;\n",
      "iter=128; mean(abs(feat))=22.9955;\n",
      "iter=129; mean(abs(feat))=23.9016;\n",
      "iter=130; mean(abs(feat))=20.0822;\n",
      "iter=131; mean(abs(feat))=18.3577;\n",
      "iter=132; mean(abs(feat))=20.8884;\n",
      "iter=133; mean(abs(feat))=23.2018;\n",
      "iter=134; mean(abs(feat))=19.125;\n",
      "iter=135; mean(abs(feat))=21.4441;\n",
      "iter=136; mean(abs(feat))=26.4039;\n",
      "iter=137; mean(abs(feat))=22.7348;\n",
      "iter=138; mean(abs(feat))=21.4464;\n",
      "iter=139; mean(abs(feat))=13.5492;\n",
      "iter=140; mean(abs(feat))=21.9161;\n",
      "iter=141; mean(abs(feat))=13.2231;\n",
      "iter=142; mean(abs(feat))=17.4999;\n",
      "iter=143; mean(abs(feat))=18.0294;\n",
      "iter=144; mean(abs(feat))=23.1228;\n",
      "iter=145; mean(abs(feat))=17.4531;\n",
      "iter=146; mean(abs(feat))=20.0595;\n",
      "iter=147; mean(abs(feat))=21.7409;\n",
      "iter=148; mean(abs(feat))=22.0553;\n",
      "iter=149; mean(abs(feat))=23.9688;\n",
      "iter=150; mean(abs(feat))=24.4926;\n",
      "iter=151; mean(abs(feat))=24.1361;\n",
      "iter=152; mean(abs(feat))=21.9187;\n",
      "iter=153; mean(abs(feat))=19.9086;\n",
      "iter=154; mean(abs(feat))=22.1905;\n",
      "iter=155; mean(abs(feat))=24.5641;\n",
      "iter=156; mean(abs(feat))=19.7642;\n",
      "iter=157; mean(abs(feat))=23.4444;\n",
      "iter=158; mean(abs(feat))=20.7373;\n",
      "iter=159; mean(abs(feat))=23.241;\n",
      "iter=160; mean(abs(feat))=19.323;\n",
      "iter=161; mean(abs(feat))=27.2012;\n",
      "iter=162; mean(abs(feat))=19.5251;\n",
      "iter=163; mean(abs(feat))=24.5346;\n",
      "iter=164; mean(abs(feat))=18.7863;\n",
      "iter=165; mean(abs(feat))=18.6099;\n",
      "iter=166; mean(abs(feat))=25.9135;\n",
      "iter=167; mean(abs(feat))=23.6766;\n",
      "iter=168; mean(abs(feat))=18.5052;\n",
      "iter=169; mean(abs(feat))=24.5173;\n",
      "iter=170; mean(abs(feat))=24.8731;\n",
      "iter=171; mean(abs(feat))=20.9153;\n",
      "iter=172; mean(abs(feat))=21.6244;\n",
      "iter=173; mean(abs(feat))=21.7788;\n",
      "iter=174; mean(abs(feat))=29.6311;\n",
      "iter=175; mean(abs(feat))=26.508;\n",
      "iter=176; mean(abs(feat))=23.2747;\n",
      "iter=177; mean(abs(feat))=24.5;\n",
      "iter=178; mean(abs(feat))=22.0586;\n",
      "iter=179; mean(abs(feat))=24.7031;\n",
      "iter=180; mean(abs(feat))=27.1058;\n",
      "iter=181; mean(abs(feat))=27.5058;\n",
      "iter=182; mean(abs(feat))=27.6323;\n",
      "iter=183; mean(abs(feat))=26.6178;\n",
      "iter=184; mean(abs(feat))=24.1235;\n",
      "iter=185; mean(abs(feat))=28.4919;\n",
      "iter=186; mean(abs(feat))=28.843;\n",
      "iter=187; mean(abs(feat))=30.8473;\n",
      "iter=188; mean(abs(feat))=19.834;\n",
      "iter=189; mean(abs(feat))=25.9978;\n",
      "iter=190; mean(abs(feat))=29.4695;\n",
      "iter=191; mean(abs(feat))=28.6276;\n",
      "iter=192; mean(abs(feat))=24.0785;\n",
      "iter=193; mean(abs(feat))=24.2577;\n",
      "iter=194; mean(abs(feat))=22.6151;\n",
      "iter=195; mean(abs(feat))=29.9853;\n",
      "iter=196; mean(abs(feat))=20.5007;\n",
      "iter=197; mean(abs(feat))=28.0965;\n",
      "iter=198; mean(abs(feat))=23.3981;\n",
      "iter=199; mean(abs(feat))=30.7739;\n",
      "iter=200; mean(abs(feat))=25.527;\n",
      "\n",
      "channel=56\n",
      "\n",
      "iter=1; mean(abs(feat))=0.0178854;\n",
      "iter=2; mean(abs(feat))=0.262291;\n",
      "iter=3; mean(abs(feat))=0.422896;\n",
      "iter=4; mean(abs(feat))=0.933965;\n",
      "iter=5; mean(abs(feat))=1.12713;\n",
      "iter=6; mean(abs(feat))=1.07495;\n",
      "iter=7; mean(abs(feat))=1.12553;\n",
      "iter=8; mean(abs(feat))=0.871454;\n",
      "iter=9; mean(abs(feat))=0.621607;\n",
      "iter=10; mean(abs(feat))=0.944009;\n",
      "iter=11; mean(abs(feat))=1.1993;\n",
      "iter=12; mean(abs(feat))=1.14435;\n",
      "iter=13; mean(abs(feat))=0.991303;\n",
      "iter=14; mean(abs(feat))=1.31058;\n",
      "iter=15; mean(abs(feat))=1.70347;\n",
      "iter=16; mean(abs(feat))=1.40239;\n",
      "iter=17; mean(abs(feat))=1.33822;\n",
      "iter=18; mean(abs(feat))=0.922844;\n",
      "iter=19; mean(abs(feat))=1.40433;\n",
      "iter=20; mean(abs(feat))=1.58606;\n",
      "iter=21; mean(abs(feat))=1.35548;\n",
      "iter=22; mean(abs(feat))=1.48408;\n",
      "iter=23; mean(abs(feat))=1.81807;\n",
      "iter=24; mean(abs(feat))=2.3057;\n",
      "iter=25; mean(abs(feat))=0.903186;\n",
      "iter=26; mean(abs(feat))=2.37184;\n",
      "iter=27; mean(abs(feat))=2.65704;\n",
      "iter=28; mean(abs(feat))=2.11685;\n",
      "iter=29; mean(abs(feat))=1.26117;\n",
      "iter=30; mean(abs(feat))=1.39749;\n",
      "iter=31; mean(abs(feat))=3.34459;\n",
      "iter=32; mean(abs(feat))=1.38155;\n",
      "iter=33; mean(abs(feat))=1.65034;\n",
      "iter=34; mean(abs(feat))=2.19101;\n",
      "iter=35; mean(abs(feat))=2.26843;\n",
      "iter=36; mean(abs(feat))=2.7694;\n",
      "iter=37; mean(abs(feat))=4.4003;\n",
      "iter=38; mean(abs(feat))=4.12884;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=39; mean(abs(feat))=6.67449;\n",
      "iter=40; mean(abs(feat))=6.35392;\n",
      "iter=41; mean(abs(feat))=4.52924;\n",
      "iter=42; mean(abs(feat))=4.8783;\n",
      "iter=43; mean(abs(feat))=5.19441;\n",
      "iter=44; mean(abs(feat))=6.98379;\n",
      "iter=45; mean(abs(feat))=5.34971;\n",
      "iter=46; mean(abs(feat))=6.4395;\n",
      "iter=47; mean(abs(feat))=9.28586;\n",
      "iter=48; mean(abs(feat))=6.11609;\n",
      "iter=49; mean(abs(feat))=8.72069;\n",
      "iter=50; mean(abs(feat))=5.99788;\n",
      "iter=51; mean(abs(feat))=9.87242;\n",
      "iter=52; mean(abs(feat))=6.97574;\n",
      "iter=53; mean(abs(feat))=8.266;\n",
      "iter=54; mean(abs(feat))=7.3092;\n",
      "iter=55; mean(abs(feat))=6.74209;\n",
      "iter=56; mean(abs(feat))=10.6765;\n",
      "iter=57; mean(abs(feat))=7.977;\n",
      "iter=58; mean(abs(feat))=7.52325;\n",
      "iter=59; mean(abs(feat))=10.0557;\n",
      "iter=60; mean(abs(feat))=9.47172;\n",
      "iter=61; mean(abs(feat))=10.3799;\n",
      "iter=62; mean(abs(feat))=11.8308;\n",
      "iter=63; mean(abs(feat))=11.7273;\n",
      "iter=64; mean(abs(feat))=9.80894;\n",
      "iter=65; mean(abs(feat))=10.1663;\n",
      "iter=66; mean(abs(feat))=11.7742;\n",
      "iter=67; mean(abs(feat))=14.0133;\n",
      "iter=68; mean(abs(feat))=11.5062;\n",
      "iter=69; mean(abs(feat))=12.5672;\n",
      "iter=70; mean(abs(feat))=12.9619;\n",
      "iter=71; mean(abs(feat))=10.0871;\n",
      "iter=72; mean(abs(feat))=13.1668;\n",
      "iter=73; mean(abs(feat))=12.5624;\n",
      "iter=74; mean(abs(feat))=14.181;\n",
      "iter=75; mean(abs(feat))=9.7008;\n",
      "iter=76; mean(abs(feat))=15.7331;\n",
      "iter=77; mean(abs(feat))=16.7542;\n",
      "iter=78; mean(abs(feat))=11.6422;\n",
      "iter=79; mean(abs(feat))=10.3487;\n",
      "iter=80; mean(abs(feat))=16.4267;\n",
      "iter=81; mean(abs(feat))=15.7406;\n",
      "iter=82; mean(abs(feat))=10.9072;\n",
      "iter=83; mean(abs(feat))=15.6098;\n",
      "iter=84; mean(abs(feat))=16.3018;\n",
      "iter=85; mean(abs(feat))=13.934;\n",
      "iter=86; mean(abs(feat))=12.5665;\n",
      "iter=87; mean(abs(feat))=14.2133;\n",
      "iter=88; mean(abs(feat))=14.8057;\n",
      "iter=89; mean(abs(feat))=14.2427;\n",
      "iter=90; mean(abs(feat))=15.0965;\n",
      "iter=91; mean(abs(feat))=15.7194;\n",
      "iter=92; mean(abs(feat))=10.9822;\n",
      "iter=93; mean(abs(feat))=15.2126;\n",
      "iter=94; mean(abs(feat))=16.4292;\n",
      "iter=95; mean(abs(feat))=18.5832;\n",
      "iter=96; mean(abs(feat))=14.3057;\n",
      "iter=97; mean(abs(feat))=13.7944;\n",
      "iter=98; mean(abs(feat))=18.3046;\n",
      "iter=99; mean(abs(feat))=13.6574;\n",
      "iter=100; mean(abs(feat))=19.1876;\n",
      "iter=101; mean(abs(feat))=16.494;\n",
      "iter=102; mean(abs(feat))=16.9342;\n",
      "iter=103; mean(abs(feat))=12.1827;\n",
      "iter=104; mean(abs(feat))=15.0036;\n",
      "iter=105; mean(abs(feat))=18.8541;\n",
      "iter=106; mean(abs(feat))=22.1347;\n",
      "iter=107; mean(abs(feat))=17.9464;\n",
      "iter=108; mean(abs(feat))=22.1064;\n",
      "iter=109; mean(abs(feat))=19.9295;\n",
      "iter=110; mean(abs(feat))=15.1307;\n",
      "iter=111; mean(abs(feat))=10.0222;\n",
      "iter=112; mean(abs(feat))=16.5401;\n",
      "iter=113; mean(abs(feat))=14.7906;\n",
      "iter=114; mean(abs(feat))=17.9924;\n",
      "iter=115; mean(abs(feat))=14.613;\n",
      "iter=116; mean(abs(feat))=18.3575;\n",
      "iter=117; mean(abs(feat))=21.2538;\n",
      "iter=118; mean(abs(feat))=20.6652;\n",
      "iter=119; mean(abs(feat))=16.8967;\n",
      "iter=120; mean(abs(feat))=20.9789;\n",
      "iter=121; mean(abs(feat))=14.8137;\n",
      "iter=122; mean(abs(feat))=16.1037;\n",
      "iter=123; mean(abs(feat))=18.8903;\n",
      "iter=124; mean(abs(feat))=14.9948;\n",
      "iter=125; mean(abs(feat))=21.9527;\n",
      "iter=126; mean(abs(feat))=22.7762;\n",
      "iter=127; mean(abs(feat))=20.6273;\n",
      "iter=128; mean(abs(feat))=19.0218;\n",
      "iter=129; mean(abs(feat))=17.4487;\n",
      "iter=130; mean(abs(feat))=17.2381;\n",
      "iter=131; mean(abs(feat))=16.5761;\n",
      "iter=132; mean(abs(feat))=23.205;\n",
      "iter=133; mean(abs(feat))=18.1919;\n",
      "iter=134; mean(abs(feat))=21.4047;\n",
      "iter=135; mean(abs(feat))=21.8348;\n",
      "iter=136; mean(abs(feat))=20.3708;\n",
      "iter=137; mean(abs(feat))=24.8586;\n",
      "iter=138; mean(abs(feat))=22.1693;\n",
      "iter=139; mean(abs(feat))=23.2128;\n",
      "iter=140; mean(abs(feat))=25.6479;\n",
      "iter=141; mean(abs(feat))=19.9479;\n",
      "iter=142; mean(abs(feat))=21.5628;\n",
      "iter=143; mean(abs(feat))=18.3972;\n",
      "iter=144; mean(abs(feat))=22.1444;\n",
      "iter=145; mean(abs(feat))=26.0833;\n",
      "iter=146; mean(abs(feat))=20.5783;\n",
      "iter=147; mean(abs(feat))=28.1326;\n",
      "iter=148; mean(abs(feat))=25.7058;\n",
      "iter=149; mean(abs(feat))=24.6057;\n",
      "iter=150; mean(abs(feat))=19.1167;\n",
      "iter=151; mean(abs(feat))=15.7565;\n",
      "iter=152; mean(abs(feat))=22.4318;\n",
      "iter=153; mean(abs(feat))=23.3641;\n",
      "iter=154; mean(abs(feat))=23.0855;\n",
      "iter=155; mean(abs(feat))=24.5432;\n",
      "iter=156; mean(abs(feat))=27.0167;\n",
      "iter=157; mean(abs(feat))=24.1858;\n",
      "iter=158; mean(abs(feat))=26.2154;\n",
      "iter=159; mean(abs(feat))=30.3335;\n",
      "iter=160; mean(abs(feat))=28.19;\n",
      "iter=161; mean(abs(feat))=29.5939;\n",
      "iter=162; mean(abs(feat))=26.3669;\n",
      "iter=163; mean(abs(feat))=22.4743;\n",
      "iter=164; mean(abs(feat))=24.4257;\n",
      "iter=165; mean(abs(feat))=25.4792;\n",
      "iter=166; mean(abs(feat))=27.2202;\n",
      "iter=167; mean(abs(feat))=24.9799;\n",
      "iter=168; mean(abs(feat))=22.0503;\n",
      "iter=169; mean(abs(feat))=26.5419;\n",
      "iter=170; mean(abs(feat))=27.086;\n",
      "iter=171; mean(abs(feat))=28.5483;\n",
      "iter=172; mean(abs(feat))=30.1869;\n",
      "iter=173; mean(abs(feat))=28.9885;\n",
      "iter=174; mean(abs(feat))=30.3391;\n",
      "iter=175; mean(abs(feat))=31.1538;\n",
      "iter=176; mean(abs(feat))=30.7268;\n",
      "iter=177; mean(abs(feat))=20.8376;\n",
      "iter=178; mean(abs(feat))=29.1965;\n",
      "iter=179; mean(abs(feat))=24.566;\n",
      "iter=180; mean(abs(feat))=24.301;\n",
      "iter=181; mean(abs(feat))=30.6999;\n",
      "iter=182; mean(abs(feat))=25.247;\n",
      "iter=183; mean(abs(feat))=23.6184;\n",
      "iter=184; mean(abs(feat))=28.6416;\n",
      "iter=185; mean(abs(feat))=27.3844;\n",
      "iter=186; mean(abs(feat))=32.396;\n",
      "iter=187; mean(abs(feat))=31.4048;\n",
      "iter=188; mean(abs(feat))=31.5003;\n",
      "iter=189; mean(abs(feat))=26.5835;\n",
      "iter=190; mean(abs(feat))=32.82;\n",
      "iter=191; mean(abs(feat))=31.3266;\n",
      "iter=192; mean(abs(feat))=32.3893;\n",
      "iter=193; mean(abs(feat))=26.8081;\n",
      "iter=194; mean(abs(feat))=27.1631;\n",
      "iter=195; mean(abs(feat))=24.5579;\n",
      "iter=196; mean(abs(feat))=27.8025;\n",
      "iter=197; mean(abs(feat))=29.2557;\n",
      "iter=198; mean(abs(feat))=29.1975;\n",
      "iter=199; mean(abs(feat))=29.9134;\n",
      "iter=200; mean(abs(feat))=25.8308;\n",
      "\n",
      "channel=123\n",
      "\n",
      "iter=1; mean(abs(feat))=0.0986431;\n",
      "iter=2; mean(abs(feat))=0.10185;\n",
      "iter=3; mean(abs(feat))=0.647051;\n",
      "iter=4; mean(abs(feat))=1.49929;\n",
      "iter=5; mean(abs(feat))=1.59234;\n",
      "iter=6; mean(abs(feat))=1.80307;\n",
      "iter=7; mean(abs(feat))=1.72622;\n",
      "iter=8; mean(abs(feat))=1.79653;\n",
      "iter=9; mean(abs(feat))=2.39196;\n",
      "iter=10; mean(abs(feat))=1.82615;\n",
      "iter=11; mean(abs(feat))=2.40741;\n",
      "iter=12; mean(abs(feat))=1.4503;\n",
      "iter=13; mean(abs(feat))=1.92194;\n",
      "iter=14; mean(abs(feat))=2.63579;\n",
      "iter=15; mean(abs(feat))=2.64611;\n",
      "iter=16; mean(abs(feat))=3.35337;\n",
      "iter=17; mean(abs(feat))=2.31314;\n",
      "iter=18; mean(abs(feat))=3.06138;\n",
      "iter=19; mean(abs(feat))=3.82517;\n",
      "iter=20; mean(abs(feat))=3.68738;\n",
      "iter=21; mean(abs(feat))=4.54256;\n",
      "iter=22; mean(abs(feat))=4.02369;\n",
      "iter=23; mean(abs(feat))=5.35474;\n",
      "iter=24; mean(abs(feat))=6.17002;\n",
      "iter=25; mean(abs(feat))=5.33227;\n",
      "iter=26; mean(abs(feat))=4.40365;\n",
      "iter=27; mean(abs(feat))=5.61038;\n",
      "iter=28; mean(abs(feat))=5.90884;\n",
      "iter=29; mean(abs(feat))=5.39386;\n",
      "iter=30; mean(abs(feat))=5.57009;\n",
      "iter=31; mean(abs(feat))=5.65675;\n",
      "iter=32; mean(abs(feat))=5.71255;\n",
      "iter=33; mean(abs(feat))=6.69333;\n",
      "iter=34; mean(abs(feat))=7.33486;\n",
      "iter=35; mean(abs(feat))=5.47155;\n",
      "iter=36; mean(abs(feat))=6.34222;\n",
      "iter=37; mean(abs(feat))=7.29382;\n",
      "iter=38; mean(abs(feat))=8.70123;\n",
      "iter=39; mean(abs(feat))=5.63301;\n",
      "iter=40; mean(abs(feat))=5.51894;\n",
      "iter=41; mean(abs(feat))=8.33873;\n",
      "iter=42; mean(abs(feat))=8.18344;\n",
      "iter=43; mean(abs(feat))=7.37708;\n",
      "iter=44; mean(abs(feat))=9.07012;\n",
      "iter=45; mean(abs(feat))=9.63638;\n",
      "iter=46; mean(abs(feat))=7.67564;\n",
      "iter=47; mean(abs(feat))=7.49147;\n",
      "iter=48; mean(abs(feat))=8.2881;\n",
      "iter=49; mean(abs(feat))=9.60842;\n",
      "iter=50; mean(abs(feat))=9.63334;\n",
      "iter=51; mean(abs(feat))=11.4634;\n",
      "iter=52; mean(abs(feat))=10.4903;\n",
      "iter=53; mean(abs(feat))=10.9921;\n",
      "iter=54; mean(abs(feat))=10.0025;\n",
      "iter=55; mean(abs(feat))=11.439;\n",
      "iter=56; mean(abs(feat))=9.92331;\n",
      "iter=57; mean(abs(feat))=11.1435;\n",
      "iter=58; mean(abs(feat))=13.061;\n",
      "iter=59; mean(abs(feat))=12.3054;\n",
      "iter=60; mean(abs(feat))=9.42862;\n",
      "iter=61; mean(abs(feat))=9.87181;\n",
      "iter=62; mean(abs(feat))=10.8281;\n",
      "iter=63; mean(abs(feat))=11.1392;\n",
      "iter=64; mean(abs(feat))=10.7543;\n",
      "iter=65; mean(abs(feat))=11.9025;\n",
      "iter=66; mean(abs(feat))=13.2027;\n",
      "iter=67; mean(abs(feat))=11.1635;\n",
      "iter=68; mean(abs(feat))=13.9385;\n",
      "iter=69; mean(abs(feat))=13.9418;\n",
      "iter=70; mean(abs(feat))=14.481;\n",
      "iter=71; mean(abs(feat))=11.0104;\n",
      "iter=72; mean(abs(feat))=12.538;\n",
      "iter=73; mean(abs(feat))=12.6207;\n",
      "iter=74; mean(abs(feat))=13.0602;\n",
      "iter=75; mean(abs(feat))=13.8864;\n",
      "iter=76; mean(abs(feat))=12.7491;\n",
      "iter=77; mean(abs(feat))=14.4234;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=78; mean(abs(feat))=12.6041;\n",
      "iter=79; mean(abs(feat))=15.2053;\n",
      "iter=80; mean(abs(feat))=13.2365;\n",
      "iter=81; mean(abs(feat))=15.6814;\n",
      "iter=82; mean(abs(feat))=10.2162;\n",
      "iter=83; mean(abs(feat))=11.578;\n",
      "iter=84; mean(abs(feat))=15.2626;\n",
      "iter=85; mean(abs(feat))=14.9269;\n",
      "iter=86; mean(abs(feat))=13.5255;\n",
      "iter=87; mean(abs(feat))=14.4715;\n",
      "iter=88; mean(abs(feat))=14.3286;\n",
      "iter=89; mean(abs(feat))=11.7504;\n",
      "iter=90; mean(abs(feat))=15.4633;\n",
      "iter=91; mean(abs(feat))=19.4925;\n",
      "iter=92; mean(abs(feat))=14.6611;\n",
      "iter=93; mean(abs(feat))=15.1791;\n",
      "iter=94; mean(abs(feat))=12.4418;\n",
      "iter=95; mean(abs(feat))=15.2386;\n",
      "iter=96; mean(abs(feat))=16.8602;\n",
      "iter=97; mean(abs(feat))=14.5338;\n",
      "iter=98; mean(abs(feat))=17.8088;\n",
      "iter=99; mean(abs(feat))=15.8423;\n",
      "iter=100; mean(abs(feat))=15.2897;\n",
      "iter=101; mean(abs(feat))=15.9455;\n",
      "iter=102; mean(abs(feat))=16.5436;\n",
      "iter=103; mean(abs(feat))=16.1505;\n",
      "iter=104; mean(abs(feat))=17.4806;\n",
      "iter=105; mean(abs(feat))=19.0582;\n",
      "iter=106; mean(abs(feat))=18.2974;\n",
      "iter=107; mean(abs(feat))=11.8347;\n",
      "iter=108; mean(abs(feat))=17.0377;\n",
      "iter=109; mean(abs(feat))=16.9763;\n",
      "iter=110; mean(abs(feat))=18.1208;\n",
      "iter=111; mean(abs(feat))=18.126;\n",
      "iter=112; mean(abs(feat))=17.8021;\n",
      "iter=113; mean(abs(feat))=20.2048;\n",
      "iter=114; mean(abs(feat))=16.3991;\n",
      "iter=115; mean(abs(feat))=16.3721;\n",
      "iter=116; mean(abs(feat))=16.6994;\n",
      "iter=117; mean(abs(feat))=19.9191;\n",
      "iter=118; mean(abs(feat))=19.2124;\n",
      "iter=119; mean(abs(feat))=19.291;\n",
      "iter=120; mean(abs(feat))=20.6722;\n",
      "iter=121; mean(abs(feat))=18.471;\n",
      "iter=122; mean(abs(feat))=20.5616;\n",
      "iter=123; mean(abs(feat))=17.3606;\n",
      "iter=124; mean(abs(feat))=17.5936;\n",
      "iter=125; mean(abs(feat))=18.7448;\n",
      "iter=126; mean(abs(feat))=15.1061;\n",
      "iter=127; mean(abs(feat))=19.8673;\n",
      "iter=128; mean(abs(feat))=19.6258;\n",
      "iter=129; mean(abs(feat))=17.466;\n",
      "iter=130; mean(abs(feat))=19.3175;\n",
      "iter=131; mean(abs(feat))=19.6691;\n",
      "iter=132; mean(abs(feat))=17.0182;\n",
      "iter=133; mean(abs(feat))=20.1016;\n",
      "iter=134; mean(abs(feat))=20.6418;\n",
      "iter=135; mean(abs(feat))=18.7668;\n",
      "iter=136; mean(abs(feat))=18.3967;\n",
      "iter=137; mean(abs(feat))=19.9667;\n",
      "iter=138; mean(abs(feat))=14.0541;\n",
      "iter=139; mean(abs(feat))=19.2702;\n",
      "iter=140; mean(abs(feat))=19.4194;\n",
      "iter=141; mean(abs(feat))=22.0327;\n",
      "iter=142; mean(abs(feat))=19.4786;\n",
      "iter=143; mean(abs(feat))=18.7433;\n",
      "iter=144; mean(abs(feat))=20.3581;\n",
      "iter=145; mean(abs(feat))=15.982;\n",
      "iter=146; mean(abs(feat))=16.132;\n",
      "iter=147; mean(abs(feat))=21.411;\n",
      "iter=148; mean(abs(feat))=22.3121;\n",
      "iter=149; mean(abs(feat))=19.9412;\n",
      "iter=150; mean(abs(feat))=22.0568;\n",
      "iter=151; mean(abs(feat))=21.3417;\n",
      "iter=152; mean(abs(feat))=22.7784;\n",
      "iter=153; mean(abs(feat))=21.9194;\n",
      "iter=154; mean(abs(feat))=22.5928;\n",
      "iter=155; mean(abs(feat))=22.8291;\n",
      "iter=156; mean(abs(feat))=25.3009;\n",
      "iter=157; mean(abs(feat))=16.6694;\n",
      "iter=158; mean(abs(feat))=21.4377;\n",
      "iter=159; mean(abs(feat))=19.9234;\n",
      "iter=160; mean(abs(feat))=24.0109;\n",
      "iter=161; mean(abs(feat))=22.2545;\n",
      "iter=162; mean(abs(feat))=21.8146;\n",
      "iter=163; mean(abs(feat))=23.3322;\n",
      "iter=164; mean(abs(feat))=24.8497;\n",
      "iter=165; mean(abs(feat))=25.187;\n",
      "iter=166; mean(abs(feat))=24.8315;\n",
      "iter=167; mean(abs(feat))=21.4606;\n",
      "iter=168; mean(abs(feat))=17.7825;\n",
      "iter=169; mean(abs(feat))=22.5138;\n",
      "iter=170; mean(abs(feat))=23.5951;\n",
      "iter=171; mean(abs(feat))=26.1448;\n",
      "iter=172; mean(abs(feat))=28.2446;\n",
      "iter=173; mean(abs(feat))=25.966;\n",
      "iter=174; mean(abs(feat))=22.785;\n",
      "iter=175; mean(abs(feat))=21.3408;\n",
      "iter=176; mean(abs(feat))=25.8234;\n",
      "iter=177; mean(abs(feat))=26.4835;\n",
      "iter=178; mean(abs(feat))=30.2534;\n",
      "iter=179; mean(abs(feat))=23.9101;\n",
      "iter=180; mean(abs(feat))=29.9595;\n",
      "iter=181; mean(abs(feat))=28.6326;\n",
      "iter=182; mean(abs(feat))=22.9391;\n",
      "iter=183; mean(abs(feat))=27.2764;\n",
      "iter=184; mean(abs(feat))=26.6964;\n",
      "iter=185; mean(abs(feat))=28.9728;\n",
      "iter=186; mean(abs(feat))=26.4946;\n",
      "iter=187; mean(abs(feat))=25.7607;\n",
      "iter=188; mean(abs(feat))=31.1701;\n",
      "iter=189; mean(abs(feat))=33.5089;\n",
      "iter=190; mean(abs(feat))=26.1392;\n",
      "iter=191; mean(abs(feat))=28.4627;\n",
      "iter=192; mean(abs(feat))=23.8141;\n",
      "iter=193; mean(abs(feat))=28.0923;\n",
      "iter=194; mean(abs(feat))=27.6133;\n",
      "iter=195; mean(abs(feat))=29.8829;\n",
      "iter=196; mean(abs(feat))=25.5307;\n",
      "iter=197; mean(abs(feat))=29.8128;\n",
      "iter=198; mean(abs(feat))=29.0798;\n",
      "iter=199; mean(abs(feat))=29.4404;\n",
      "iter=200; mean(abs(feat))=32.1273;\n",
      "\n",
      "channel=124\n",
      "\n",
      "iter=1; mean(abs(feat))=0.096618;\n",
      "iter=2; mean(abs(feat))=0.894885;\n",
      "iter=3; mean(abs(feat))=1.53632;\n",
      "iter=4; mean(abs(feat))=1.80043;\n",
      "iter=5; mean(abs(feat))=2.08617;\n",
      "iter=6; mean(abs(feat))=2.24787;\n",
      "iter=7; mean(abs(feat))=1.91919;\n",
      "iter=8; mean(abs(feat))=2.28913;\n",
      "iter=9; mean(abs(feat))=2.28812;\n",
      "iter=10; mean(abs(feat))=2.06024;\n",
      "iter=11; mean(abs(feat))=3.23191;\n",
      "iter=12; mean(abs(feat))=2.81282;\n",
      "iter=13; mean(abs(feat))=2.26412;\n",
      "iter=14; mean(abs(feat))=2.02283;\n",
      "iter=15; mean(abs(feat))=3.02877;\n",
      "iter=16; mean(abs(feat))=3.08686;\n",
      "iter=17; mean(abs(feat))=2.50788;\n",
      "iter=18; mean(abs(feat))=2.82113;\n",
      "iter=19; mean(abs(feat))=1.88424;\n",
      "iter=20; mean(abs(feat))=3.26721;\n",
      "iter=21; mean(abs(feat))=3.71136;\n",
      "iter=22; mean(abs(feat))=3.12819;\n",
      "iter=23; mean(abs(feat))=3.93658;\n",
      "iter=24; mean(abs(feat))=3.57708;\n",
      "iter=25; mean(abs(feat))=3.26294;\n",
      "iter=26; mean(abs(feat))=3.58584;\n",
      "iter=27; mean(abs(feat))=3.97056;\n",
      "iter=28; mean(abs(feat))=4.3766;\n",
      "iter=29; mean(abs(feat))=4.37281;\n",
      "iter=30; mean(abs(feat))=5.69385;\n",
      "iter=31; mean(abs(feat))=5.32333;\n",
      "iter=32; mean(abs(feat))=4.347;\n",
      "iter=33; mean(abs(feat))=4.16391;\n",
      "iter=34; mean(abs(feat))=6.26304;\n",
      "iter=35; mean(abs(feat))=6.46983;\n",
      "iter=36; mean(abs(feat))=7.28938;\n",
      "iter=37; mean(abs(feat))=3.84333;\n",
      "iter=38; mean(abs(feat))=7.76623;\n",
      "iter=39; mean(abs(feat))=5.79011;\n",
      "iter=40; mean(abs(feat))=6.59266;\n",
      "iter=41; mean(abs(feat))=6.68564;\n",
      "iter=42; mean(abs(feat))=8.36201;\n",
      "iter=43; mean(abs(feat))=8.43163;\n",
      "iter=44; mean(abs(feat))=7.85069;\n",
      "iter=45; mean(abs(feat))=8.49057;\n",
      "iter=46; mean(abs(feat))=6.86762;\n",
      "iter=47; mean(abs(feat))=8.34644;\n",
      "iter=48; mean(abs(feat))=6.92527;\n",
      "iter=49; mean(abs(feat))=12.9757;\n",
      "iter=50; mean(abs(feat))=10.5021;\n",
      "iter=51; mean(abs(feat))=5.65378;\n",
      "iter=52; mean(abs(feat))=10.2248;\n",
      "iter=53; mean(abs(feat))=10.9667;\n",
      "iter=54; mean(abs(feat))=10.8789;\n",
      "iter=55; mean(abs(feat))=10.4678;\n",
      "iter=56; mean(abs(feat))=9.35887;\n",
      "iter=57; mean(abs(feat))=13.6855;\n",
      "iter=58; mean(abs(feat))=9.30028;\n",
      "iter=59; mean(abs(feat))=10.9988;\n",
      "iter=60; mean(abs(feat))=11.6951;\n",
      "iter=61; mean(abs(feat))=14.6791;\n",
      "iter=62; mean(abs(feat))=13.1556;\n",
      "iter=63; mean(abs(feat))=11.0045;\n",
      "iter=64; mean(abs(feat))=14.2482;\n",
      "iter=65; mean(abs(feat))=11.6004;\n",
      "iter=66; mean(abs(feat))=12.2358;\n",
      "iter=67; mean(abs(feat))=11.014;\n",
      "iter=68; mean(abs(feat))=12.6504;\n",
      "iter=69; mean(abs(feat))=14.4381;\n",
      "iter=70; mean(abs(feat))=17.1733;\n",
      "iter=71; mean(abs(feat))=17.4049;\n",
      "iter=72; mean(abs(feat))=16.2363;\n",
      "iter=73; mean(abs(feat))=14.6664;\n",
      "iter=74; mean(abs(feat))=14.0066;\n",
      "iter=75; mean(abs(feat))=15.4279;\n",
      "iter=76; mean(abs(feat))=12.6766;\n",
      "iter=77; mean(abs(feat))=14.5318;\n",
      "iter=78; mean(abs(feat))=15.1852;\n",
      "iter=79; mean(abs(feat))=16.4404;\n",
      "iter=80; mean(abs(feat))=14.0468;\n",
      "iter=81; mean(abs(feat))=15.1668;\n",
      "iter=82; mean(abs(feat))=14.0801;\n",
      "iter=83; mean(abs(feat))=16.582;\n",
      "iter=84; mean(abs(feat))=15.5726;\n",
      "iter=85; mean(abs(feat))=19.8596;\n",
      "iter=86; mean(abs(feat))=18.5344;\n",
      "iter=87; mean(abs(feat))=20.7165;\n",
      "iter=88; mean(abs(feat))=18.82;\n",
      "iter=89; mean(abs(feat))=20.8181;\n",
      "iter=90; mean(abs(feat))=21.0698;\n",
      "iter=91; mean(abs(feat))=20.0421;\n",
      "iter=92; mean(abs(feat))=20.4986;\n",
      "iter=93; mean(abs(feat))=23.4065;\n",
      "iter=94; mean(abs(feat))=22.6745;\n",
      "iter=95; mean(abs(feat))=22.9546;\n",
      "iter=96; mean(abs(feat))=22.4472;\n",
      "iter=97; mean(abs(feat))=19.6233;\n",
      "iter=98; mean(abs(feat))=22.0235;\n",
      "iter=99; mean(abs(feat))=21.4481;\n",
      "iter=100; mean(abs(feat))=21.6584;\n",
      "iter=101; mean(abs(feat))=23.7624;\n",
      "iter=102; mean(abs(feat))=20.6313;\n",
      "iter=103; mean(abs(feat))=19.9136;\n",
      "iter=104; mean(abs(feat))=24.5844;\n",
      "iter=105; mean(abs(feat))=17.5315;\n",
      "iter=106; mean(abs(feat))=18.4377;\n",
      "iter=107; mean(abs(feat))=20.9538;\n",
      "iter=108; mean(abs(feat))=22.8078;\n",
      "iter=109; mean(abs(feat))=23.044;\n",
      "iter=110; mean(abs(feat))=21.0993;\n",
      "iter=111; mean(abs(feat))=19.3753;\n",
      "iter=112; mean(abs(feat))=14.8243;\n",
      "iter=113; mean(abs(feat))=24.7068;\n",
      "iter=114; mean(abs(feat))=21.2298;\n",
      "iter=115; mean(abs(feat))=24.6968;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=116; mean(abs(feat))=22.3069;\n",
      "iter=117; mean(abs(feat))=24.2974;\n",
      "iter=118; mean(abs(feat))=16.3743;\n",
      "iter=119; mean(abs(feat))=22.5375;\n",
      "iter=120; mean(abs(feat))=21.2603;\n",
      "iter=121; mean(abs(feat))=23.416;\n",
      "iter=122; mean(abs(feat))=27.4001;\n",
      "iter=123; mean(abs(feat))=27.2673;\n",
      "iter=124; mean(abs(feat))=24.0843;\n",
      "iter=125; mean(abs(feat))=22.9926;\n",
      "iter=126; mean(abs(feat))=26.6773;\n",
      "iter=127; mean(abs(feat))=22.5561;\n",
      "iter=128; mean(abs(feat))=24.9213;\n",
      "iter=129; mean(abs(feat))=23.9271;\n",
      "iter=130; mean(abs(feat))=23.2206;\n",
      "iter=131; mean(abs(feat))=29.4054;\n",
      "iter=132; mean(abs(feat))=26.1144;\n",
      "iter=133; mean(abs(feat))=25.5215;\n",
      "iter=134; mean(abs(feat))=29.9524;\n",
      "iter=135; mean(abs(feat))=23.584;\n",
      "iter=136; mean(abs(feat))=20.707;\n",
      "iter=137; mean(abs(feat))=29.4902;\n",
      "iter=138; mean(abs(feat))=26.946;\n",
      "iter=139; mean(abs(feat))=23.6221;\n",
      "iter=140; mean(abs(feat))=19.5546;\n",
      "iter=141; mean(abs(feat))=24.6353;\n",
      "iter=142; mean(abs(feat))=22.5013;\n",
      "iter=143; mean(abs(feat))=26.5022;\n",
      "iter=144; mean(abs(feat))=27.7643;\n",
      "iter=145; mean(abs(feat))=30.5576;\n",
      "iter=146; mean(abs(feat))=20.7706;\n",
      "iter=147; mean(abs(feat))=23.4938;\n",
      "iter=148; mean(abs(feat))=28.1368;\n",
      "iter=149; mean(abs(feat))=26.996;\n",
      "iter=150; mean(abs(feat))=23.8748;\n",
      "iter=151; mean(abs(feat))=30.4219;\n",
      "iter=152; mean(abs(feat))=26.5807;\n",
      "iter=153; mean(abs(feat))=28.477;\n",
      "iter=154; mean(abs(feat))=26.5601;\n",
      "iter=155; mean(abs(feat))=29.5505;\n",
      "iter=156; mean(abs(feat))=29.3787;\n",
      "iter=157; mean(abs(feat))=24.2101;\n",
      "iter=158; mean(abs(feat))=28.3729;\n",
      "iter=159; mean(abs(feat))=28.1467;\n",
      "iter=160; mean(abs(feat))=27.7318;\n",
      "iter=161; mean(abs(feat))=26.563;\n",
      "iter=162; mean(abs(feat))=25.9324;\n",
      "iter=163; mean(abs(feat))=30.4617;\n",
      "iter=164; mean(abs(feat))=30.2615;\n",
      "iter=165; mean(abs(feat))=27.554;\n",
      "iter=166; mean(abs(feat))=30.6436;\n",
      "iter=167; mean(abs(feat))=29.6898;\n",
      "iter=168; mean(abs(feat))=27.3546;\n",
      "iter=169; mean(abs(feat))=25.236;\n",
      "iter=170; mean(abs(feat))=30.6209;\n",
      "iter=171; mean(abs(feat))=27.8316;\n",
      "iter=172; mean(abs(feat))=31.0395;\n",
      "iter=173; mean(abs(feat))=30.798;\n",
      "iter=174; mean(abs(feat))=35.9206;\n",
      "iter=175; mean(abs(feat))=33.0074;\n",
      "iter=176; mean(abs(feat))=32.3726;\n",
      "iter=177; mean(abs(feat))=34.3165;\n",
      "iter=178; mean(abs(feat))=25.2382;\n",
      "iter=179; mean(abs(feat))=35.0002;\n",
      "iter=180; mean(abs(feat))=33.1717;\n",
      "iter=181; mean(abs(feat))=22.6452;\n",
      "iter=182; mean(abs(feat))=35.188;\n",
      "iter=183; mean(abs(feat))=29.6245;\n",
      "iter=184; mean(abs(feat))=30.3;\n",
      "iter=185; mean(abs(feat))=26.2342;\n",
      "iter=186; mean(abs(feat))=31.4874;\n",
      "iter=187; mean(abs(feat))=35.337;\n",
      "iter=188; mean(abs(feat))=29.1832;\n",
      "iter=189; mean(abs(feat))=35.0465;\n",
      "iter=190; mean(abs(feat))=34.4551;\n",
      "iter=191; mean(abs(feat))=26.0402;\n",
      "iter=192; mean(abs(feat))=30.5446;\n",
      "iter=193; mean(abs(feat))=34.4692;\n",
      "iter=194; mean(abs(feat))=32.6866;\n",
      "iter=195; mean(abs(feat))=36.0256;\n",
      "iter=196; mean(abs(feat))=32.8417;\n",
      "iter=197; mean(abs(feat))=33.7892;\n",
      "iter=198; mean(abs(feat))=35.9008;\n",
      "iter=199; mean(abs(feat))=37.4015;\n",
      "iter=200; mean(abs(feat))=36.4132;\n",
      "\n",
      "channel=215\n",
      "\n",
      "iter=1; mean(abs(feat))=0.0956182;\n",
      "iter=2; mean(abs(feat))=0.0943744;\n",
      "iter=3; mean(abs(feat))=0.0251491;\n",
      "iter=4; mean(abs(feat))=0.308446;\n",
      "iter=5; mean(abs(feat))=0.601273;\n",
      "iter=6; mean(abs(feat))=0.760218;\n",
      "iter=7; mean(abs(feat))=1.21817;\n",
      "iter=8; mean(abs(feat))=1.31705;\n",
      "iter=9; mean(abs(feat))=2.09227;\n",
      "iter=10; mean(abs(feat))=1.43529;\n",
      "iter=11; mean(abs(feat))=1.76892;\n",
      "iter=12; mean(abs(feat))=1.68676;\n",
      "iter=13; mean(abs(feat))=2.74097;\n",
      "iter=14; mean(abs(feat))=2.28847;\n",
      "iter=15; mean(abs(feat))=1.53629;\n",
      "iter=16; mean(abs(feat))=2.219;\n",
      "iter=17; mean(abs(feat))=2.7102;\n",
      "iter=18; mean(abs(feat))=2.66598;\n",
      "iter=19; mean(abs(feat))=2.47524;\n",
      "iter=20; mean(abs(feat))=1.96152;\n",
      "iter=21; mean(abs(feat))=2.46817;\n",
      "iter=22; mean(abs(feat))=2.73641;\n",
      "iter=23; mean(abs(feat))=2.65375;\n",
      "iter=24; mean(abs(feat))=2.77736;\n",
      "iter=25; mean(abs(feat))=2.5272;\n",
      "iter=26; mean(abs(feat))=3.42355;\n",
      "iter=27; mean(abs(feat))=3.82062;\n",
      "iter=28; mean(abs(feat))=3.46054;\n",
      "iter=29; mean(abs(feat))=3.48341;\n",
      "iter=30; mean(abs(feat))=3.595;\n",
      "iter=31; mean(abs(feat))=3.64049;\n",
      "iter=32; mean(abs(feat))=3.17929;\n",
      "iter=33; mean(abs(feat))=4.16026;\n",
      "iter=34; mean(abs(feat))=3.60938;\n",
      "iter=35; mean(abs(feat))=3.90425;\n",
      "iter=36; mean(abs(feat))=4.62613;\n",
      "iter=37; mean(abs(feat))=5.28401;\n",
      "iter=38; mean(abs(feat))=5.5472;\n",
      "iter=39; mean(abs(feat))=5.61251;\n",
      "iter=40; mean(abs(feat))=5.36775;\n",
      "iter=41; mean(abs(feat))=4.10155;\n",
      "iter=42; mean(abs(feat))=4.8381;\n",
      "iter=43; mean(abs(feat))=4.87678;\n",
      "iter=44; mean(abs(feat))=6.70092;\n",
      "iter=45; mean(abs(feat))=2.67061;\n",
      "iter=46; mean(abs(feat))=4.26888;\n",
      "iter=47; mean(abs(feat))=6.25788;\n",
      "iter=48; mean(abs(feat))=3.70914;\n",
      "iter=49; mean(abs(feat))=6.98129;\n",
      "iter=50; mean(abs(feat))=6.86263;\n",
      "iter=51; mean(abs(feat))=6.85618;\n",
      "iter=52; mean(abs(feat))=7.03389;\n",
      "iter=53; mean(abs(feat))=6.59423;\n",
      "iter=54; mean(abs(feat))=7.3312;\n",
      "iter=55; mean(abs(feat))=6.26346;\n",
      "iter=56; mean(abs(feat))=8.32379;\n",
      "iter=57; mean(abs(feat))=8.58493;\n",
      "iter=58; mean(abs(feat))=6.80366;\n",
      "iter=59; mean(abs(feat))=8.80367;\n",
      "iter=60; mean(abs(feat))=9.19031;\n",
      "iter=61; mean(abs(feat))=9.06499;\n",
      "iter=62; mean(abs(feat))=8.82067;\n",
      "iter=63; mean(abs(feat))=9.66471;\n",
      "iter=64; mean(abs(feat))=7.76778;\n",
      "iter=65; mean(abs(feat))=8.75589;\n",
      "iter=66; mean(abs(feat))=9.76906;\n",
      "iter=67; mean(abs(feat))=12.0255;\n",
      "iter=68; mean(abs(feat))=6.70683;\n",
      "iter=69; mean(abs(feat))=10.7867;\n",
      "iter=70; mean(abs(feat))=10.4057;\n",
      "iter=71; mean(abs(feat))=11.2585;\n",
      "iter=72; mean(abs(feat))=11.883;\n",
      "iter=73; mean(abs(feat))=9.72324;\n",
      "iter=74; mean(abs(feat))=12.3942;\n",
      "iter=75; mean(abs(feat))=13.2271;\n",
      "iter=76; mean(abs(feat))=14.0578;\n",
      "iter=77; mean(abs(feat))=13.1518;\n",
      "iter=78; mean(abs(feat))=7.25434;\n",
      "iter=79; mean(abs(feat))=10.8585;\n",
      "iter=80; mean(abs(feat))=11.4333;\n",
      "iter=81; mean(abs(feat))=16.2777;\n",
      "iter=82; mean(abs(feat))=12.3481;\n",
      "iter=83; mean(abs(feat))=14.142;\n",
      "iter=84; mean(abs(feat))=15.007;\n",
      "iter=85; mean(abs(feat))=11.8767;\n",
      "iter=86; mean(abs(feat))=11.3304;\n",
      "iter=87; mean(abs(feat))=11.4987;\n",
      "iter=88; mean(abs(feat))=12.7356;\n",
      "iter=89; mean(abs(feat))=13.4016;\n",
      "iter=90; mean(abs(feat))=16.2168;\n",
      "iter=91; mean(abs(feat))=13.3617;\n",
      "iter=92; mean(abs(feat))=16.5674;\n",
      "iter=93; mean(abs(feat))=12.8738;\n",
      "iter=94; mean(abs(feat))=14.3823;\n",
      "iter=95; mean(abs(feat))=15.4841;\n",
      "iter=96; mean(abs(feat))=12.4347;\n",
      "iter=97; mean(abs(feat))=15.7034;\n",
      "iter=98; mean(abs(feat))=19.0343;\n",
      "iter=99; mean(abs(feat))=14.7547;\n",
      "iter=100; mean(abs(feat))=18.2211;\n",
      "iter=101; mean(abs(feat))=14.1896;\n",
      "iter=102; mean(abs(feat))=17.7078;\n",
      "iter=103; mean(abs(feat))=10.4183;\n",
      "iter=104; mean(abs(feat))=15.8496;\n",
      "iter=105; mean(abs(feat))=15.6629;\n",
      "iter=106; mean(abs(feat))=13.3312;\n",
      "iter=107; mean(abs(feat))=13.7644;\n",
      "iter=108; mean(abs(feat))=13.3718;\n",
      "iter=109; mean(abs(feat))=17.6055;\n",
      "iter=110; mean(abs(feat))=13.8226;\n",
      "iter=111; mean(abs(feat))=15.824;\n",
      "iter=112; mean(abs(feat))=12.5567;\n",
      "iter=113; mean(abs(feat))=16.6056;\n",
      "iter=114; mean(abs(feat))=18.3908;\n",
      "iter=115; mean(abs(feat))=17.1284;\n",
      "iter=116; mean(abs(feat))=17.4165;\n",
      "iter=117; mean(abs(feat))=14.9417;\n",
      "iter=118; mean(abs(feat))=17.2194;\n",
      "iter=119; mean(abs(feat))=16.9442;\n",
      "iter=120; mean(abs(feat))=18.421;\n",
      "iter=121; mean(abs(feat))=21.6226;\n",
      "iter=122; mean(abs(feat))=19.5862;\n",
      "iter=123; mean(abs(feat))=20.7659;\n",
      "iter=124; mean(abs(feat))=15.5562;\n",
      "iter=125; mean(abs(feat))=22.2768;\n",
      "iter=126; mean(abs(feat))=18.3861;\n",
      "iter=127; mean(abs(feat))=22.883;\n",
      "iter=128; mean(abs(feat))=22.671;\n",
      "iter=129; mean(abs(feat))=21.7581;\n",
      "iter=130; mean(abs(feat))=19.6396;\n",
      "iter=131; mean(abs(feat))=18.7332;\n",
      "iter=132; mean(abs(feat))=18.3054;\n",
      "iter=133; mean(abs(feat))=17.2883;\n",
      "iter=134; mean(abs(feat))=18.371;\n",
      "iter=135; mean(abs(feat))=17.4062;\n",
      "iter=136; mean(abs(feat))=22.7418;\n",
      "iter=137; mean(abs(feat))=15.6661;\n",
      "iter=138; mean(abs(feat))=21.1277;\n",
      "iter=139; mean(abs(feat))=24.8534;\n",
      "iter=140; mean(abs(feat))=19.8565;\n",
      "iter=141; mean(abs(feat))=21.4848;\n",
      "iter=142; mean(abs(feat))=21.1065;\n",
      "iter=143; mean(abs(feat))=23.3305;\n",
      "iter=144; mean(abs(feat))=20.5503;\n",
      "iter=145; mean(abs(feat))=19.1945;\n",
      "iter=146; mean(abs(feat))=19.7593;\n",
      "iter=147; mean(abs(feat))=19.4719;\n",
      "iter=148; mean(abs(feat))=25.138;\n",
      "iter=149; mean(abs(feat))=21.6464;\n",
      "iter=150; mean(abs(feat))=23.5332;\n",
      "iter=151; mean(abs(feat))=17.5317;\n",
      "iter=152; mean(abs(feat))=20.6592;\n",
      "iter=153; mean(abs(feat))=15.12;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=154; mean(abs(feat))=22.6226;\n",
      "iter=155; mean(abs(feat))=18.1482;\n",
      "iter=156; mean(abs(feat))=23.4864;\n",
      "iter=157; mean(abs(feat))=20.8365;\n",
      "iter=158; mean(abs(feat))=23.9851;\n",
      "iter=159; mean(abs(feat))=18.8115;\n",
      "iter=160; mean(abs(feat))=22.1356;\n",
      "iter=161; mean(abs(feat))=24.6211;\n",
      "iter=162; mean(abs(feat))=19.568;\n",
      "iter=163; mean(abs(feat))=23.1422;\n",
      "iter=164; mean(abs(feat))=23.0608;\n",
      "iter=165; mean(abs(feat))=24.4634;\n",
      "iter=166; mean(abs(feat))=27.4218;\n",
      "iter=167; mean(abs(feat))=22.6917;\n",
      "iter=168; mean(abs(feat))=27.3035;\n",
      "iter=169; mean(abs(feat))=27.0378;\n",
      "iter=170; mean(abs(feat))=20.1096;\n",
      "iter=171; mean(abs(feat))=26.3057;\n",
      "iter=172; mean(abs(feat))=27.0722;\n",
      "iter=173; mean(abs(feat))=24.4417;\n",
      "iter=174; mean(abs(feat))=26.9486;\n",
      "iter=175; mean(abs(feat))=23.3633;\n",
      "iter=176; mean(abs(feat))=28.6618;\n",
      "iter=177; mean(abs(feat))=28.986;\n",
      "iter=178; mean(abs(feat))=26.9824;\n",
      "iter=179; mean(abs(feat))=22.6665;\n",
      "iter=180; mean(abs(feat))=30.01;\n",
      "iter=181; mean(abs(feat))=27.7421;\n",
      "iter=182; mean(abs(feat))=29.1055;\n",
      "iter=183; mean(abs(feat))=29.7737;\n",
      "iter=184; mean(abs(feat))=29.523;\n",
      "iter=185; mean(abs(feat))=24.6382;\n",
      "iter=186; mean(abs(feat))=29.5948;\n",
      "iter=187; mean(abs(feat))=31.0131;\n",
      "iter=188; mean(abs(feat))=27.4545;\n",
      "iter=189; mean(abs(feat))=31.6737;\n",
      "iter=190; mean(abs(feat))=30.4333;\n",
      "iter=191; mean(abs(feat))=32.8453;\n",
      "iter=192; mean(abs(feat))=30.4108;\n",
      "iter=193; mean(abs(feat))=25.2218;\n",
      "iter=194; mean(abs(feat))=32.1287;\n",
      "iter=195; mean(abs(feat))=29.1388;\n",
      "iter=196; mean(abs(feat))=24.7906;\n",
      "iter=197; mean(abs(feat))=27.0603;\n",
      "iter=198; mean(abs(feat))=30.8476;\n",
      "iter=199; mean(abs(feat))=31.6575;\n",
      "iter=200; mean(abs(feat))=30.7304;\n"
     ]
    }
   ],
   "source": [
    "for channel in channel_list:\n",
    "    #\n",
    "    print('')\n",
    "    print('channel='+str(channel))\n",
    "    print('')\n",
    "\n",
    "    # target units\n",
    "    feat_size = feat_shape\n",
    "    #y_index = int(feat_size[2]/2) # the unit in the center of feature map\n",
    "    #x_index = int(feat_size[3]/2) # the unit in the center of feature map\n",
    "    feature_mask = np.zeros(feat_size)\n",
    "    #feature_mask[0,channel,y_index,x_index] = 1\n",
    "    \n",
    "    feature_mask[0,channel] = 1\n",
    "    #feature_mask[0,:] = 1\n",
    "    # weights for the target units\n",
    "    feature_weight = np.zeros(feat_size, dtype=np.float32)\n",
    "    #feature_weight[0,:] = -1000\n",
    "    feature_weight[0,channel] = 1\n",
    "    \n",
    "    #\n",
    "    preferred_stim = generate_preferred(net, exec_str_list, feature_mask=feature_mask, **opts)\n",
    "    # save the results\n",
    "    save_name = 'preferred_img' + '_layer_' + str(target_layer) + '_channel_' + str(channel) + '.npy'\n",
    "    np.save(os.path.join(save_path,save_name), preferred_stim)\n",
    "\n",
    "    save_name = 'preferred_img' + '_layer_' + str(target_layer) + '_channel_' + str(channel) + '.jpg'\n",
    "    #save_video(normalise_vid(clip_extreme_pixel(preferred_stim,pct=0.04)), save_name, save_path )\n",
    "    PIL.Image.fromarray(normalise_img(clip_extreme_pixel(preferred_stim, pct=0.04))).save(\n",
    "                    os.path.join(save_path, save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_cnn_features' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-78603992f51b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mee\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mget_cnn_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreferred_stim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexec_str_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_cnn_features' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "ee= get_cnn_features(net, torch.Tensor(preferred_stim.transpose(2,0,1)[np.newaxis]), exec_str_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ee[0].detach().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.29465234"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.classifier.weight.detach().numpy().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
