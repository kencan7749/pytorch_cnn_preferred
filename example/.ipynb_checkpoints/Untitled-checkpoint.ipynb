{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "# import\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "\n",
    "import scipy.io as sio\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.path.append('../model')\n",
    "from C3D import C3D\n",
    "                \n",
    "\n",
    "sys.path.append('../cnn_preferred')\n",
    "from utils import normalise_img, clip_extreme_pixel, save_video, normalise_vid, get_cnn_features\n",
    "from activation_maximization import generate_preferred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isdir('../cnn_preferred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C3D(\n",
       "  (conv1): Conv3d(3, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool1): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool2): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3a): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (conv3b): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool3): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4a): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (conv4b): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool4): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv5a): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (conv5b): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool5): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
       "  (fc6): Linear(in_features=8192, out_features=4096, bias=True)\n",
       "  (fc7): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (fc8): Linear(in_features=4096, out_features=487, bias=True)\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (relu): ReLU()\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = C3D.C3D()\n",
    "param_file = os.path.join('../model','C3D', 'c3d.pickle')\n",
    "net.load_state_dict(torch.load(param_file))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torchvision.models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torchvision.models.resnet50(pretrained=True)\n",
    "#net = torchvision.models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_mean = np.float32([104, 117, 123])\n",
    "img_std = np.float32([1,1,1])\n",
    "\n",
    "# image\n",
    "img_mean=np.array([0.485, 0.456, 0.406],dtype=np.float),\n",
    "img_std = np.array([0.229,0.224,0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_dir\n",
    "save_dir = '../result'\n",
    "save_folder = 'jupyter_demo_torch_C3D_TV_norm_all'#__file__.split('.')[0]\n",
    "save_folder = save_folder + '_' + datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "save_path = os.path.join(save_dir,save_folder)\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook(module, input, output):\n",
    "    outputs.append(output.clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C3D(\n",
       "  (conv1): Conv3d(3, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool1): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool2): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3a): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (conv3b): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool3): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4a): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (conv4b): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool4): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv5a): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (conv5b): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool5): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
       "  (fc6): Linear(in_features=8192, out_features=4096, bias=True)\n",
       "  (fc7): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (fc8): Linear(in_features=4096, out_features=487, bias=True)\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (relu): ReLU()\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_list = ['fc8']\n",
    "layer_list = ['fc8']\n",
    "layer = layer_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial image for the optimization\n",
    "fr, h, w = 16, 112,112\n",
    "initial_video = np.zeros((fr, h,w,3),dtype='float32')\n",
    "\n",
    "h, w = 224,224\n",
    "initial_image = np.zeros(( h,w,3),dtype='float32')\n",
    "\n",
    "\n",
    "initial_input = np.random.randint(0, 256, (h,w,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# video\n",
    "\n",
    "#targetlayer\n",
    "exec_str_list = [\"net.\"+layer+'.register_forward_hook(hook)']\n",
    "\n",
    "exec(\"num_of_ch = net.\"+layer+\".weight.detach().numpy().shape[0]\") #param_list[layer_value].shape[0]\n",
    "num_of_img = 10\n",
    "step = int(num_of_ch/num_of_img)\n",
    "channel_list = range(0,num_of_ch,step)\n",
    "\n",
    "ee = get_cnn_features(net,torch.Tensor(initial_video.transpose(3,0, 1, 2)[np.newaxis]), exec_str_list)\n",
    "feat_num = ee[0].detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1.8620, -1.6925, -0.6393, -0.2916,  0.4595, -0.4594, -0.4528,\n",
       "           0.2161,  0.7801, -0.4271,  0.9405,  0.2597,  1.0147, -0.5320,\n",
       "          -0.3751,  0.7027,  0.5555, -0.1977,  0.0808,  0.4149, -0.0149,\n",
       "          -0.5480, -0.8084, -0.4998, -0.2819, -0.9104, -0.2909, -0.9761,\n",
       "          -0.7457, -1.6968, -0.6902, -1.0913, -1.2734, -0.8816, -0.6625,\n",
       "          -1.5463, -1.3037, -1.2240, -1.3473, -0.2895, -0.3981, -0.3294,\n",
       "          -0.1359, -0.0137,  0.8445, -0.1700, -0.2184, -0.6449, -0.5671,\n",
       "          -0.6598, -0.6680, -0.8099, -0.5671, -0.7802, -0.4564, -1.1022,\n",
       "          -0.4305,  0.6165, -1.1533,  0.3974, -0.2420, -0.2280, -0.0916,\n",
       "          -0.5005, -0.9549, -1.0626, -0.4695, -1.0169, -0.4525, -0.5529,\n",
       "          -1.7205, -1.7023, -0.7665, -0.4090, -0.4559, -0.4317, -0.3563,\n",
       "           0.8303,  0.0300,  0.3464,  0.2805,  0.2395,  0.3012,  0.3790,\n",
       "           1.8192,  1.1401,  0.4927, -0.9365, -0.8516, -0.7921, -0.8787,\n",
       "          -0.6536, -0.9242, -1.3293, -0.7037, -1.1805, -1.4080, -1.0334,\n",
       "          -1.6470, -1.1870, -1.1644, -1.1133, -0.9879, -1.2699,  1.9306,\n",
       "           1.7575,  2.1132,  0.9002,  1.5113,  2.0378,  1.0984,  0.3686,\n",
       "           0.0045,  0.3287, -0.1483, -0.5165, -0.0212,  0.1177,  0.2412,\n",
       "          -0.4217, -0.5740,  0.8086, -0.3902, -0.9395, -1.0811, -1.4603,\n",
       "          -1.3592, -2.0162, -0.5722, -1.1932, -1.6978, -0.7801, -0.8784,\n",
       "           0.4110, -0.0263,  0.4073,  0.2869, -0.2395,  0.4955,  0.2219,\n",
       "           0.3797,  0.0408, -0.1345,  0.3549,  0.1038,  0.7185,  0.1190,\n",
       "          -0.3503, -0.6020,  0.4896,  0.3825, -0.4218,  0.9960, -0.3035,\n",
       "           0.2921, -0.2741,  0.8819,  0.2873, -0.9089,  0.6223, -0.4773,\n",
       "           1.3518,  0.9748,  0.2867,  0.2604,  0.3113, -0.9360,  0.1861,\n",
       "           0.9328,  0.0031, -0.7657, -0.5595,  0.5528,  1.1597,  1.4523,\n",
       "           1.3876,  1.4366,  0.5206,  0.7426, -0.8198,  0.6366, -1.4684,\n",
       "          -0.0183,  0.6900,  3.9695,  1.0807,  0.2612,  1.0325,  0.3361,\n",
       "           0.3590,  0.5503, -0.1707,  0.2643, -0.5589, -0.3678, -0.5668,\n",
       "          -0.4034, -1.3840, -0.9492, -1.1255, -0.8436,  0.9758,  0.7219,\n",
       "          -0.2634,  0.8639,  0.3959,  0.0651,  0.1730,  1.4905,  0.0729,\n",
       "           0.4484,  0.5265,  0.9457,  0.4290,  0.3329,  0.6664,  0.3571,\n",
       "           0.6977, -0.3092,  0.6764,  0.1434, -0.4119,  0.4585,  1.0179,\n",
       "           1.3043,  1.2635,  0.1852,  0.3406, -0.4279,  0.2662,  0.5267,\n",
       "           0.4323, -0.2702,  0.8265, -0.6754,  0.5978,  1.2031, -0.1520,\n",
       "           1.0677,  0.7022,  0.3758,  0.8628,  1.4526, -0.5620,  0.4877,\n",
       "           0.2252, -0.8213, -1.0781, -0.4732, -0.2931,  0.2919, -0.4785,\n",
       "          -0.3730, -0.4957, -1.3883, -0.0828,  0.0943,  0.1503, -0.4828,\n",
       "          -0.2592,  0.5920,  0.0694, -1.0157,  0.6024, -0.5811, -0.2546,\n",
       "          -0.6231, -0.1404,  0.7374,  1.8512,  0.5324,  0.0137, -0.1982,\n",
       "           0.3096,  0.9639,  1.3950, -0.1033,  0.2026,  0.1600,  0.6304,\n",
       "           0.5468,  0.7036,  0.8186,  0.5449,  0.0181,  1.1137,  1.4242,\n",
       "           1.6797,  1.0550,  0.4695,  0.4003, -0.4454, -0.2513,  0.0545,\n",
       "           1.1169,  0.7053, -0.1047,  0.5270, -0.2597,  0.7510,  0.3377,\n",
       "          -0.2622, -1.0390,  0.8188, -0.2896,  0.5116,  0.2574, -0.1741,\n",
       "           0.5188,  0.8882,  0.5606,  0.4996,  0.4041, -1.1743,  0.9077,\n",
       "           0.5506, -0.2158,  0.5129,  0.7437, -0.4812, -0.0310,  0.0709,\n",
       "          -1.7521,  1.1338,  0.8965,  1.1623,  0.6995,  0.7213,  0.4957,\n",
       "           0.3969,  0.2310,  2.0485,  0.0621, -1.3089, -0.4536, -0.6800,\n",
       "          -0.8405,  0.4065, -0.2150, -0.0107,  0.1779,  0.1548,  0.1218,\n",
       "          -0.1124, -0.3869, -0.1833, -0.1079, -0.6353,  0.9055,  0.8072,\n",
       "          -0.2549,  0.0252,  0.7775,  0.2747, -1.2057, -1.1384, -0.1984,\n",
       "          -0.5107,  0.2146, -0.7846, -0.5818, -0.3765, -0.3439,  0.5615,\n",
       "          -0.7242,  0.2639,  0.1034,  0.1019, -0.9852, -0.5957, -0.4203,\n",
       "          -0.4560, -0.2780, -0.5425,  0.4636,  0.6644, -0.3991, -0.2027,\n",
       "          -0.3157,  0.1774, -0.8775, -0.1770,  1.0371,  0.7361,  0.6070,\n",
       "           0.2978, -1.4965,  0.4868,  0.5057, -0.3317,  0.1461,  0.5692,\n",
       "           0.1624, -0.2373, -0.8777,  0.1375, -0.7100, -0.9356, -1.3112,\n",
       "          -0.5647, -0.2543,  0.3191, -0.5281,  0.0601, -0.9852, -0.5841,\n",
       "          -0.2737,  0.2695, -0.3587,  0.5625,  0.3642,  0.1411, -0.5105,\n",
       "          -0.6116, -0.5179, -1.1393, -1.1504, -1.2780, -1.3853, -1.0858,\n",
       "          -0.1085, -0.7711, -0.7677, -0.7143, -0.3751, -1.0216, -0.2206,\n",
       "          -0.1442,  0.7687,  0.3193, -0.6275, -0.8582, -0.6997, -1.7515,\n",
       "          -0.4813, -0.0333, -0.1511, -0.3867, -0.7139,  0.2222, -0.6719,\n",
       "          -0.7726, -0.4882, -0.6417, -0.8654, -0.0323, -1.5347,  0.0652,\n",
       "           0.5558,  2.5256,  0.6322, -0.0065, -0.1577,  0.0079,  0.2176,\n",
       "           0.7083,  0.1363,  0.9772,  0.6664, -0.0154,  2.1560, -0.1907,\n",
       "           0.5697, -0.2662, -0.3752, -0.3390, -0.4354, -0.1449, -0.0684,\n",
       "          -1.3470,  0.6135,  0.6089, -0.6971, -0.5230,  1.5158,  1.5800,\n",
       "           1.2231,  1.3264,  2.0807,  1.1783,  1.4469,  1.2296,  1.9835,\n",
       "           1.8469,  2.2189,  1.1775,  2.3574]])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#targetlayer\n",
    "exec_str_list = [\"net.classifier[6].register_forward_hook(hook)\"]\n",
    "exec(exec_str_list[0])\n",
    "exec(\"num_of_ch = net.classifier[6].weight.detach().numpy().shape[0]\") #param_list[layer_value].shape[0]\n",
    "num_of_img = 10\n",
    "step = int(num_of_ch/num_of_img)\n",
    "channel_list = range(1,num_of_ch,step)\n",
    "outputs = []\n",
    "ee = net(torch.Tensor(initial_image.transpose(2,0, 1)[np.newaxis]))\n",
    "feat_num = outputs[0].detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#targetlayer\n",
    "exec_str_list = [\"net.conv1.register_forward_hook(hook)\"]\n",
    "exec(exec_str_list[0])\n",
    "exec(\"num_of_ch = net.conv1.weight.detach().numpy().shape[0]\") #param_list[layer_value].shape[0]\n",
    "num_of_img = 10\n",
    "step = int(num_of_ch/num_of_img)\n",
    "channel_list = range(1,num_of_ch,step)\n",
    "outputs = []\n",
    "ee = net(torch.Tensor(initial_image.transpose(2,0, 1)[np.newaxis]))\n",
    "feat_num = outputs[0].detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layer = \"net.layer1[2].conv3\"\n",
    "target_layer = \"net.layer4[0].bn3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#targetlayer\n",
    "exec_str_list = [target_layer +\".register_forward_hook(hook)\"]\n",
    "\n",
    "\n",
    "exec(\"num_of_ch = \"+target_layer+\".weight.detach().numpy().shape[0]\") #param_list[layer_value].shape[0]\n",
    "num_of_img = 10\n",
    "step = int(num_of_ch/num_of_img)\n",
    "channel_list = range(0,num_of_ch,step)\n",
    "\n",
    "ee = get_cnn_features(net,torch.Tensor(initial_input.transpose(2,0, 1)[np.newaxis]), exec_str_list)\n",
    "feat_num = ee[0].detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2048, 7, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options\n",
    "opts = {\n",
    "    'img_mean': img_mean,\n",
    "    'img_std': img_std,\n",
    "    'exec_code': exec_str_list, # exection code inside the function\n",
    "\n",
    "    'iter_n': 200, # the total number of iterations for gradient descend\n",
    "\n",
    "    'disp_every': 1, # display the information on the terminal for every n iterations\n",
    "\n",
    "    'save_intermediate': True, # save the intermediate or not\n",
    "    'save_intermediate_every': 10, # save the intermediate for every n iterations\n",
    "    'save_intermediate_path': save_path, # the path to save the intermediate\n",
    "\n",
    "    'lr_start': 1., # learning rate\n",
    "    'lr_end': 1.,\n",
    "\n",
    "    'momentum_start': 0.001, # gradient with momentum\n",
    "    'momentum_end': 0.001,\n",
    "\n",
    "    'decay_start': 0.001, # pixel decay for each iteration\n",
    "    'decay_end': 0.001,\n",
    "\n",
    "    'image_blur': True, # Use image smoothing or not\n",
    "    'sigma_start': 2.5, # the size of the gaussian filter for image smoothing\n",
    "    'sigma_end': 0.5,\n",
    "\n",
    "    'image_jitter': True, # use image jittering during\n",
    "    'jitter_size': 4,\n",
    "    \n",
    "    'use_p_norm_reg': False,\n",
    "    'p': 2,\n",
    "\n",
    "    'use_TV_norm_reg': False,\n",
    "    'TVbeta1': 1, \n",
    "    'TVbeta2':1.2,\n",
    "\n",
    "    'clip_small_norm': True,\n",
    "    'clip_small_norm_every': 1,\n",
    "    'n_pct_start': 5,\n",
    "    'n_pct_end': 5,\n",
    "\n",
    "    'clip_small_contribution': True,\n",
    "    'clip_small_contribution_every': 1,\n",
    "    'c_pct_start': 5,\n",
    "    'c_pct_end':5,\n",
    "    \n",
    "    'input_size': (16, 112,112,3),\n",
    "    #'initial_input': None, # the initial image for the optimization (setting to None will use random noise as initial image)\n",
    "    'initial_input': initial_video,\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options\n",
    "opts = {\n",
    "    'img_mean': img_mean,\n",
    "    'img_std': img_std,\n",
    "    'exec_code': exec_str_list, # exection code inside the function\n",
    "\n",
    "    'iter_n': 200, # the total number of iterations for gradient descend\n",
    "\n",
    "    'disp_every': 1, # display the information on the terminal for every n iterations\n",
    "\n",
    "    'save_intermediate': True, # save the intermediate or not\n",
    "    'save_intermediate_every': 10, # save the intermediate for every n iterations\n",
    "    'save_intermediate_path': save_path, # the path to save the intermediate\n",
    "\n",
    "    'lr_start': 1., # learning rate\n",
    "    'lr_end': 1.,\n",
    "\n",
    "    'momentum_start': 0.001, # gradient with momentum\n",
    "    'momentum_end': 0.001,\n",
    "\n",
    "    'decay_start': 0.001, # pixel decay for each iteration\n",
    "    'decay_end': 0.001,\n",
    "\n",
    "    'image_blur': True, # Use image smoothing or not\n",
    "    'sigma_start': 2.5, # the size of the gaussian filter for image smoothing\n",
    "    'sigma_end': 0.5,\n",
    "\n",
    "    'image_jitter': True, # use image jittering during\n",
    "    'jitter_size': 4,\n",
    "    \n",
    "    'use_p_norm_reg': False,\n",
    "    'p': 2,\n",
    "\n",
    "    'use_TV_norm_reg': False,\n",
    "    'TVbeta1': 1, \n",
    "    'TVbeta2':1.2,\n",
    "\n",
    "    'clip_small_norm': True,\n",
    "    'clip_small_norm_every': 1,\n",
    "    'n_pct_start': 5,\n",
    "    'n_pct_end': 5,\n",
    "\n",
    "    'clip_small_contribution': True,\n",
    "    'clip_small_contribution_every': 1,\n",
    "    'c_pct_start': 5,\n",
    "    'c_pct_end':5,\n",
    "    \n",
    "    #'input_size': (16, 112,112,3),\n",
    "    'input_size': (224,224,3),\n",
    "    #'initial_input': None, # the initial image for the optimization (setting to None will use random noise as initial image)\n",
    "    'initial_input': initial_input,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options for resnet\n",
    "opts = {\n",
    "    'img_mean': img_mean,\n",
    "    'img_std': img_std,\n",
    "    'exec_code': exec_str_list, # exection code inside the function\n",
    "\n",
    "    'iter_n': 200, # the total number of iterations for gradient descend\n",
    "\n",
    "    'disp_every': 1, # display the information on the terminal for every n iterations\n",
    "\n",
    "    'save_intermediate': True, # save the intermediate or not\n",
    "    'save_intermediate_every': 10, # save the intermediate for every n iterations\n",
    "    'save_intermediate_path': save_path, # the path to save the intermediate\n",
    "\n",
    "    'lr_start': 0.01, # learning rate\n",
    "    'lr_end': 0.01,\n",
    "\n",
    "    'momentum_start': 0.00001, # gradient with momentum\n",
    "    'momentum_end': 0.00001,\n",
    "\n",
    "    'decay_start': 0.001, # pixel decay for each iteration\n",
    "    'decay_end': 0.001,\n",
    "\n",
    "    'image_blur': True, # Use image smoothing or not\n",
    "    'sigma_start': 2.5, # the size of the gaussian filter for image smoothing\n",
    "    'sigma_end': 0.5,\n",
    "\n",
    "    'image_jitter': True, # use image jittering during\n",
    "    'jitter_size': 32,\n",
    "\n",
    "    'use_TV_norm_reg': False,\n",
    "    'TVbeta1': 1, \n",
    "    'TVbeta2':1.2,\n",
    "\n",
    "    'clip_small_norm': True,\n",
    "    'clip_small_norm_every': 1,\n",
    "    'n_pct_start': 5,\n",
    "    'n_pct_end': 5,\n",
    "\n",
    "    'clip_small_contribution': True,\n",
    "    'clip_small_contribution_every': 1,\n",
    "    'c_pct_start': 5,\n",
    "    'c_pct_end':5,\n",
    "    \n",
    "    #'input_size': (16, 112,112,3),\n",
    "    'input_size': (224,224,3),\n",
    "    #'initial_input': None, # the initial image for the optimization (setting to None will use random noise as initial image)\n",
    "    'initial_input': initial_input,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_list = [149]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "channel=149\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4a85bca12142>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mfeature_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mpreferred_vid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_preferred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# save the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyworks/pytorch_cnn_preferred/cnn_preferred/activation_maximization.py\u001b[0m in \u001b[0;36mgenerate_preferred\u001b[0;34m(net, feature_mask, exec_code, img_mean, img_std, input_size, feature_weight, initial_input, iter_n, lr_start, lr_end, momentum_start, momentum_end, decay_start, decay_end, grad_normalize, image_jitter, jitter_size, image_blur, sigma_start, sigma_end, use_p_norm_reg, p, lamda_start, lamda_end, use_TV_norm_reg, TVbeta1, TVbeta2, TVlamda_start, TVlamda_end, clip_extreme, clip_extreme_every, e_pct_start, e_pct_end, clip_small_norm, clip_small_norm_every, n_pct_start, n_pct_end, clip_small_contribution, clip_small_contribution_every, c_pct_start, c_pct_end, disp_every, save_intermediate, save_intermediate_every, save_intermediate_path)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mfw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cnn_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexec_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyworks/pytorch_cnn_preferred/cnn_preferred/utils.py\u001b[0m in \u001b[0;36mget_cnn_features\u001b[0;34m(model, input, exec_code_list)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexec_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 raise RuntimeError(\n",
      "\u001b[0;32m~/pyworks/pytorch_cnn_preferred/cnn_preferred/activation_maximization.py\u001b[0m in \u001b[0;36mhook\u001b[0;34m(module, input, output)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0;31m# run the code in exec_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mexec_str\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexec_code\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'outputs' is not defined"
     ]
    }
   ],
   "source": [
    "for channel in channel_list:\n",
    "    #\n",
    "    print('')\n",
    "    print('channel='+str(channel))\n",
    "    print('')\n",
    "\n",
    "    # target units\n",
    "    feat_size = feat_num\n",
    "    y_index = int(feat_size[2]/2) # the unit in the center of feature map\n",
    "    x_index = int(feat_size[3]/2) # the unit in the center of feature map\n",
    "    feature_mask = np.zeros(feat_size)\n",
    "    feature_mask[0,channel,y_index,x_index] = 1\n",
    "\n",
    "    # weights for the target units\n",
    "    feature_weight = np.zeros(feat_size, dtype=np.float32)\n",
    "    feature_weight[:] = 1.\n",
    "    #\n",
    "    preferred_vid = generate_preferred(net, feature_mask, feature_weight=feature_weight, **opts)\n",
    "\n",
    "    # save the results\n",
    "    save_name = 'preferred_img' + '_layer_' + str(layer) + '_channel_' + str(channel) + '.mat'\n",
    "    sio.savemat(os.path.join(save_path,save_name),{'preferred_vid':preferred_vid})\n",
    "\n",
    "    save_name = 'preferred_img' + '_layer_' + str(layer) + '_channel_' + str(channel) + '.avi'\n",
    "    save_video(normalise_vid(clip_extreme_pixel(preferred_vid,pct=0.04)), save_name, save_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2048, 7, 7)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
