{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "# import\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "\n",
    "import scipy.io as sio\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.path.append('../model')\n",
    "from C3D import C3D\n",
    "                \n",
    "\n",
    "sys.path.append('../cnn_preferred')\n",
    "from utils import normalise_img, clip_extreme_pixel, save_video, normalise_vid, get_cnn_features, img_deprocess\n",
    "from activation_maximization import generate_preferred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C3D(\n",
       "  (conv1): Conv3d(3, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool1): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool2): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3a): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (conv3b): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool3): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4a): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (conv4b): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool4): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv5a): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (conv5b): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool5): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
       "  (fc6): Linear(in_features=8192, out_features=4096, bias=True)\n",
       "  (fc7): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (fc8): Linear(in_features=4096, out_features=487, bias=True)\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (relu): ReLU()\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = C3D.C3D()\n",
    "param_file = os.path.join('../model','C3D', 'c3d.pickle')\n",
    "net.load_state_dict(torch.load(param_file))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torchvision.models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#net = torchvision.models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image\n",
    "img_mean=np.array([0.485, 0.456, 0.406],dtype=np.float),\n",
    "img_std = np.array([0.229,0.224,0.225])\n",
    "\n",
    "# preprocess \n",
    "norm = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_dir\n",
    "save_dir = '../result'\n",
    "save_folder = 'jupyter_demo_torch_simpleCNN_lower'#__file__.split('.')[0]\n",
    "save_folder = save_folder + '_' + datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "save_path = os.path.join(save_dir,save_folder)\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook(module, input, output):\n",
    "    outputs.append(output.clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.features[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_list = ['fc8']\n",
    "layer_list = ['conv4a']\n",
    "layer = layer_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial image for the optimization\n",
    "\n",
    "h, w = 224,224\n",
    "initial_image = np.zeros(( h,w,3),dtype='float32')\n",
    "\n",
    "\n",
    "initial_input = np.random.randint(0, 256, (h,w,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#targetlayer\n",
    "exec_str_list = [\"net.classifier[6].register_forward_hook(hook)\"]\n",
    "exec(exec_str_list[0])\n",
    "exec(\"num_of_ch = net.classifier[6].weight.detach().numpy().shape[0]\") #param_list[layer_value].shape[0]\n",
    "num_of_img = 10\n",
    "step = int(num_of_ch/num_of_img)\n",
    "channel_list = range(1,num_of_ch,step)\n",
    "outputs = []\n",
    "ee = net(torch.Tensor(initial_image.transpose(2,0, 1)[np.newaxis]))\n",
    "feat_num = outputs[0].detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AlexNet' object has no attribute 'conv1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f573fab67e18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#targetlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mexec_str_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"net.conv1.register_forward_hook(hook)\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexec_str_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"num_of_ch = net.conv1.weight.detach().numpy().shape[0]\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#param_list[layer_value].shape[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_of_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 532\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AlexNet' object has no attribute 'conv1'"
     ]
    }
   ],
   "source": [
    "#targetlayer\n",
    "exec_str_list = [\"net.conv1.register_forward_hook(hook)\"]\n",
    "exec(exec_str_list[0])\n",
    "exec(\"num_of_ch = net.conv1.weight.detach().numpy().shape[0]\") #param_list[layer_value].shape[0]\n",
    "num_of_img = 10\n",
    "step = int(num_of_ch/num_of_img)\n",
    "channel_list = range(1,num_of_ch,step)\n",
    "outputs = []\n",
    "ee = net(torch.Tensor(initial_image.transpose(2,0, 1)[np.newaxis]))\n",
    "feat_num = outputs[0].detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_layer = \"net.features[8]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#targetlayer\n",
    "exec_str_list = [target_layer +\".register_forward_hook(hook)\"]\n",
    "\n",
    "\n",
    "exec(\"num_of_ch = \"+target_layer+\".weight.detach().numpy().shape[0]\") #param_list[layer_value].shape[0]\n",
    "num_of_img = 10\n",
    "step = int(num_of_ch/num_of_img)\n",
    "channel_list = range(0,num_of_ch,step)\n",
    "\n",
    "ee = get_cnn_features(net,torch.Tensor(initial_input.transpose(2,0, 1)[np.newaxis]), exec_str_list)\n",
    "feat_num = ee[0].detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 13, 13)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options\n",
    "opts = {\n",
    "    'img_mean': img_mean,\n",
    "    'img_std': img_std,\n",
    "    'exec_code': exec_str_list, # exection code inside the function\n",
    "\n",
    "    'iter_n': 200, # the total number of iterations for gradient descend\n",
    "\n",
    "    'disp_every': 1, # display the information on the terminal for every n iterations\n",
    "\n",
    "    'save_intermediate': True, # save the intermediate or not\n",
    "    'save_intermediate_every': 10, # save the intermediate for every n iterations\n",
    "    'save_intermediate_path': save_path, # the path to save the intermediate\n",
    "\n",
    "    'lr_start': 1., # learning rate\n",
    "    'lr_end': 1.,\n",
    "\n",
    "    'momentum_start': 0.001, # gradient with momentum\n",
    "    'momentum_end': 0.001,\n",
    "\n",
    "    'decay_start': 0.001, # pixel decay for each iteration\n",
    "    'decay_end': 0.001,\n",
    "\n",
    "    'image_blur': True, # Use image smoothing or not\n",
    "    'sigma_start': 2.5, # the size of the gaussian filter for image smoothing\n",
    "    'sigma_end': 0.5,\n",
    "\n",
    "    'image_jitter': True, # use image jittering during\n",
    "    'jitter_size': 4,\n",
    "    \n",
    "    'use_p_norm_reg': False,\n",
    "    'p': 2,\n",
    "\n",
    "    'use_TV_norm_reg': False,\n",
    "    'TVbeta1': 1, \n",
    "    'TVbeta2':1.2,\n",
    "\n",
    "    'clip_small_norm': True,\n",
    "    'clip_small_norm_every': 1,\n",
    "    'n_pct_start': 5,\n",
    "    'n_pct_end': 5,\n",
    "\n",
    "    'clip_small_contribution': True,\n",
    "    'clip_small_contribution_every': 1,\n",
    "    'c_pct_start': 5,\n",
    "    'c_pct_end':5,\n",
    "    \n",
    "    #'input_size': (16, 112,112,3),\n",
    "    'input_size': (224,224,3),\n",
    "    #'initial_input': None, # the initial image for the optimization (setting to None will use random noise as initial image)\n",
    "    'initial_input': initial_input,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_list = [14,56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "channel=14\n",
      "\n",
      "iter=1; mean(abs(feat))=2.69148;\n",
      "iter=2; mean(abs(feat))=50.6482;\n",
      "iter=3; mean(abs(feat))=39.0147;\n",
      "iter=4; mean(abs(feat))=65.4091;\n",
      "iter=5; mean(abs(feat))=127.524;\n",
      "iter=6; mean(abs(feat))=125.808;\n",
      "iter=7; mean(abs(feat))=181.409;\n",
      "iter=8; mean(abs(feat))=223.963;\n",
      "iter=9; mean(abs(feat))=236.957;\n",
      "iter=10; mean(abs(feat))=326.366;\n",
      "iter=11; mean(abs(feat))=391.958;\n",
      "iter=12; mean(abs(feat))=351.345;\n",
      "iter=13; mean(abs(feat))=373.665;\n",
      "iter=14; mean(abs(feat))=387.149;\n",
      "iter=15; mean(abs(feat))=483.593;\n",
      "iter=16; mean(abs(feat))=543.92;\n",
      "iter=17; mean(abs(feat))=519.638;\n",
      "iter=18; mean(abs(feat))=563.112;\n",
      "iter=19; mean(abs(feat))=521.439;\n",
      "iter=20; mean(abs(feat))=456.432;\n",
      "iter=21; mean(abs(feat))=553.642;\n",
      "iter=22; mean(abs(feat))=469.851;\n",
      "iter=23; mean(abs(feat))=537.237;\n",
      "iter=24; mean(abs(feat))=588.482;\n",
      "iter=25; mean(abs(feat))=597.191;\n",
      "iter=26; mean(abs(feat))=631.621;\n",
      "iter=27; mean(abs(feat))=758.477;\n",
      "iter=28; mean(abs(feat))=685.919;\n",
      "iter=29; mean(abs(feat))=664.822;\n",
      "iter=30; mean(abs(feat))=805.869;\n",
      "iter=31; mean(abs(feat))=804.4;\n",
      "iter=32; mean(abs(feat))=824.299;\n",
      "iter=33; mean(abs(feat))=757.07;\n",
      "iter=34; mean(abs(feat))=747.566;\n",
      "iter=35; mean(abs(feat))=735.164;\n",
      "iter=36; mean(abs(feat))=698.461;\n",
      "iter=37; mean(abs(feat))=848.234;\n",
      "iter=38; mean(abs(feat))=852.073;\n",
      "iter=39; mean(abs(feat))=807.344;\n",
      "iter=40; mean(abs(feat))=887.988;\n",
      "iter=41; mean(abs(feat))=878.366;\n",
      "iter=42; mean(abs(feat))=965.765;\n",
      "iter=43; mean(abs(feat))=986.437;\n",
      "iter=44; mean(abs(feat))=1074.29;\n",
      "iter=45; mean(abs(feat))=882.951;\n",
      "iter=46; mean(abs(feat))=1057.26;\n",
      "iter=47; mean(abs(feat))=1011.29;\n",
      "iter=48; mean(abs(feat))=976.909;\n",
      "iter=49; mean(abs(feat))=1084.99;\n",
      "iter=50; mean(abs(feat))=1048.94;\n",
      "iter=51; mean(abs(feat))=1028.55;\n",
      "iter=52; mean(abs(feat))=1008.2;\n",
      "iter=53; mean(abs(feat))=1058.49;\n",
      "iter=54; mean(abs(feat))=1098.22;\n",
      "iter=55; mean(abs(feat))=1150.79;\n",
      "iter=56; mean(abs(feat))=1152.86;\n",
      "iter=57; mean(abs(feat))=906.55;\n",
      "iter=58; mean(abs(feat))=1169.93;\n",
      "iter=59; mean(abs(feat))=1246.09;\n",
      "iter=60; mean(abs(feat))=1328.54;\n",
      "iter=61; mean(abs(feat))=1308.87;\n",
      "iter=62; mean(abs(feat))=1192.88;\n",
      "iter=63; mean(abs(feat))=1164.08;\n",
      "iter=64; mean(abs(feat))=1101.93;\n",
      "iter=65; mean(abs(feat))=1380.15;\n",
      "iter=66; mean(abs(feat))=1246.88;\n",
      "iter=67; mean(abs(feat))=1326.93;\n",
      "iter=68; mean(abs(feat))=1333.06;\n",
      "iter=69; mean(abs(feat))=1397.41;\n",
      "iter=70; mean(abs(feat))=1341.31;\n",
      "iter=71; mean(abs(feat))=1377.23;\n",
      "iter=72; mean(abs(feat))=1448.64;\n",
      "iter=73; mean(abs(feat))=1500.79;\n",
      "iter=74; mean(abs(feat))=1456.87;\n",
      "iter=75; mean(abs(feat))=1329.22;\n",
      "iter=76; mean(abs(feat))=1464.11;\n",
      "iter=77; mean(abs(feat))=1429.77;\n",
      "iter=78; mean(abs(feat))=1497.03;\n",
      "iter=79; mean(abs(feat))=1474.81;\n",
      "iter=80; mean(abs(feat))=1660.47;\n",
      "iter=81; mean(abs(feat))=1582.89;\n",
      "iter=82; mean(abs(feat))=1733.49;\n",
      "iter=83; mean(abs(feat))=1639.03;\n",
      "iter=84; mean(abs(feat))=1512.68;\n",
      "iter=85; mean(abs(feat))=1722.36;\n",
      "iter=86; mean(abs(feat))=1488.06;\n",
      "iter=87; mean(abs(feat))=1629.43;\n",
      "iter=88; mean(abs(feat))=1572.21;\n",
      "iter=89; mean(abs(feat))=1914.4;\n",
      "iter=90; mean(abs(feat))=2045.41;\n",
      "iter=91; mean(abs(feat))=1550.66;\n",
      "iter=92; mean(abs(feat))=2106.53;\n",
      "iter=93; mean(abs(feat))=1872.16;\n",
      "iter=94; mean(abs(feat))=1865.58;\n",
      "iter=95; mean(abs(feat))=2000.15;\n",
      "iter=96; mean(abs(feat))=2004.79;\n",
      "iter=97; mean(abs(feat))=1692.59;\n",
      "iter=98; mean(abs(feat))=1846.42;\n",
      "iter=99; mean(abs(feat))=2283.36;\n",
      "iter=100; mean(abs(feat))=2301.33;\n",
      "iter=101; mean(abs(feat))=1967.43;\n",
      "iter=102; mean(abs(feat))=2108.57;\n",
      "iter=103; mean(abs(feat))=2153.87;\n",
      "iter=104; mean(abs(feat))=2249.84;\n",
      "iter=105; mean(abs(feat))=2317.35;\n",
      "iter=106; mean(abs(feat))=2059.93;\n",
      "iter=107; mean(abs(feat))=2140.87;\n",
      "iter=108; mean(abs(feat))=2231.07;\n",
      "iter=109; mean(abs(feat))=2314.6;\n",
      "iter=110; mean(abs(feat))=2345.63;\n",
      "iter=111; mean(abs(feat))=2396.56;\n",
      "iter=112; mean(abs(feat))=2357.48;\n",
      "iter=113; mean(abs(feat))=2897.12;\n",
      "iter=114; mean(abs(feat))=2248.12;\n",
      "iter=115; mean(abs(feat))=2410.81;\n",
      "iter=116; mean(abs(feat))=2530.7;\n",
      "iter=117; mean(abs(feat))=2578.03;\n",
      "iter=118; mean(abs(feat))=2502.87;\n",
      "iter=119; mean(abs(feat))=2549.32;\n",
      "iter=120; mean(abs(feat))=2774.08;\n",
      "iter=121; mean(abs(feat))=3016.37;\n",
      "iter=122; mean(abs(feat))=2969.3;\n",
      "iter=123; mean(abs(feat))=2700.56;\n",
      "iter=124; mean(abs(feat))=3212.15;\n",
      "iter=125; mean(abs(feat))=3084.11;\n",
      "iter=126; mean(abs(feat))=3242.51;\n",
      "iter=127; mean(abs(feat))=2864.19;\n",
      "iter=128; mean(abs(feat))=3014.61;\n",
      "iter=129; mean(abs(feat))=3503.25;\n",
      "iter=130; mean(abs(feat))=2893.94;\n",
      "iter=131; mean(abs(feat))=3539.86;\n",
      "iter=132; mean(abs(feat))=3094.93;\n",
      "iter=133; mean(abs(feat))=3407.82;\n",
      "iter=134; mean(abs(feat))=3768.53;\n",
      "iter=135; mean(abs(feat))=3728.49;\n",
      "iter=136; mean(abs(feat))=2807.47;\n",
      "iter=137; mean(abs(feat))=3414.54;\n",
      "iter=138; mean(abs(feat))=3420.06;\n",
      "iter=139; mean(abs(feat))=3923.42;\n",
      "iter=140; mean(abs(feat))=3995.77;\n",
      "iter=141; mean(abs(feat))=4377.57;\n",
      "iter=142; mean(abs(feat))=4261.47;\n",
      "iter=143; mean(abs(feat))=4471.73;\n",
      "iter=144; mean(abs(feat))=3820.42;\n",
      "iter=145; mean(abs(feat))=4005.83;\n",
      "iter=146; mean(abs(feat))=4060.36;\n",
      "iter=147; mean(abs(feat))=4789.84;\n",
      "iter=148; mean(abs(feat))=4898.81;\n",
      "iter=149; mean(abs(feat))=4546.46;\n",
      "iter=150; mean(abs(feat))=4246.22;\n",
      "iter=151; mean(abs(feat))=4414.48;\n",
      "iter=152; mean(abs(feat))=5405.49;\n",
      "iter=153; mean(abs(feat))=4220.87;\n",
      "iter=154; mean(abs(feat))=4753.02;\n",
      "iter=155; mean(abs(feat))=4905.26;\n",
      "iter=156; mean(abs(feat))=5749.16;\n",
      "iter=157; mean(abs(feat))=5186.32;\n",
      "iter=158; mean(abs(feat))=4217.95;\n",
      "iter=159; mean(abs(feat))=5017.68;\n",
      "iter=160; mean(abs(feat))=4979.15;\n",
      "iter=161; mean(abs(feat))=5675.56;\n",
      "iter=162; mean(abs(feat))=5533.3;\n",
      "iter=163; mean(abs(feat))=4844.3;\n",
      "iter=164; mean(abs(feat))=5814.46;\n",
      "iter=165; mean(abs(feat))=5476.83;\n",
      "iter=166; mean(abs(feat))=6043.79;\n",
      "iter=167; mean(abs(feat))=5698.98;\n",
      "iter=168; mean(abs(feat))=6074.61;\n",
      "iter=169; mean(abs(feat))=6631.02;\n",
      "iter=170; mean(abs(feat))=7111.49;\n",
      "iter=171; mean(abs(feat))=6071.73;\n",
      "iter=172; mean(abs(feat))=5939.09;\n",
      "iter=173; mean(abs(feat))=7043.19;\n",
      "iter=174; mean(abs(feat))=7056.6;\n",
      "iter=175; mean(abs(feat))=6736.12;\n",
      "iter=176; mean(abs(feat))=7270.4;\n",
      "iter=177; mean(abs(feat))=7801.2;\n",
      "iter=178; mean(abs(feat))=6596.17;\n",
      "iter=179; mean(abs(feat))=6881.97;\n",
      "iter=180; mean(abs(feat))=7227.46;\n",
      "iter=181; mean(abs(feat))=7412.48;\n",
      "iter=182; mean(abs(feat))=7034.56;\n",
      "iter=183; mean(abs(feat))=8605.38;\n",
      "iter=184; mean(abs(feat))=9513.66;\n",
      "iter=185; mean(abs(feat))=8763.42;\n",
      "iter=186; mean(abs(feat))=8286.63;\n",
      "iter=187; mean(abs(feat))=9130.51;\n",
      "iter=188; mean(abs(feat))=8606.54;\n",
      "iter=189; mean(abs(feat))=9604.45;\n",
      "iter=190; mean(abs(feat))=9336.78;\n",
      "iter=191; mean(abs(feat))=8320.76;\n",
      "iter=192; mean(abs(feat))=9925.84;\n",
      "iter=193; mean(abs(feat))=10599;\n",
      "iter=194; mean(abs(feat))=10522.4;\n",
      "iter=195; mean(abs(feat))=9544.16;\n",
      "iter=196; mean(abs(feat))=9348.82;\n",
      "iter=197; mean(abs(feat))=10906.2;\n",
      "iter=198; mean(abs(feat))=10807.5;\n",
      "iter=199; mean(abs(feat))=11309.1;\n",
      "iter=200; mean(abs(feat))=11197.8;\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (224,224,3) (3,1,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-72d216605cad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0msave_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'preferred_img'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_layer_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_layer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_channel_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.avi'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m#save_video(normalise_vid(clip_extreme_pixel(preferred_stim,pct=0.04)), save_name, save_path )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     PIL.Image.fromarray(normalise_img(clip_extreme_pixel(img_deprocess(preferred_stim, img_mean, img_std), pct=0.04))).save(\n\u001b[0m\u001b[1;32m     28\u001b[0m                     os.path.join(save_path, save_name))\n",
      "\u001b[0;32m~/pyworks/pytorch_cnn_preferred/cnn_preferred/utils.py\u001b[0m in \u001b[0;36mimg_deprocess\u001b[0;34m(img, img_mean, img_std, norm)\u001b[0m\n\u001b[1;32m     34\u001b[0m                   img_std=np.array([0.229, 0.224, 0.225], dtype=np.float), norm=255):\n\u001b[1;32m     35\u001b[0m     \u001b[0;34m'''convert from Pytorch's input image layout'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_std\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnorm\u001b[0m  \u001b[0;31m# [:,:,::-1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (224,224,3) (3,1,1) "
     ]
    }
   ],
   "source": [
    "for channel in channel_list:\n",
    "    #\n",
    "    print('')\n",
    "    print('channel='+str(channel))\n",
    "    print('')\n",
    "\n",
    "    # target units\n",
    "    feat_size = feat_num\n",
    "    y_index = int(feat_size[2]/2) # the unit in the center of feature map\n",
    "    x_index = int(feat_size[3]/2) # the unit in the center of feature map\n",
    "    feature_mask = np.zeros(feat_size)\n",
    "    feature_mask[0,channel,y_index,x_index] = 1\n",
    "\n",
    "    # weights for the target units\n",
    "    feature_weight = np.zeros(feat_size, dtype=np.float32)\n",
    "    feature_weight[:] = 1.\n",
    "    #\n",
    "    preferred_stim = generate_preferred(net, feature_mask, feature_weight=feature_weight, **opts)\n",
    "\n",
    "    # save the results\n",
    "    save_name = 'preferred_img' + '_layer_' + str(target_layer) + '_channel_' + str(channel) + '.mat'\n",
    "    sio.savemat(os.path.join(save_path,save_name),{'preferred_stim':preferred_stim})\n",
    "    \n",
    "\n",
    "    save_name = 'preferred_img' + '_layer_' + str(target_layer) + '_channel_' + str(channel) + '.avi'\n",
    "    #save_video(normalise_vid(clip_extreme_pixel(preferred_stim,pct=0.04)), save_name, save_path )\n",
    "    PIL.Image.fromarray(normalise_img(clip_extreme_pixel(preferred_stim, pct=0.04))).save(\n",
    "                    os.path.join(save_path, save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27685.621365509032"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preferred_stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "channel=23\n",
      "\n",
      "1\n",
      "iter=1; mean(abs(feat))=4.71797;\n",
      "1\n",
      "iter=2; mean(abs(feat))=328.048;\n",
      "1\n",
      "iter=3; mean(abs(feat))=627.787;\n",
      "1\n",
      "iter=4; mean(abs(feat))=822.265;\n",
      "1\n",
      "iter=5; mean(abs(feat))=1149.37;\n",
      "1\n",
      "iter=6; mean(abs(feat))=1239.92;\n",
      "1\n",
      "iter=7; mean(abs(feat))=1461.47;\n",
      "1\n",
      "iter=8; mean(abs(feat))=1448.2;\n",
      "1\n",
      "iter=9; mean(abs(feat))=1638.48;\n",
      "1\n",
      "iter=10; mean(abs(feat))=1589.6;\n",
      "1\n",
      "iter=11; mean(abs(feat))=1647.17;\n",
      "1\n",
      "iter=12; mean(abs(feat))=1769.25;\n",
      "1\n",
      "iter=13; mean(abs(feat))=1524.04;\n",
      "1\n",
      "iter=14; mean(abs(feat))=1660.6;\n",
      "1\n",
      "iter=15; mean(abs(feat))=1712.89;\n",
      "1\n",
      "iter=16; mean(abs(feat))=1856.9;\n",
      "1\n",
      "iter=17; mean(abs(feat))=2035.2;\n",
      "1\n",
      "iter=18; mean(abs(feat))=1855.03;\n",
      "1\n",
      "iter=19; mean(abs(feat))=2101.78;\n",
      "1\n",
      "iter=20; mean(abs(feat))=2024.25;\n",
      "1\n",
      "iter=21; mean(abs(feat))=2057.42;\n",
      "1\n",
      "iter=22; mean(abs(feat))=2390.24;\n",
      "1\n",
      "iter=23; mean(abs(feat))=2378.4;\n",
      "1\n",
      "iter=24; mean(abs(feat))=2129.09;\n",
      "1\n",
      "iter=25; mean(abs(feat))=2454.77;\n",
      "1\n",
      "iter=26; mean(abs(feat))=2369.3;\n",
      "1\n",
      "iter=27; mean(abs(feat))=2474.32;\n",
      "1\n",
      "iter=28; mean(abs(feat))=2632.15;\n",
      "1\n",
      "iter=29; mean(abs(feat))=2664.48;\n",
      "1\n",
      "iter=30; mean(abs(feat))=2715.05;\n",
      "1\n",
      "iter=31; mean(abs(feat))=2576.08;\n",
      "1\n",
      "iter=32; mean(abs(feat))=2353.55;\n",
      "1\n",
      "iter=33; mean(abs(feat))=2901.76;\n",
      "1\n",
      "iter=34; mean(abs(feat))=2688.27;\n",
      "1\n",
      "iter=35; mean(abs(feat))=2949.21;\n",
      "1\n",
      "iter=36; mean(abs(feat))=2178.36;\n",
      "1\n",
      "iter=37; mean(abs(feat))=2652.63;\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-840cb4f27367>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mfeature_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mpreferred_vid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_preferred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# save the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyworks/pytorch_cnn_preferred/cnn_preferred/activation_maximization.py\u001b[0m in \u001b[0;36mgenerate_preferred\u001b[0;34m(net, feature_mask, exec_code, img_mean, img_std, input_size, feature_weight, initial_input, iter_n, lr_start, lr_end, momentum_start, momentum_end, decay_start, decay_end, grad_normalize, image_jitter, jitter_size, image_blur, sigma_start, sigma_end, use_p_norm_reg, p, lamda_start, lamda_end, use_TV_norm_reg, TVbeta1, TVbeta2, TVlamda_start, TVlamda_end, clip_extreme, clip_extreme_every, e_pct_start, e_pct_end, clip_small_norm, clip_small_norm_every, n_pct_start, n_pct_end, clip_small_contribution, clip_small_contribution_every, c_pct_start, c_pct_end, disp_every, save_intermediate, save_intermediate_every, save_intermediate_path)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mfw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cnn_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexec_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyworks/pytorch_cnn_preferred/cnn_preferred/utils.py\u001b[0m in \u001b[0;36mget_cnn_features\u001b[0;34m(model, input, exec_code_list)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexec_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyworks/pytorch_cnn_preferred/model/C3D/C3D.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, extract)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextract\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         return F.conv3d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 421\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# video\n",
    "for channel in channel_list:\n",
    "    #\n",
    "    print('')\n",
    "    print('channel='+str(channel))\n",
    "    print('')\n",
    "\n",
    "    # target units\n",
    "    feat_size = feat_num\n",
    "    t_index = int(feat_size[2]/2)\n",
    "    y_index = int(feat_size[3]/2) # the unit in the center of feature map\n",
    "    x_index = int(feat_size[4]/2) # the unit in the center of feature map\n",
    "    feature_mask = np.zeros(feat_size)\n",
    "    feature_mask[0,channel,t_index, y_index,x_index] = 1\n",
    "\n",
    "    # weights for the target units\n",
    "    feature_weight = np.zeros(feat_size, dtype=np.float32)\n",
    "    feature_weight[:] = 1.\n",
    "    #\n",
    "    preferred_vid = generate_preferred(net, feature_mask, feature_weight=feature_weight, **opts)\n",
    "\n",
    "    # save the results\n",
    "    save_name = 'preferred_img' + '_layer_' + str(layer) + '_channel_' + str(channel) + '.mat'\n",
    "    sio.savemat(os.path.join(save_path,save_name),{'preferred_vid':preferred_vid})\n",
    "\n",
    "    save_name = 'preferred_img' + '_layer_' + str(layer) + '_channel_' + str(channel) + '.avi'\n",
    "    save_video(normalise_vid(clip_extreme_pixel(preferred_vid,pct=0.04)), save_name, save_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['net.conv4a.register_forward_hook(hook)']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exec_str_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 512, 4, 14, 14)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
